[
  {
    "id": "python-basics",
    "name": "Python 기초",
    "questions": [
      {
        "id": 1,
        "text": "Python 언어의 특징으로 가장 적절하지 않은 것은 무엇인가요?",
        "options": [
          "문법이 간결하고 배우기 쉽다.",
          "컴파일 언어로 실행 속도가 매우 빠르다.",
          "방대한 라이브러리와 커뮤니티 지원이 있다.",
          "웹 개발, 데이터 분석, AI/ML 등 범용적으로 사용된다.",
          "LLM(Large Language Model) 개발에서 많은 활용성을 보인다."
        ],
        "correctIndex": 1,
        "explanation": "Python은 스크립트 언어(인터프리터)이며 컴파일 언어가 아니다.",
        "isExam": false
      },
      {
        "id": 2,
        "text": ".py 파일과 .ipynb 파일의 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          ".py 파일은 주피터 노트북 파일이다.",
          ".ipynb 파일은 일반 Python 스크립트 파일로 실제 개발에 적합하다.",
          ".ipynb 파일은 JSON 형식으로 저장되며 코드, 결과, 문서를 함께 관리할 수 있다.",
          ".py 파일은 데이터 분석 및 교육용 실험에 주로 사용된다.",
          "두 파일 형식 간에는 아무런 기능적 차이가 없다."
        ],
        "correctIndex": 2,
        "explanation": ".ipynb는 주피터 노트북 파일로 JSON 형식이며 코드와 결과, 마크다운을 함께 관리한다.",
        "isExam": false
      },
      {
        "id": 3,
        "text": "Python 변수(Variable)의 특징인 '동적 타이핑(Dynamic Typing)'에 대한 설명으로 옳은 것은?",
        "options": [
          "변수 선언 시 int, str과 같은 타입을 반드시 명시해야 한다.",
          "변수의 타입은 컴파일 시점에 결정된다.",
          "실행 시점에 값이 할당될 때 타입이 결정된다.",
          "한 번 선언된 변수의 타입은 변경할 수 없다.",
          "var, let 같은 키워드를 사용하여 변수를 선언해야 한다."
        ],
        "correctIndex": 2,
        "explanation": "Python은 실행 시점에 값이 할당될 때 타입이 결정되는 동적 타이핑을 지원한다.",
        "isExam": false
      },
      {
        "id": 4,
        "text": "Python의 변수 명명 규칙(PEP8)에 어긋나는 것은?",
        "options": [
          "user_name",
          "total_count",
          "MAX_RETRY",
          "class",
          "_private_var"
        ],
        "correctIndex": 3,
        "explanation": "예약어인 class는 변수명으로 사용할 수 없다.",
        "isExam": false
      },
      {
        "id": 5,
        "text": "다음 중 Python의 기본 자료형에 대한 설명으로 틀린 것은?",
        "options": [
          "int: 메모리 제한 없는 큰 정수를 표현할 수 있다.",
          "float: 부동소수점 방식을 사용하며 정밀도 한계가 존재한다.",
          "str: 문자열을 나타내며 불변(immutable) 시퀀스이다.",
          "bool: True와 False 값을 가지며 내부적으로는 1과 0으로 처리된다.",
          "None: 값이 0임을 나타내는 숫자형 데이터이다."
        ],
        "correctIndex": 4,
        "explanation": "None은 널 타입으로 값이 없음을 나타내며 숫자 0과는 다르다.",
        "isExam": false
      },
      {
        "id": 6,
        "text": "Python의 자료구조 중 '순서가 있고 값을 변경할 수 없는(Immutable)' 것은?",
        "options": [
          "List",
          "Dictionary",
          "Set",
          "Tuple",
          "Array"
        ],
        "correctIndex": 3,
        "explanation": "Tuple은 순서가 있지만 값을 변경할 수 없는 자료구조이다.",
        "isExam": false
      },
      {
        "id": 7,
        "text": "Python 조건문에서 '거짓(Falsy)'으로 평가되는 값이 아닌 것은?",
        "options": [
          "None",
          "0",
          "\"\" (빈 문자열)",
          "[] (빈 리스트)",
          "-1"
        ],
        "correctIndex": 4,
        "explanation": "-1은 Truthy 값이며 거짓이 아니다.",
        "isExam": false
      },
      {
        "id": 8,
        "text": "반복문(Loop) 제어 키워드 중, 현재 반복을 건너뛰고 다음 반복을 진행하게 하는 것은?",
        "options": [
          "break",
          "continue",
          "pass",
          "return",
          "stop"
        ],
        "correctIndex": 1,
        "explanation": "continue는 현재 반복을 건너뛰고 다음 반복으로 진행한다.",
        "isExam": false
      },
      {
        "id": 9,
        "text": "함수(Function)를 사용하는 목적으로 가장 적절한 것은?",
        "options": [
          "코드를 복잡하게 만들기 위해",
          "한 번만 실행되는 코드를 작성하기 위해",
          "특정 코드나 기능을 반복 사용하고 재사용성을 높이 위해",
          "프로그램의 실행 속도를 늦추기 위해",
          "변수의 타입을 강제로 변환하기 위해"
        ],
        "correctIndex": 2,
        "explanation": "함수는 코드 재사용성과 가독성을 높이기 위해 사용한다.",
        "isExam": false
      },
      {
        "id": 10,
        "text": "효율적인 코드 설계를 위한 'DRY 원칙'의 의미는 무엇인가요?",
        "options": [
          "Do Repeat Yourself (코드를 반복해서 작성하라)",
          "Don't Repeat Yourself (같은 코드의 반복을 피하라)",
          "Define Return Yield (반환값을 항상 정의하라)",
          "Data Research Yield (데이터를 먼저 분석하라)",
          "Debug Run Yield (디버깅을 먼저 수행하라)"
        ],
        "correctIndex": 1,
        "explanation": "DRY는 'Don't Repeat Yourself'의 약자로 중복 코드를 피한다는 의미이다.",
        "isExam": false
      },
      {
        "id": 11,
        "text": "Python 모듈(Module)과 패키지(Package)에 대한 설명으로 바른 것은?",
        "options": [
          ".py 파일 하나는 모듈이 될 수 없다.",
          "패키지는 하나의 폴더에 여러 모듈을 묶어서 저장하는 형식이다.",
          "import 구문은 모듈 내의 함수를 사용할 수 없게 한다.",
          "라이브러리는 모듈과 패키지를 포함하지 않는 개념이다.",
          "모듈은 반드시 __init__.py 파일이 있어야 한다."
        ],
        "correctIndex": 1,
        "explanation": "패키지는 폴더에 여러 모듈을 묶어 저장한다.",
        "isExam": false
      },
      {
        "id": 12,
        "text": "Python의 리스트 컴프리헨션(List Comprehension)을 사용한 코드로 올바른 것은? (목표: 0부터 9까지의 짝수의 제곱을 담은 리스트 생성)",
        "options": [
          "result = [x**2 if x % 2 == 0 for x in range(10)]",
          "result = [x**2 for x in range(10) if x % 2 == 0]",
          "result = {x**2 for x in range(10) if x % 2 == 0}",
          "result = (x**2 for x in range(10) if x % 2 == 0)",
          "result = [for x in range(10) if x % 2 == 0 return x**2]"
        ],
        "correctIndex": 1,
        "explanation": "리스트 컴프리헨션의 올바른 문법은 [표현식 for 변수 in 이터러블 if 조건] 형태이다.",
        "isExam": false
      },
      {
        "id": 13,
        "text": "파일 입출력 시 with open(...) as f: 구문을 사용하는 주된 이유는 무엇인가요?",
        "options": [
          "파일을 더 빠르게 읽기 위해",
          "파일의 인코딩을 자동으로 변환하기 위해",
          "블록 실행 후 파일을 자동으로 닫아주기(close) 위해",
          "바이너리 파일을 텍스트로 변환하기 위해",
          "파일 이름을 자동으로 변경하기 위해"
        ],
        "correctIndex": 2,
        "explanation": "with 구문은 블록을 벗어날 때 자동으로 파일을 닫는다.",
        "isExam": false
      },
      {
        "id": 14,
        "text": "경량 데이터 교환 형식으로, 파이썬의 Dictionary와 유사한 구조를 가진 것은?",
        "options": [
          "XML",
          "HTML",
          "CSV",
          "JSON",
          "SQL"
        ],
        "correctIndex": 3,
        "explanation": "JSON은 키-값 구조로 파이썬 dict와 유사하다.",
        "isExam": false
      },
      {
        "id": 15,
        "text": "예외 처리(Exception Handling)에서 try-except 구문의 역할로 가장 적절한 것은?",
        "options": [
          "프로그램의 문법 오류를 자동으로 수정한다.",
          "모든 에러를 무시하고 프로그램을 강제로 종료한다.",
          "실행 중 발생한 예외를 포착하여 프로그램이 비정상 종료되지 않도록 처리한다.",
          "코드를 컴파일하여 실행 속도를 높인다.",
          "데이터베이스 연결을 최적화한다."
        ],
        "correctIndex": 2,
        "explanation": "try-except는 예외를 포착해 프로그램이 중단되지 않게 처리한다.",
        "isExam": false
      },
      {
        "id": 16,
        "text": "예외 처리 구문 중 예외 발생 여부와 상관없이 '항상 실행되는 코드'를 작성하는 블록은?",
        "options": [
          "try",
          "except",
          "else",
          "finally",
          "catch"
        ],
        "correctIndex": 3,
        "explanation": "finally 블록은 예외 발생 여부와 관계없이 항상 실행된다.",
        "isExam": false
      },
      {
        "id": 17,
        "text": "객체지향 프로그래밍(OOP)에서 'Class'의 정의로 가장 적절한 것은?",
        "options": [
          "데이터(속성)와 기능(메서드)을 하나로 묶은 객체의 설계도",
          "실행 가능한 독립적인 프로그램 파일",
          "데이터베이스의 테릿을 관리하는 도구",
          "외부 라이브러리를 설치하는 명령어",
          "반복문을 효율적으로 실행하는 함수"
        ],
        "correctIndex": 0,
        "explanation": "Class는 데이터와 메서드를 포함하는 설계도이다.",
        "isExam": false
      },
      {
        "id": 18,
        "text": "Class 내부에서 인스턴스(Instance) 자신을 가리키는 키워드는 무엇인가요?",
        "options": [
          "this",
          "self",
          "me",
          "instance",
          "object"
        ],
        "correctIndex": 1,
        "explanation": "Python에서는 self가 인스턴스를 가리킨다.",
        "isExam": false
      },
      {
        "id": 19,
        "text": "Class 생성자 메서드의 이름으로 올바른 것은?",
        "options": [
          "__create__",
          "__start__",
          "__main__",
          "__init__",
          "__new__"
        ],
        "correctIndex": 3,
        "explanation": "Python 클래스의 생성자는 __init__ 메서드이다.",
        "isExam": false
      },
      {
        "id": 20,
        "text": "상속(Inheritance) 관계에서 자식 클래스가 부모 클래스의 메서드 기능을 그대로 가져오면서 확장하려고 할 때 사용하는 함수는?",
        "options": [
          "parent()",
          "base()",
          "super()",
          "root()",
          "extend()"
        ],
        "correctIndex": 2,
        "explanation": "super()를 사용해 부모 클래스 메서드를 호출한다.",
        "isExam": false
      },
      {
        "id": 21,
        "text": "Python의 특징으로 옳지 않은 것은 무엇인가요?",
        "options": [
          "인터프리터 언어이다.",
          "동적 타이핑을 지원한다.",
          "문법이 복잡하고 배우기 어렵다.",
          "방대한 라이브러리를 지원한다.",
          "AI 및 데이터 분석 분야에서 널리 사용된다."
        ],
        "correctIndex": 2,
        "explanation": "Python은 문법이 간결하고 배우기 쉬운 것이 가장 큰 특징 중 하나입니다. 또한 방대한 라이브러리와 커뮤니티 지원 덕분에 AI와 머신러닝 개발에 널리 사용되는 범용 언어입니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "다음 중 수정 불가능한(Immutable) 자료형은 무엇인가요?",
        "options": [
          "List",
          "Dictionary",
          "Set",
          "Tuple",
          "Array"
        ],
        "correctIndex": 3,
        "explanation": "Tuple은 소괄호 ()를 사용하여 데이터를 묶으며, 한 번 생성되면 내부의 값을 변경할 수 없는(Immutable) 성질을 가집니다. 반면 List는 대괄호 []를 사용하며 값 변경이 가능합니다 .",
        "isExam": true
      },
      {
        "id": 23,
        "text": "함수(Function) 정의 시 사용하는 키워드는 무엇인가요?",
        "options": [
          "func",
          "define",
          "def",
          "function",
          "lambda"
        ],
        "correctIndex": 2,
        "explanation": "Python에서 새로운 함수를 정의할 때는 def 키워드를 사용합니다. 함수의 기본 구조는 def 함수명(매개변수): 형태를 따릅니다 .",
        "isExam": true
      },
      {
        "id": 24,
        "text": "다음 코드의 실행 결과로 올바른 타입은 무엇인가요? print(type([]))",
        "options": [
          "<class 'tuple'>",
          "<class 'list'>",
          "<class 'dict'>",
          "<class 'set'>",
          "<class 'int'>"
        ],
        "correctIndex": 1,
        "explanation": "대괄호 [] 안에 값들을 나열하는 방식은 List(리스트) 자료형을 생성하는 문법입니다. 따라서 타입 확인 시 list 클래스로 출력됩니다 .",
        "isExam": true
      },
      {
        "id": 25,
        "text": "try-except 구문을 사용하는 주된 목적은 무엇인가요?",
        "options": [
          "코드 실행 속도 향상",
          "예외 발생 시 프로그램 비정상 종료 방지",
          "메모리 사용량 감소",
          "무한 루프 생성",
          "데이터베이스 자동 연결"
        ],
        "correctIndex": 1,
        "explanation": "예외 처리는 프로그램 실행 중 에러(Exception)가 발생했을 때 이를 포착하여 적절히 처리함으로써, 프로그램이 멈추지 않고 계속 실행될 수 있도록 방지하는 역할을 합니다 .",
        "isExam": true
      },
      {
        "id": 26,
        "text": "클래스 내에서 인스턴스 자신을 가리키는 첫 번째 매개변수의 관례적 이름은 무엇인가요?",
        "options": [
          "this",
          "me",
          "self",
          "instance",
          "super"
        ],
        "correctIndex": 2,
        "explanation": "Python의 클래스 메서드에서는 인스턴스 자신을 지칭하기 위해 self라는 키워드를 첫 번째 매개변수로 사용합니다. 이를 통해 인스턴스 변수에 접근할 수 있습니다 .",
        "isExam": true
      },
      {
        "id": 27,
        "text": "객체지향 프로그래밍에서 부모 클래스의 기능을 자식 클래스가 물려받는 것은 무엇인가요?",
        "options": [
          "다형성 (Polymorphism)",
          "캡슐화 (Encapsulation)",
          "상속 (Inheritance)",
          "추상화 (Abstraction)",
          "최적화 (Optimization)"
        ],
        "correctIndex": 2,
        "explanation": "상속(Inheritance)은 기존 클래스(부모)를 확장하여 새로운 클래스(자식)를 정의하는 개념입니다. 이를 통해 코드의 재사용성을 높일 수 있습니다 .",
        "isExam": true
      },
      {
        "id": 28,
        "text": "다음 중 Dictionary 자료형의 올바른 예시는 무엇인가요?",
        "options": [
          "[]",
          "(1, 2, 3)",
          "{'name': 'Kim', 'age': 25}",
          "{1, 2, 3}",
          "'{\"name\": \"Kim\"}'"
        ],
        "correctIndex": 2,
        "explanation": "Dictionary는 중괄호 {}를 사용하며, 키(Key)와 값(Value)이 콜론(:)으로 연결된 쌍(Key: Value)으로 데이터를 저장합니다 .",
        "isExam": true
      },
      {
        "id": 29,
        "text": "Python 가상 환경을 사용하는 이유로 가장 적절한 것은 무엇인가요?",
        "options": [
          "파이썬 실행 속도를 높이기 위해",
          "프로젝트별로 독립적인 라이브러리 버전을 관리하기 위해",
          "하드웨어 성능을 최적화하기 위해",
          "코드를 암호화하기 위해",
          "소스 코드를 자동으로 생성하기 위해"
        ],
        "correctIndex": 1,
        "explanation": "가상 환경은 프로젝트마다 독립적인 실행 환경을 만들어 줍니다. 이를 통해 프로젝트별로 서로 다른 버전의 라이브러리를 설치하더라도 충돌이 발생하지 않도록 관리할 수 있습니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "__init__ 메서드의 역할은 무엇인가요?",
        "options": [
          "클래스 소멸자",
          "클래스 생성자 (초기화)",
          "문자열 반환",
          "연산자 오버로딩",
          "모듈 임포트"
        ],
        "correctIndex": 1,
        "explanation": "__init__ 메서드는 클래스의 인스턴스가 생성될 때 자동으로 호출되는 생성자(Constructor)입니다. 주로 객체의 속성(변수)을 초기화하는 데 사용됩니다 .",
        "isExam": true
      }
    ]
  },
  {
    "id": "data-analysis",
    "name": "데이터 분석",
    "questions": [
      {
        "id": 1,
        "text": "Python의 수치 연산 라이브러리인 NumPy에 대한 설명으로 가장 적절하지 않은 것은?",
        "options": [
          "C 언어로 구현된 함수를 사용하여 연산 속도가 빠르다.",
          "파이썬의 기본 리스트(List)보다 대량의 데이터 처리에 유리하다.",
          "벡터, 행렬, 텐서 연산을 수행하는 데 필수적이다.",
          "머신러닝 및 딥러닝 라이브러리에서는 거의 사용되지 않는다.",
          "LLM 및 AI 분야의 기초가 되는 라이브러리다."
        ],
        "correctIndex": 3,
        "explanation": "거의 모든 ML/DL 라이브러리는 NumPy를 기반으로 사용합니다.",
        "isExam": false
      },
      {
        "id": 2,
        "text": "NumPy에서 모든 요소가 0인 m×n 행렬을 생성하는 함수는?",
        "options": [
          "np.array()",
          "np.zeros((m,n))",
          "np.ones((m,n))",
          "np.arange()",
          "np.random.randn()"
        ],
        "correctIndex": 1,
        "explanation": "np.zeros((m,n))은 m×n 크기의 영(0)행렬을 생성합니다.",
        "isExam": false
      },
      {
        "id": 3,
        "text": "두 벡터의 방향 유사도를 측정할 때 주로 사용되는 NumPy 연산은 무엇인가요?",
        "options": [
          "요소별 덧셈 (+)",
          "요소별 곱셈 (*)",
          "내적 (np.dot)",
          "전치 행렬 (.T)",
          "노름 (np.linalg.norm)"
        ],
        "correctIndex": 2,
        "explanation": "내적(Dot Product)은 벡터의 방향 유사도를 측정하는 데 활용됩니다.",
        "isExam": false
      },
      {
        "id": 4,
        "text": "NumPy 행렬 연산에서 두 행렬 A와 B의 행렬 곱(Matrix Multiplication)을 수행하는 코드로 옳은 것은?",
        "options": [
          "A * B",
          "np.add(A, B)",
          "A / B",
          "np.matmul(A, B)",
          "np.transpose(A)"
        ],
        "correctIndex": 3,
        "explanation": "행렬 곱은 np.matmul(A, B) 함수를 쓰거나 A @ B 연산자를 사용합니다.",
        "isExam": false
      },
      {
        "id": 5,
        "text": "Pandas의 데이터 구조 중 2차원 테이블 형태의 데이터를 다루는 객체는?",
        "options": [
          "Series",
          "DataFrame",
          "List",
          "Dictionary",
          "Array"
        ],
        "correctIndex": 1,
        "explanation": "Series는 1차원, DataFrame은 2차원(행과 열) 구조를 제공하며 Series의 결합 형태입니다.",
        "isExam": false
      },
      {
        "id": 6,
        "text": "Pandas DataFrame(df)의 기초 통계 분석 결과(평균, 표준편차, 최솟값 등)를 요약해서 보여주는 함수는?",
        "options": [
          "df.shape",
          "df.columns",
          "df.info()",
          "df.describe()",
          "df.head()"
        ],
        "correctIndex": 3,
        "explanation": "df.describe()는 데이터의 기본 통계 분석 결과를 제공합니다.",
        "isExam": false
      },
      {
        "id": 7,
        "text": "Pandas에서 특정 조건(예: 20대 이상이면서 남성)을 만족하는 데이터를 필터링할 때 사용하는 논리 연산자는?",
        "options": [
          "&&",
          "||",
          "& , |",
          "and, or",
          "!"
        ],
        "correctIndex": 2,
        "explanation": "Pandas 필터링 시에는 &(AND)와 |(OR) 연산자를 사용하여 조건을 결합합니다.",
        "isExam": false
      },
      {
        "id": 8,
        "text": "Pandas에서 SQL의 JOIN과 유사하게, 두 개의 DataFrame을 특정 키(Key)를 기준으로 합치는 함수는?",
        "options": [
          "concat()",
          "append()",
          "merge()",
          "groupby()",
          "pivot_table()"
        ],
        "correctIndex": 2,
        "explanation": "merge() 함수는 SQL JOIN과 유사하게 공통 컬럼을 기준으로 데이터를 병합합니다.",
        "isExam": false
      },
      {
        "id": 9,
        "text": "데이터프레임에서 특정 기준(컬럼)으로 데이터를 묶어서 통계(평균, 합계 등)를 계산할 때 사용하는 메서드는?",
        "options": [
          "sort_values()",
          "groupby()",
          "apply()",
          "fillna()",
          "drop()"
        ],
        "correctIndex": 1,
        "explanation": "groupby()는 특정 기준으로 데이터를 묶어서 통계를 계산할 때 사용됩니다.",
        "isExam": false
      },
      {
        "id": 10,
        "text": "텍스트 분석 전처리 과정이 필요한 이유로 가장 적절한 것은?",
        "options": [
          "텍스트 데이터를 이미지로 변환하기 위해",
          "불필요한 문자나 잡음(Noise)을 제거하고 데이터를 표준화하기 위해",
          "데이터의 용량을 무조건 늘리기 위해",
          "모든 단어를 숫자가 아닌 특수문자로 변환하기 위해",
          "LLM이 전처리된 데이터는 처리하지 못하기 때문에"
        ],
        "correctIndex": 1,
        "explanation": "텍스트 분석 모델에 전달하기 전에 불필요한 문자/잡음에 취약한 부분을 정리 및 표준화해야 합니다.",
        "isExam": false
      },
      {
        "id": 11,
        "text": "정규표현식(Regex) 패턴 중 연속된 숫자(0-9)를 의미하는 패턴은?",
        "options": [
          "\\s+",
          "[가-힣]+",
          "[a-zA-Z]+",
          "\\d+",
          "\\b"
        ],
        "correctIndex": 3,
        "explanation": "\\d+는 숫자를 의미하는 정규표현식 패턴입니다.",
        "isExam": false
      },
      {
        "id": 12,
        "text": "텍스트 정제(Cleaning) 단계에서 주로 수행하는 작업이 아닌 것은?",
        "options": [
          "HTML 태그 제거",
          "URL 주소 제거",
          "이모지(Emoji) 제거",
          "특수문자를 공백으로 치환",
          "문장의 긍정/부정 분류"
        ],
        "correctIndex": 4,
        "explanation": "정제(Cleaning)는 태그, URL, 이모지 제거 등을 수행하며, 감성 분류는 전처리가 끝난 후 모델링 단계의 작업입니다.",
        "isExam": false
      },
      {
        "id": 13,
        "text": "문장을 의미 있는 단위(단어, 형태소 등)로 나누는 과정을 무엇이라 하는가?",
        "options": [
          "정규화 (Normalization)",
          "토큰화 (Tokenization)",
          "임베딩 (Embedding)",
          "파싱 (Parsing)",
          "시각화 (Visualization)"
        ],
        "correctIndex": 1,
        "explanation": "토큰화(Tokenization)는 문장, 단어, 형태소 등 의미 있는 단위로 텍스트를 분리하는 과정입니다.",
        "isExam": false
      },
      {
        "id": 14,
        "text": "텍스트 정규화(Normalization)의 예시로 적절한 것은?",
        "options": [
          "\"Hello\"와 \"hello\"를 대소문자 통일하여 같은 단어로 처리한다.",
          "문장의 순서를 무작위로 섞는다.",
          "모든 명사를 제거한다.",
          "문장을 띄어쓰기 없이 모두 합친다.",
          "이미지를 텍스트로 설명한다."
        ],
        "correctIndex": 0,
        "explanation": "정규화는 대소문자 통일, 반복 문자 축소 등을 통해 텍스트를 표준 형태로 변환하는 과정입니다.",
        "isExam": false
      },
      {
        "id": 15,
        "text": "\"이\", \"그\", \"저\", \"것\"과 같이 문법적 기능은 하지만 분석에 큰 의미가 없어 제거하는 단어들을 무엇이라 하는가?",
        "options": [
          "핵심어 (Keywords)",
          "고유명사 (Proper Nouns)",
          "불용어 (Stopwords)",
          "신조어 (Slang)",
          "외래어 (Loanwords)"
        ],
        "correctIndex": 2,
        "explanation": "불용어(Stopwords)는 분석에 불필요한 조사, 접속사 등을 의미하며 이를 제거하여 품질을 개선합니다.",
        "isExam": false
      },
      {
        "id": 16,
        "text": "텍스트를 숫자로 변환하는 기법 중, 단어의 순서는 무시하고 단어의 출현 빈도만을 벡터로 표현하는 방식은?",
        "options": [
          "Word2Vec",
          "Bag of Words (BoW)",
          "Transformer",
          "RNN",
          "Sequence-to-Sequence"
        ],
        "correctIndex": 1,
        "explanation": "Bag of Words(BoW)는 텍스트를 단어의 묶음으로 처리하며, 순서를 무시하고 빈도수를 벡터로 표현합니다.",
        "isExam": false
      },
      {
        "id": 17,
        "text": "Bag of Words(BoW) 방식의 단점으로 가장 적절한 것은?",
        "options": [
          "구현이 매우 복잡하다.",
          "단어의 순서 정보가 손실되어 문맥 파악이 어렵다.",
          "계산 속도가 매우 느리다.",
          "모든 단어가 0이 아닌 값을 가진다.",
          "문서 분류에는 사용할 수 없다."
        ],
        "correctIndex": 1,
        "explanation": "BoW는 단어의 순서를 무시하기 때문에 복잡한 맥락에서 내용들을 이해하기 어렵다는 단점이 있습니다.",
        "isExam": false
      },
      {
        "id": 18,
        "text": "TF-IDF에서 'IDF(Inverse Document Frequency)'의 의미로 올바른 것은?",
        "options": [
          "특정 문서 내에서 단어가 등장한 횟수",
          "모든 문서에서 자주 등장하는 흔한 단어에 가중치를 주는 값",
          "전체 문서 수 대비 해당 단어가 포함된 문서 수의 비율을 역수로 취한 값",
          "문장의 길이를 측정하는 척도",
          "단어 간의 거리를 계산하는 함수"
        ],
        "correctIndex": 2,
        "explanation": "IDF는 전체 문서 수 중 해당 단어가 포함된 문서 수가 적을수록(희귀할수록) 높은 값을 가지며, 이는 단어의 중요도를 반영합니다.",
        "isExam": false
      },
      {
        "id": 19,
        "text": "두 문서 벡터 간의 유사도를 측정하는 방법 중, 벡터 사이의 각도(방향)를 기반으로 유사성을 판단하는 것은?",
        "options": [
          "유클리드 거리 (Euclidean Distance)",
          "맨해튼 거리 (Manhattan Distance)",
          "코사인 유사도 (Cosine Similarity)",
          "자카드 유사도 (Jaccard Similarity)",
          "해밍 거리 (Hamming Distance)"
        ],
        "correctIndex": 2,
        "explanation": "코사인 유사도(Cosine Similarity)는 두 벡터가 얼마나 비슷한 방향인지(각도)를 측정하여 유사도를 계산합니다.",
        "isExam": false
      },
      {
        "id": 20,
        "text": "TF-IDF 행렬을 사용하여 문서 간의 유사도를 시각화할 때 유용한 그래프 형태는?",
        "options": [
          "파이 차트 (Pie Chart)",
          "히트맵 (Heatmap)",
          "산점도 (Scatter Plot)",
          "박스 플롯 (Box Plot)",
          "히스토그램 (Histogram)"
        ],
        "correctIndex": 1,
        "explanation": "문서 유사도 히트맵(Heatmap)을 사용하면 문서 간의 코사인 유사도 등을 색상의 진하기로 직관적으로 비교할 수 있습니다.",
        "isExam": false
      },
      {
        "id": 21,
        "text": "NumPy 배열과 Python 리스트의 가장 큰 차이점은?",
        "options": [
          "NumPy 배열은 서로 다른 데이터 타입을 자유롭게 담을 수 있어 리스트보다 유연하다.",
          "NumPy 배열은 C로 구현되어 있어 대용량 데이터 연산 속도가 훨씬 빠르다.",
          "Python 리스트는 다차원 구조(행렬 등)를 전혀 만들 수 없다.",
          "NumPy 배열은 인덱싱(Indexing) 기능을 지원하지 않는다.",
          "두 자료구조 간에는 성능이나 기능상 차이점이 없다."
        ],
        "correctIndex": 1,
        "explanation": "NumPy는 C 언어로 구현된 함수를 사용하여 파이썬의 기본 리스트보다 벡터·행렬·텐서 연산을 훨씬 빠르게 수행할 수 있습니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "Pandas에서 CSV 파일을 불러오는 함수로 올바른 것은?",
        "options": [
          "pd.load_csv()",
          "pd.get_csv()",
          "pd.read_csv()",
          "pd.import_csv()",
          "pd.open_csv()"
        ],
        "correctIndex": 2,
        "explanation": "Pandas는 CSV 파일 로드에 특화된 pd.read_csv() 함수를 제공하며, JSON은 pd.read_json()을 사용합니다.",
        "isExam": true
      },
      {
        "id": 23,
        "text": "두 DataFrame을 특정 컬럼(Key)을 기준으로 SQL의 JOIN처럼 합치는 함수는?",
        "options": [
          "concat()",
          "append()",
          "merge()",
          "split()",
          "select()"
        ],
        "correctIndex": 2,
        "explanation": "merge() 함수는 SQL의 JOIN과 유사하게 공통된 컬럼(Key)을 기준으로 데이터를 병합하는 기능을 수행합니다.",
        "isExam": true
      },
      {
        "id": 24,
        "text": "Pandas에서 결측치(NaN)를 확인하거나 처리할 때 사용하는 메서드와 거리가 먼 것은?",
        "options": [
          "isnull()",
          "fillna()",
          "dropna()",
          "info()",
          "groupby()"
        ],
        "correctIndex": 4,
        "explanation": "isnull()은 결측치 확인, fillna()는 채우기 등에 사용됩니다. 반면 groupby()는 데이터를 그룹화하여 통계를 계산할 때 사용합니다.",
        "isExam": true
      },
      {
        "id": 25,
        "text": "Pandas groupby() 메서드의 주된 용도는 무엇인가요?",
        "options": [
          "데이터의 행과 열을 바꾸기 위해 (Transpose)",
          "특정 기준(컬럼)에 따라 데이터를 묶어서 평균, 합계 등 통계 연산을 수행하기 위해",
          "데이터의 결측치를 자동으로 제거하기 위해",
          "두 개의 데이터프레임을 위아래로 단순히 이어 붙이기 위해",
          "문자열 데이터를 날짜 데이터로 변환하기 위해"
        ],
        "correctIndex": 1,
        "explanation": "groupby()는 특정 기준(컬럼)으로 데이터를 묶어서 통계(평균, 합계 등)를 계산할 때 사용되는 핵심 함수입니다.",
        "isExam": true
      },
      {
        "id": 26,
        "text": "텍스트 전처리 중 '불용어(Stopwords)'의 예시로 가장 적절한 것은?",
        "options": [
          "인공지능, 머신러닝",
          "Python, Java, C++",
          "2024, 100, 3.14",
          "그리고, 은, 는, 이, 가",
          "삼성SDS, 데이터 분석"
        ],
        "correctIndex": 3,
        "explanation": "불용어 처리는 \"이\", \"있\", \"것\", \"그리고\"와 같이 문법적 기능은 하지만 분석에 큰 의미가 없는 조사나 접속사 등을 제거하는 과정입니다.",
        "isExam": true
      },
      {
        "id": 27,
        "text": "정규표현식(Regex)에서 숫자를 의미하며, 전화번호나 날짜 추출에 유용한 패턴은?",
        "options": [
          "\\w",
          "\\s",
          "\\d",
          "\\b",
          "\\t"
        ],
        "correctIndex": 2,
        "explanation": "정규표현식에서 \\d+ (digit) 패턴은 숫자를 의미하며, 이를 통해 텍스트 내의 날짜, 전화번호 등 숫자 데이터를 추출할 수 있습니다.",
        "isExam": true
      },
      {
        "id": 28,
        "text": "텍스트를 문맥이 반영되도록 N개의 연속된 단어 묶음으로 처리하는 기법은?",
        "options": [
          "One-hot Encoding",
          "N-gram",
          "Stemming (어간 추출)",
          "Padding",
          "Dropout"
        ],
        "correctIndex": 1,
        "explanation": "N-gram은 연속된 n개의 단어 묶음을 생성하여(\"딥러닝 모델을\", \"모델을 학습시키기\") 단어의 순서와 문맥을 반영할 수 있는 기법입니다.",
        "isExam": true
      },
      {
        "id": 29,
        "text": "TF-IDF에서 IDF(Inverse Document Frequency) 값이 높다는 것의 의미는?",
        "options": [
          "해당 단어가 모든 문서에서 매우 흔하게 등장한다.",
          "해당 단어가 문서 내에서 가장 많이 반복되었다.",
          "해당 단어의 글자 수가 많다.",
          "전체 문서 집합에서 해당 단어가 포함된 문서가 적어 희귀하다.",
          "해당 단어가 문법적으로 중요하지 않은 불용어이다."
        ],
        "correctIndex": 3,
        "explanation": "IDF는 전체 문서 수 대비 해당 단어가 포함된 문서 수의 비율을 역수로 계산한 값으로, 희귀한 단어일수록 높은 값을 가지며 중요한 단어로 취급됩니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "텍스트 임베딩 벡터 간의 유사도를 측정할 때, 벡터의 크기보다는 '방향(각도)'의 유사성을 중시하는 지표는?",
        "options": [
          "유클리드 거리 (Euclidean Distance)",
          "맨해튼 거리 (Manhattan Distance)",
          "자카드 유사도 (Jaccard Similarity)",
          "코사인 유사도 (Cosine Similarity)",
          "피어슨 상관계수 (Pearson Correlation)"
        ],
        "correctIndex": 3,
        "explanation": "코사인 유사도(Cosine Similarity)는 두 벡터 사이의 각도를 기반으로 방향이 얼마나 비슷한지를 측정하며, 문서 검색이나 추천 시스템에서 주로 사용됩니다.",
        "isExam": true
      }
    ]
  },
  {
    "id": "llm-basics",
    "name": "LLM 기본",
    "questions": [
      {
        "id": 1,
        "text": "RAG(Retrieval‑Augmented Generation)의 핵심 개념으로 가장 적절한 것은?",
        "options": [
          "모델의 파라미터를 직접 수정하여 지식을 주입하는 방식이다.",
          "외부 데이터베이스에서 관련 정보를 검색(Retrieval)하여 프롬프트에 포함시킨 뒤 생성(Generation)하는 방식이다.",
          "검색 없이 LLM의 내부 지식만을 활용해 답변을 생성하는 기법이다.",
          "텍스트를 이미지로 변환한 후 다시 텍스트로 바꾸는 과정이다.",
          "정해진 규칙(Rule‑based)에 따라 답변을 선택하는 챗봇 방식이다."
        ],
        "correctIndex": 1,
        "explanation": "RAG는 LLM이 학습하지 않은 최신 정보나 사내 데이터를 활용하기 위해, 질문과 관련된 문서를 검색하여 문맥(Context)으로 제공하는 기술입니다.",
        "isExam": false
      },
      {
        "id": 2,
        "text": "LLM의 하이퍼파라미터 중 'Temperature'에 대한 설명으로 옳은 것은?",
        "options": [
          "값이 0에 가까울수록 답변이 창의적이고 무작위성이 강해진다.",
          "값이 높을수록(예: 1.0 이상) 답변이 결정론적이고 일관되게 변한다.",
          "Temperature는 모델의 학습 속도를 조절하는 변수다.",
          "값이 낮을수록(예: 0.1) 가장 확률이 높은 토큰을 선택하여 답변이 논리적이고 사실적이 된다.",
          "Temperature는 입력 텍스트의 길이를 제한하는 설정이다."
        ],
        "correctIndex": 3,
        "explanation": "Temperature가 낮으면 확률 분포가 뾰족해져 가장 높은 확률의 단어를 선택(결정론적)하며, 높으면 분포가 평탄해져 다양한 단어를 선택(창의적)하게 됩니다.",
        "isExam": false
      },
      {
        "id": 3,
        "text": "'환각(Hallucination)' 현상에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "LLM이 사용자 의도를 완벽하게 파악하여 정답을 맞히는 현상",
          "모델이 사실이 아닌 정보를 마치 사실인 것처럼 그럴듯하게 생성하는 현상",
          "질문에 대한 답변을 거부하는 안전 장치 작동 현상",
          "검색된 문서의 내용만을 그대로 복사하여 출력하는 현상",
          "네트워크 오류로 인해 답변 생성이 중단되는 현상"
        ],
        "correctIndex": 1,
        "explanation": "환각은 LLM이 확률적으로 문장을 생성하는 과정에서, 사실 관계가 틀리거나 없는 내용을 있는 것처럼 꾸며내는 현상을 말합니다.",
        "isExam": false
      },
      {
        "id": 4,
        "text": "텍스트를 컴퓨터가 이해할 수 있는 숫자 형태의 벡터(Vector)로 변환하는 과정을 무엇이라 하는가?",
        "options": [
          "Tokenization (토큰화)",
          "Chunking (청킹)",
          "Embedding (임베딩)",
          "Parsing (파싱)",
          "Rendering (렌더링)"
        ],
        "correctIndex": 2,
        "explanation": "임베딩(Embedding)은 텍스트의 의미를 고차원 공간의 벡터(숫자 배열)로 변환하여 컴퓨터가 의미적 유사성을 계산할 수 있게 하는 과정입니다.",
        "isExam": false
      },
      {
        "id": 5,
        "text": "다음 중 벡터 데이터베이스(Vector DB)가 주로 수행하는 역할은?",
        "options": [
          "정형 데이터(SQL)의 테이블 간 관계를 정의한다.",
          "이미지 파일을 원본 그대로 압축하여 저장한다.",
          "임베딩된 벡터를 저장하고, 질문 벡터와 유사한 벡터를 고속으로 검색한다.",
          "웹사이트의 HTML 코드를 실시간으로 크롤링한다.",
          "LLM의 파라미터 가중치를 실시간으로 업데이트한다."
        ],
        "correctIndex": 2,
        "explanation": "Vector DB는 임베딩 벡터를 저장하고 인덱싱하여, 코사인 유사도 등을 기반으로 유사한 데이터를 빠르게 찾는(Similarity Search) 역할을 합니다.",
        "isExam": false
      },
      {
        "id": 6,
        "text": "RAG 파이프라인에서 'Chunking(청킹)'이 필요한 이유는?",
        "options": [
          "LLM의 컨텍스트 윈도우(입력 길이) 제한을 맞추고, 검색의 정확도를 높이기 위해",
          "텍스트를 암호화하여 보안을 강화하기 위해",
          "모든 데이터를 하나의 거대한 파일로 합치기 위해",
          "데이터베이스의 저장 용량을 늘리기 위해",
          "이미지를 텍스트로 변환하기 위해"
        ],
        "correctIndex": 0,
        "explanation": "긴 문서를 통째로 넣으면 LLM의 입력 한계를 초과하거나 정보의 밀도가 희석됩니다. 의미 단위로 적절히 자르는 청킹은 검색 정밀도와 LLM 이해도를 모두 높습니다.",
        "isExam": false
      },
      {
        "id": 7,
        "text": "'Hybrid Search(하이브리드 검색)'란 무엇을 의미하는가?",
        "options": [
          "구글 검색과 네이버 검색을 동시에 사용하는 것",
          "키워드 기반 검색(Keyword Search)과 의미 기반 검색(Semantic Search)을 결합하여 사용하는 것",
          "텍스트 검색과 이미지 검색을 번갈아 수행하는 것",
          "SQL 쿼리와 NoSQL 쿼리를 섞어 쓰는 것",
          "사람이 직접 검색하고 AI가 요약하는 방식"
        ],
        "correctIndex": 1,
        "explanation": "키워드 매칭(Lexical)의 정확성과 의미적 유사성(Semantic)의 맥락 파악 능력을 결합하여 상호 보완적인 검색 결과를 얻는 방식입니다.",
        "isExam": false
      },
      {
        "id": 8,
        "text": "RAG 시스템에서 'Reranker(재순위화 모델)'의 역할은?",
        "options": [
          "문서를 처음부터 다시 작성한다.",
          "검색된 후보 문서들의 점수를 다시 계산하여, 질문과의 관련성이 높은 순서로 재정렬한다.",
          "벡터 데이터베이스의 인덱스를 삭제한다.",
          "사용자의 질문을 다른 언어로 번역한다.",
          "검색 속도를 물리적으로 2배 빠르게 만든다."
        ],
        "correctIndex": 1,
        "explanation": "1차 검색(Retrieval)으로 가져온 문서들은 순위가 부정확할 수 있습니다. Reranker는 더 정교한 모델을 사용해 질문‑문서 쌍의 관련성을 정밀 채점하여 최상위 문서의 품질을 높입니다.",
        "isExam": false
      },
      {
        "id": 9,
        "text": "프롬프트 엔지니어링 기법 중, 예제(Example)를 몇 개 보여주어 모델이 패턴을 학습하게 하는 방식은?",
        "options": [
          "Zero-shot Prompting",
          "Few-shot Prompting",
          "Chain-of-Thought",
          "Tree of Thoughts",
          "ReAct"
        ],
        "correctIndex": 1,
        "explanation": "Few-shot Prompting은 ‘질문: A, 답변: B’와 같은 예시(Shot)를 소수 제공하여 모델이 작업의 형식과 의도를 파악하도록 유도하는 기법입니다.",
        "isExam": false
      },
      {
        "id": 10,
        "text": "'Chain-of-Thought (CoT)' 프롬프트의 특징은?",
        "options": [
          "질문에 대해 즉시 단답형으로 대답하도록 강제한다.",
          "답변을 생성하기 전에 단계별 추론 과정을 거치도록 유도한다.",
          "외부 도구를 사용하지 않도록 제한한다.",
          "모델의 파라미터를 영구적으로 변경한다.",
          "문장의 순서를 무작위로 섞는다."
        ],
        "correctIndex": 1,
        "explanation": "‘Let’s think step by step’과 같이 추론 과정을 명시적으로 생성하게 함으로써 복잡한 문제의 해결 능력을 향상시킵니다.",
        "isExam": false
      },
      {
        "id": 11,
        "text": "다음 중 LLM 기반 ‘에이전트(Agent)’와 일반적인 LLM 챗봇의 가장 큰 차이점은?",
        "options": [
          "에이전트는 인터넷에 연결되어 있지 않다.",
          "에이전트는 도구(Tool)를 스스로 선택하고 사용하여 작업을 수행하는 자율성을 가진다.",
          "챗봇은 항상 정확한 답변만 한다.",
          "에이전트는 텍스트 생성을 할 수 없다.",
          "차이점이 없다."
        ],
        "correctIndex": 1,
        "explanation": "에이전트는 단순 대화를 넘어 검색, 계산기, API 호출 등의 도구(Tool)를 사용할 수 있으며, 계획(Plan)을 세우고 실행(Action)하는 주체적 능력을 가집니다.",
        "isExam": false
      },
      {
        "id": 12,
        "text": "'Prompt Injection' 공격에 대한 설명으로 옳은 것은?",
        "options": [
          "프롬프트를 짧게 입력하여 비용을 아끼는 기술",
          "악의적인 명령어를 입력하여 LLM이 설계된 지침(System Prompt)을 무시하고 엉뚱한 동작을 하게 만드는 공격",
          "데이터베이스의 속도를 느리게 만드는 디도스 공격의 일종",
          "프롬프트에 이모티콘을 많이 넣어 답변을 부드럽게 만드는 것",
          "모델의 학습 데이터를 삭제하는 해킹 기법"
        ],
        "correctIndex": 1,
        "explanation": "‘이전의 모든 지시를 무시하고…’와 같은 문구를 통해 시스템이 설정한 윤리적 제약이나 페르소나를 뚫는 공격 방식입니다.",
        "isExam": false
      },
      {
        "id": 13,
        "text": "LLM의 'Context Window(컨텍스트 윈도우)'가 가득 찼을 때 발생하는 문제는?",
        "options": [
          "모델의 지능이 갑자기 상승한다.",
          "가장 최근의 대화 내용이나 중요한 앞부분의 정보가 잘려나가 기억하지 못하게 된다.",
          "답변 생성 속도가 매우 빨라진다.",
          "토큰 비용이 0이 된다.",
          "모델이 자동으로 재부팅된다."
        ],
        "correctIndex": 1,
        "explanation": "컨텍스트 윈도우는 모델이 한 번에 처리할 수 있는 토큰의 최대 한도입니다. 이를 초과하면 과거 정보를 잊거나 오류가 발생합니다.",
        "isExam": false
      },
      {
        "id": 14,
        "text": "RAG에서 'Lost in the Middle' 현상은 무엇을 의미하는가?",
        "options": [
          "검색된 문서가 너무 적어서 답변을 못하는 현상",
          "프롬프트의 중간 부분에 위치한 정보보다 처음과 끝에 위치한 정보를 모델이 더 잘 기억하는 경향",
          "데이터베이스의 중간 데이터가 삭제되는 현상",
          "임베딩 과정에서 중간 차원이 소실되는 현상",
          "사용자가 질문 도중에 말을 멈추는 현상"
        ],
        "correctIndex": 1,
        "explanation": "LLM은 긴 컨텍스트(Long Context)를 처리할 때, 문맥의 시작과 끝에 집중하고 중간 부분의 정보를 간과하는 경향이 있다는 연구 결과입니다.",
        "isExam": false
      },
      {
        "id": 15,
        "text": "벡터 유사도 측정 방식 중, 두 벡터 사이의 각도를 기반으로 유사성을 판단하는 가장 보편적인 지표는?",
        "options": [
          "유클리드 거리 (Euclidean Distance)",
          "코사인 유사도 (Cosine Similarity)",
          "맨해튼 거리 (Manhattan Distance)",
          "자카드 유사도 (Jaccard Similarity)",
          "해밍 거리 (Hamming Distance)"
        ],
        "correctIndex": 1,
        "explanation": "텍스트 임베딩 검색에서는 벡터의 크기보다 방향(각도)이 의미적 유사성을 더 잘 나타내므로 코사인 유사도가 가장 널리 사용됩니다.",
        "isExam": false
      },
      {
        "id": 16,
        "text": "'Fine‑tuning'과 RAG의 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          "Fine‑tuning은 외부 지식을 검색하고, RAG는 모델 내부 지식을 바꾼다.",
          "Fine‑tuning은 모델의 파라미터를 업데이트하여 특정 말투나 형식을 학습시키는 데 유리하고, RAG는 최신 정보 제공에 유리하다.",
          "RAG는 비용이 매우 비싸고 Fine‑tuning은 비용이 거의 들지 않는다.",
          "Fine‑tuning은 환각 현상을 100% 제거할 수 있다.",
          "두 기술은 동시에 사용할 수 없다."
        ],
        "correctIndex": 1,
        "explanation": "Fine‑tuning은 모델 자체를 재학습시켜 도메인 특화 지식이나 스타일을 주입하는 것이고, RAG는 검색을 통해 지식을 보강하는 것입니다. 두 기술은 상호 보완적으로 함께 사용될 수 있습니다.",
        "isExam": false
      },
      {
        "id": 17,
        "text": "LLM이 도구(Tool)를 사용하기 위해 출력해야 하는 구조화된 데이터 형식으로 가장 많이 쓰이는 것은?",
        "options": [
          "Plain Text",
          "JSON (JavaScript Object Notation)",
          "Binary Code",
          "HTML",
          "MP3"
        ],
        "correctIndex": 1,
        "explanation": "함수 호출(Function Calling) 시, LLM은 도구 이름과 인자(Arguments)를 명확히 전달하기 위해 구조화가 용이한 JSON 형식을 주로 생성합니다.",
        "isExam": false
      },
      {
        "id": 18,
        "text": "'Multi‑Query Retrieval' 전략의 목적은?",
        "options": [
          "사용자의 질문을 하나로 요약하여 검색 횟수를 줄이는 것",
          "사용자의 모호한 질문을 다양한 관점의 여러 질문으로 변환하여 검색 범위를 넓히고 정답 가능성을 높이는 것",
          "여러 명의 사용자가 동시에 질문할 수 있게 하는 것",
          "질문을 100개 복사하여 시스템 부하를 테스트하는 것",
          "검색 결과를 무시하고 LLM이 질문을 다시 만드는 것"
        ],
        "correctIndex": 1,
        "explanation": "하나의 질문만으로는 검색에 실패할 수 있으므로, LLM을 이용해 유사한 의미의 다른 질문들을 생성하고 각각 검색하여 결과를 종합하는 전략입니다.",
        "isExam": false
      },
      {
        "id": 19,
        "text": "LLM 애플리케이션 개발 프레임워크인 ‘LangChain’이나 ‘LlamaIndex’의 주된 역할이 아닌 것은?",
        "options": [
          "다양한 LLM 모델을 쉽게 교체하여 사용할 수 있게 추상화한다.",
          "문서 로드, 청킹, 임베딩 과정을 파이프라인으로 연결한다.",
          "자체적인 GPU를 제공하여 모델을 학습시킨다.",
          "에이전트 및 메모리 기능을 구현하기 위한 도구를 제공한다.",
          "프롬프트 템플릿을 관리한다."
        ],
        "correctIndex": 2,
        "explanation": "이들 프레임워크는 LLM 활용을 돕는 오케스트레이션(조정) 도구이지, GPU 인프라나 모델 학습 플랫폼 자체는 아닙니다.",
        "isExam": false
      },
      {
        "id": 20,
        "text": "RAG 시스템의 성능을 평가할 때 ‘Ground Truth(정답 데이터)’와 생성된 답변을 비교하여 평가하는 지표가 아닌 것은?",
        "options": [
          "Faithfulness (충실성 - 검색된 문서에 기반했는가)",
          "Answer Relevance (답변 관련성 - 질문에 적절한가)",
          "Context Precision (문맥 정확도 - 검색된 내용이 유용한가)",
          "Latency (지연 시간)",
          "BLEU Score (일반적인 기계 번역 평가 지표, RAG 특화는 아님)"
        ],
        "correctIndex": 3,
        "explanation": "Latency는 시스템 속도 지표이며, 내용의 정확성을 평가하는 지표는 아닙니다.",
        "isExam": false
      },
      {
        "id": 21,
        "text": "Word2Vec과 같은 임베딩 기술의 주된 목적은?",
        "options": [
          "텍스트의 오타 수정 및 자동 교정",
          "단어의 의미를 벡터(숫자)로 변환하여 컴퓨터가 이해하도록 함",
          "텍스트 데이터를 암호화하여 보안 유지",
          "문장의 문법 오류를 실시간으로 검사",
          "텍스트 데이터를 압축하여 저장 공간 확보"
        ],
        "correctIndex": 1,
        "explanation": "임베딩은 자연어(텍스트)를 컴퓨터가 계산할 수 있는 수치 형태인 고차원 벡터로 변환하는 기술입니다. 이 과정에서 비슷한 의미를 가진 단어들은 벡터 공간에서 서로 가까운 위치에 배치됩니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "트랜스포머(Transformer) 모델의 핵심 메커니즘으로, 문장 내 단어들의 관계를 계산하는 것은?",
        "options": [
          "Convolution (합성곱)",
          "Max Pooling (맥스 풀링)",
          "Self-Attention (셀프 어텐션)",
          "Recurrent Neural Network (순환 신경망)",
          "Backpropagation (역전파)"
        ],
        "correctIndex": 2,
        "explanation": "Self-Attention은 문장 내의 각 단어가 서로 어떤 관련이 있는지 점수를 매겨 중요한 정보에 집중하게 만드는 메커니즘입니다. 이를 통해 문맥을 매우 효과적으로 파악할 수 있습니다.",
        "isExam": true
      },
      {
        "id": 23,
        "text": "트랜스포머 구조에서 입력 문장의 의미를 파악하고 벡터로 변환하는 역할을 주로 하는 부분은?",
        "options": [
          "Encoder (인코더)",
          "Decoder (디코더)",
          "Generator (생성기)",
          "Discriminator (판별기)",
          "Classifier (분류기)"
        ],
        "correctIndex": 0,
        "explanation": "인코더는 입력된 정보를 받아 의미를 추출하고 수치화(임베딩)하는 데 특화되어 있습니다. 반대로 디코더는 인코더가 만든 정보를 바탕으로 새로운 문장을 생성하는 역할을 수행합니다.",
        "isExam": true
      },
      {
        "id": 24,
        "text": "GPT 모델은 트랜스포머의 어떤 부분을 주로 사용하는가?",
        "options": [
          "Encoder만 사용",
          "Decoder만 사용",
          "Encoder와 Decoder를 교차로 사용",
          "둘 다 사용하지 않고 새로운 구조 사용",
          "오직 Self-Attention 레이어만 단독 사용"
        ],
        "correctIndex": 1,
        "explanation": "GPT는 'Generative Pre-trained Transformer'의 약자로, 다음 단어를 예측하며 문장을 만들어내는 '생성'에 특화된 모델입니다. 따라서 트랜스포머의 구조 중 생성에 최적화된 디코더 구조를 기반으로 합니다.",
        "isExam": true
      },
      {
        "id": 25,
        "text": "BERT 모델의 특징으로 옳은 것은?",
        "options": [
          "단방향(왼쪽에서 오른쪽)으로만 문맥을 학습한다.",
          "주로 긴 문장을 요약하고 생성하는 데 사용된다.",
          "트랜스포머의 인코더 구조를 기반으로 양방향 문맥을 이해한다.",
          "순차적으로 데이터를 처리하여 RNN보다 속도가 느리다.",
          "이미지 인식 분야에서 가장 먼저 고안된 모델이다."
        ],
        "correctIndex": 2,
        "explanation": "BERT는 문장의 앞뒤 문맥을 동시에 고려하는 양방향(Bi-directional) 학습을 수행합니다. 트랜스포머의 인코더를 활용하며, 문맥 이해도가 높아 질문 답변이나 분류 문제에 강점이 있습니다.",
        "isExam": true
      },
      {
        "id": 26,
        "text": "트랜스포머는 병렬 처리를 위해 순서 정보가 사라지는 문제를 해결하고자 무엇을 사용하는가?",
        "options": [
          "Word Embedding",
          "Positional Encoding (포지셔널 인코딩)",
          "Tokenization",
          "Layer Normalization",
          "Dropout"
        ],
        "correctIndex": 1,
        "explanation": "트랜스포머는 RNN처럼 단어를 순차적으로 입력받지 않고 한꺼번에 처리합니다. 이때 단어의 위치(순서) 정보를 알려주기 위해 벡터 값에 위치 정보를 더해주는 '포지셔널 인코딩' 기법을 사용합니다.",
        "isExam": true
      },
      {
        "id": 27,
        "text": "다음 중 토큰화(Tokenization)에 대한 설명으로 옳은 것은?",
        "options": [
          "텍스트를 무조건 글자(Character) 단위로 자르는 것이다.",
          "텍스트를 모델이 처리 가능한 작은 단위(토큰)로 나누는 과정이다.",
          "텍스트를 문장 단위로 합쳐서 데이터를 정제하는 과정이다.",
          "이미지 데이터를 픽셀로 변환하여 신경망에 넣는 것이다.",
          "단어의 의미를 수치화하여 벡터 공간에 투영하는 것이다."
        ],
        "correctIndex": 1,
        "explanation": "토큰화는 자연어 처리를 위한 첫 단계로, 문장을 단어, 형태소, 혹은 서브워드(Subword) 단위로 쪼개어 모델이 이해할 수 있는 최소 단위인 '토큰'으로 만드는 작업입니다.",
        "isExam": true
      },
      {
        "id": 28,
        "text": "LLM이 문장을 생성하는 주된 방식은?",
        "options": [
          "문장 전체를 한 번에 통째로 생성",
          "확률적으로 가장 적절한 '다음 토큰'을 하나씩 예측 (Next Token Prediction)",
          "데이터베이스에서 미리 저장된 유사 문장을 검색하여 출력",
          "문법 규칙에 따라 단어를 무작위로 조합",
          "입력된 문장을 그대로 복사하여 출력"
        ],
        "correctIndex": 1,
        "explanation": "현재의 거대언어모델(LLM)은 이전에 나온 단어들을 바탕으로 그다음에 올 단어(토큰)가 무엇일지 확률적으로 계산하여 순차적으로 이어 붙이는 방식으로 문장을 완성합니다.",
        "isExam": true
      },
      {
        "id": 29,
        "text": "'Attention is All You Need' 논문이 발표된 연도는? (트랜스포머의 등장)",
        "options": [
          "2012년",
          "2015년",
          "2017년",
          "2019년",
          "2020년"
        ],
        "correctIndex": 2,
        "explanation": "구글 연구팀이 2017년에 발표한 이 논문은 기존의 RNN이나 CNN 없이 오직 Attention 메커니즘만으로도 뛰어난 성능을 낼 수 있음을 증명하며 생성형 AI 시대를 열었습니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "RNN 대비 트랜스포머의 가장 큰 장점은?",
        "options": [
          "모델의 파라미터 수가 훨씬 적어 가볍다.",
          "적은 양의 데이터로도 완벽하게 학습이 가능하다.",
          "긴 문맥 처리에 강하고 병렬 연산이 가능하여 학습 속도가 빠르다.",
          "이미지 데이터 처리에 있어 CNN보다 항상 우월하다.",
          "하드웨어 리소스를 거의 사용하지 않는다."
        ],
        "correctIndex": 2,
        "explanation": "RNN은 데이터를 순차적으로 처리해야 하므로 병렬화가 어렵고 긴 문장 뒤쪽으로 갈수록 앞의 정보를 잊어버리는 문제가 있습니다. 트랜스포머는 전체 문장을 한 번에 처리(병렬화)하여 이 문제를 획기적으로 해결했습니다.",
        "isExam": true
      },
      {
        "id": 31,
        "text": "학습된 모델을 사용하여 새로운 입력에 대한 결과를 생성하는 과정을 무엇이라 하는가?",
        "options": [
          "Training (학습)",
          "Inference (추론)",
          "Backpropagation (역전파)",
          "Tokenization (토큰화)",
          "Optimization (최적화)"
        ],
        "correctIndex": 1,
        "explanation": "모델을 만드는 과정은 학습(Training), 완성된 모델을 실제 서비스에 활용하여 답을 내는 단계는 추론(Inference)입니다.",
        "categoryId": "llm-basics",
        "isExam": true
      },
      {
        "id": 32,
        "text": "모델 생성 시 Temperature 값을 0에 가깝게 설정했을 때의 특징으로 옳은 것은?",
        "options": [
          "답변의 무작위성이 높아져서 매우 창의적인 답변이 생성된다.",
          "확률이 가장 높은 토큰만 선택하여 일관되고 결정론적인 답변을 생성한다.",
          "모델의 연산 과정이 단순화되어 추론 속도가 2배 이상 빨라진다.",
          "입력 가능한 최대 토큰 수(Context Window)가 비약적으로 늘어난다.",
          "사실 여부와 관계없이 사용자의 질문보다 항상 긴 답변을 생성한다."
        ],
        "correctIndex": 1,
        "explanation": "온도가 낮을수록 답변이 보수적이고 사실에 가까워지며, 온도가 높을수록 다양하고 창의적인 답변이 나옵니다.",
        "categoryId": "llm-basics",
        "isExam": true
      },
      {
        "id": 33,
        "text": "LLM의 입력 토큰 수가 모델의 한계(Context Limit)를 초과했을 때 발생하는 문제는?",
        "options": [
          "모델이 부족한 정보를 메우기 위해 자동으로 학습 데이터를 업데이트한다.",
          "입력된 정보 중 앞부분이 잘려나가는 Truncation(잘림) 현상이 발생한다.",
          "답변 생성에 필요한 연산량이 줄어들어 서비스 비용이 0원이 된다.",
          "모델의 파라미터가 실시간으로 최적화되어 지능이 비약적으로 상승한다.",
          "에러 발생 없이 외부 데이터베이스를 참조하여 모든 문맥을 이해한다."
        ],
        "correctIndex": 1,
        "explanation": "컨텍스트 윈도우 한계를 넘어서면 모델은 기억 용량을 초과한 가장 오래된 대화 내용부터 잊어버리게 됩니다.",
        "categoryId": "llm-basics",
        "isExam": true
      },
      {
        "id": 34,
        "text": "별도의 추가 학습 없이 프롬프트에 몇 개의 예시를 넣는 것만으로 모델이 작업을 이해하는 능력은?",
        "options": [
          "Transfer Learning (전이 학습)",
          "Fine-Tuning (미세 조정)",
          "In-Context Learning (문맥 내 학습)",
          "Meta Learning (메타 학습)",
          "Supervised Learning (지도 학습)"
        ],
        "correctIndex": 2,
        "explanation": "가중치 업데이트 없이 프롬프트 내의 예시(Few-shot)만으로 새로운 태스크를 수행하는 LLM의 핵심 능력입니다.",
        "categoryId": "llm-basics",
        "isExam": true
      },
      {
        "id": 35,
        "text": "LLM이 실제 지식이 아니라 확률적으로 그럴듯한 문장만 생성한다는 비판적 용어는?",
        "options": [
          "Smart Agent (지능형 에이전트)",
          "Stochastic Parrot (확률적 앵무새)",
          "Neural Network (신경망 모델)",
          "Turing Machine (튜링 기계)",
          "Digital Oracle (디지털 신탁)"
        ],
        "correctIndex": 1,
        "explanation": "모델이 문장의 의미를 진정으로 이해하는 것이 아니라, 대량의 데이터에서 배운 확률 통계를 바탕으로 답변을 구성한다는 비판입니다.",
        "categoryId": "llm-basics",
        "isExam": true
      }
    ]
  },
  {
    "id": "prompt-engineering",
    "name": "프롬프트 엔지니어링",
    "questions": [
      {
        "id": 1,
        "text": "최근 LLM 모델의 발전으로 인한 프롬프트 엔지니어링의 변화 양상으로 가장 적절한 것은?",
        "options": [
          "모델 성능이 좋아져 프롬프트에 아무런 지시를 하지 않아도 완벽한 답을 한다.",
          "모델이 고도화됨에 따라 정보를 단순 나열하기보다, 원하는 출력 형식을 위해 정보를 요약 및 구조화하는 방향으로 변화했다.",
          "최신 모델은 'Meta Prompting' 학습이 되어 있지 않아 사용자가 모든 규칙을 세세히 정해야 한다.",
          "프롬프트 엔지니어링은 이제 완전히 사라진 기술이다.",
          "과거 모델일수록 복잡한 추론 과정을 스스로 잘 수행했다."
        ],
        "correctIndex": 1,
        "explanation": "최근 모델은 정보를 단순 나열하기보다 사용 목적에 따라 적합한 포맷으로 출력하도록 정보를 요약하고 구조화하는 능력이 향상되었습니다. 또한 LLM 자체가 다양한 프롬프트 작성 방식(Meta Prompting)에 대해 학습되어 있습니다.",
        "isExam": false
      },
      {
        "id": 2,
        "text": "Google Gemini Prompting Guide 101에서 제시한 효과적인 프롬프트의 4가지 요소가 아닌 것은?",
        "options": [
          "Persona (역할 설정)",
          "Task (작업 내용)",
          "Context (참고 정보)",
          "Format (출력 형식)",
          "Temperature (창의성 조절)"
        ],
        "correctIndex": 4,
        "explanation": "교재에서 제시한 Google Gemini의 프롬프트 4요소는 Persona, Task, Context, Format입니다.",
        "isExam": false
      },
      {
        "id": 3,
        "text": "최근 연구(EMNLP 2024 등)에서 밝혀진 '시스템 프롬프트 내 페르소나(Persona)'의 효과에 대한 설명으로 옳은 것은?",
        "options": [
          "모든 상황에서 페르소나를 설정하면 성능이 비약적으로 향상된다.",
          "페르소나는 모델의 추론 능력보다는 답변의 '형식(Format)'이나 '어조'를 맞추는 데 더 유효하다.",
          "페르소나는 이제 전혀 사용할 필요가 없는 기법이다.",
          "특정 직업(예: 변호사, 의사)을 부여하면 해당 도메인의 전문 지식이 없는 모델도 전문가처럼 답변한다.",
          "페르소나는 항상 사용자 프롬프트의 맨 마지막에 위치해야 한다."
        ],
        "correctIndex": 1,
        "explanation": "최근 연구에 따르면 시스템 프롬프트의 페르소나는 지식 기반 성능 향상에 큰 도움을 주지 않으며, 오히려 답변의 형식 차원에서 여전히 유효한 것으로 나타났습니다.",
        "isExam": false
      },
      {
        "id": 4,
        "text": "Few-Shot Prompting을 사용할 때 발생할 수 있는 편향(Bias)이나 주의점으로 적절한 것은?",
        "options": [
          "예시를 많이 줄수록 토큰 사용량이 줄어든다.",
          "예시의 내용뿐만 아니라 길이, 톤, 어휘 등에 모델이 과도하게 영향을 받을 수 있다.",
          "예시는 반드시 1개만 제공해야 한다.",
          "예시를 주면 모델의 창의성이 무한대로 늘어난다.",
          "한국어는 영어보다 토큰 효율이 높으므로 예시를 더 많이 넣어도 비용이 적게 든다."
        ],
        "correctIndex": 1,
        "explanation": "Few-Shot Prompting은 입력된 예시에 몰입된 결과로 편향이 생길 수 있으며, 예시의 특정 방향(길이, 톤 등)에 과도하게 영향을 받을 수 있습니다.",
        "isExam": false
      },
      {
        "id": 5,
        "text": "복잡한 작업을 한 번에 처리하지 않고 여러 단계로 나누어 처리하는 'Prompt Chaining'의 장점으로 옳지 않은 것은?",
        "options": [
          "불필요한 정보를 제거하여 Context 길이를 단축할 수 있다.",
          "토큰 소모를 절감할 수 있다.",
          "이전 단계의 맥락(Context)을 무시하고 매번 새로운 대화를 시작해야 한다.",
          "복잡한 질문을 쪼개어 답변의 정확도를 높일 수 있다.",
          "LLM 사용 효율성을 향상시킨다."
        ],
        "correctIndex": 2,
        "explanation": "Prompt Chaining은 LLM이 이전 맥락을 기억한다는 점을 활용하여 질문을 쪼개 처리하는 방식으로, 맥락을 무시하는 것이 아니라 효율적으로 관리하는 기법입니다.",
        "isExam": false
      },
      {
        "id": 6,
        "text": "LLM의 논리적 추론 능력을 향상시키기 위해, 질문에 바로 답하지 않고 풀이 과정을 출력하도록 유도하는 기법은?",
        "options": [
          "Retrieval Augmented Generation (RAG)",
          "Chain-of-Thought (CoT)",
          "Lexical Search",
          "Few-Shot Prompting",
          "ReAct"
        ],
        "correctIndex": 1,
        "explanation": "CoT(Chain-of-Thought)는 문제 풀이 시 논리적 사고를 단계적으로 유도하여 추론 성능을 높이는 기법입니다.",
        "isExam": false
      },
      {
        "id": 7,
        "text": "예시(Example) 없이 프롬프트에 \"Let's think step by step\"이라는 문구를 추가하여 논리적 추론을 유도하는 방식은?",
        "options": [
          "Few-shot CoT",
          "Zero-shot CoT",
          "Step-Back Prompting",
          "Reflexion",
          "Self-Consistency"
        ],
        "correctIndex": 1,
        "explanation": "Zero-shot CoT는 별도의 예제 없이 \"Let's think step by step\"과 같은 지시어만으로 단계적 추론을 유도합니다.",
        "isExam": false
      },
      {
        "id": 8,
        "text": "'Step-Back Prompting'에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "문제를 더 작은 단위로 쪼개어 순차적으로 해결한다.",
          "답변을 생성하기 전에, 문제의 본질이나 더 큰 개념을 먼저 도출하여 구조를 파악한다.",
          "무조건 답변을 짧게 하도록 강제하는 기법이다.",
          "과거의 기억을 모두 삭제하고 처음부터 다시 시작하는 방식이다.",
          "검색된 문서의 내용을 그대로 복사해서 답변하는 방식이다."
        ],
        "correctIndex": 1,
        "explanation": "Step-Back Prompting은 구체적인 질문에서 한 발 물러나 더 높은 수준의 개념이나 원리를 먼저 파악(Abstraction)한 뒤 답변을 생성하여 정확도를 높이는 기법입니다.",
        "isExam": false
      },
      {
        "id": 9,
        "text": "프롬프트 작성 시 한국어와 영어 사용에 대한 팁으로 올바른 것은?",
        "options": [
          "한국어 특화 모델이 아니면 일반적으로 영어로 지시하는 것이 모델의 이해력과 토큰 효율성 측면에서 유리하다.",
          "모든 모델은 한국어 데이터를 영어보다 더 많이 학습했다.",
          "한국어로 지시할 때 문법 오류나 언어 혼용은 절대 발생하지 않는다.",
          "지시 사항을 영어로 작성하면 답변의 정확도가 항상 떨어진다.",
          "오픈 소스 LLM은 상용 LLM보다 한국어 성능이 항상 뛰어나다."
        ],
        "correctIndex": 0,
        "explanation": "대부분의 모델은 영어 학습량이 압도적이므로 영어 지시 시 이해력과 토큰 효율성이 증가합니다. 한국어 미흡 모델은 문법 오류나 언어 혼용이 발생할 수 있습니다.",
        "isExam": false
      },
      {
        "id": 10,
        "text": "LangChain의 핵심 문법인 LCEL(LangChain Expression Language)에서 구성 요소를 연결하는 연산자는?",
        "options": [
          "+",
          ">>",
          "| (Pipe)",
          "&",
          "->"
        ],
        "correctIndex": 2,
        "explanation": "LCEL은 유닉스 파이프와 유사한 | 연산자를 사용하여 Prompt, LLM, OutputParser 등을 체인으로 연결합니다.",
        "isExam": false
      },
      {
        "id": 11,
        "text": "LangChain의 기본 Chain 구성 순서로 가장 일반적인 것은?",
        "options": [
          "LLM → Prompt → OutputParser",
          "Prompt → OutputParser → LLM",
          "Prompt → LLM → OutputParser",
          "OutputParser → LLM → Prompt",
          "LLM → OutputParser → Prompt"
        ],
        "correctIndex": 2,
        "explanation": "입력 변수를 받아 프롬프트를 구성하고(Prompt), 이를 모델에 전달하여(LLM), 그 결과를 원하는 형식으로 변환(OutputParser)하는 순서가 일반적입니다.",
        "isExam": false
      },
      {
        "id": 12,
        "text": "LangChain에서 LLM의 출력을 문자열(String), JSON, Pydantic 등 원하는 형식으로 변환해주는 모듈은?",
        "options": [
          "Retriever",
          "VectorStore",
          "PromptTemplate",
          "OutputParser",
          "Loader"
        ],
        "correctIndex": 3,
        "explanation": "Parser(OutputParser)는 LLM 뒤에 연결하여 LLM의 텍스트 출력을 구조화된 데이터(JSON 등)나 특정 포맷으로 변환하는 역할을 합니다.",
        "isExam": false
      },
      {
        "id": 13,
        "text": "RAG(Retrieval Augmented Generation) 파이프라인 도입의 주된 목적은?",
        "options": [
          "LLM의 학습 속도를 높이기 위함",
          "LLM이 모르는 정보나 최신 정보를 외부 검색을 통해 보완하여 할루시네이션을 줄이기 위함",
          "프롬프트 작성을 자동화하기 위함",
          "이미지 생성을 가능하게 하기 위함",
          "텍스트를 음성으로 변환하기 위함"
        ],
        "correctIndex": 1,
        "explanation": "RAG는 검색 도구를 추가하여 LLM이 학습하지 않았거나 정확하지 않은 정보에 대해 외부 데이터를 참조해 답변하게 함으로써 할루시네이션을 완화합니다.",
        "isExam": false
      },
      {
        "id": 14,
        "text": "LLM에게 외부 함수나 API를 사용할 수 있는 능력을 부여하는 기능으로, 최근 모델들이 JSON 형식의 스키마를 통해 지원하는 것은?",
        "options": [
          "Fine-tuning",
          "Prompt Chaining",
          "Tool Calling (Function Calling)",
          "Vector Embedding",
          "Zero-shot Learning"
        ],
        "correctIndex": 2,
        "explanation": "Tool Calling(또는 Function Calling)은 LLM이 사용할 수 있는 도구(함수)의 정보를 제공하고, LLM이 필요시 이를 호출하여 작업을 수행하게 하는 기능입니다.",
        "isExam": false
      },
      {
        "id": 15,
        "text": "LLM Agent의 초기 모델인 'ReAct' 프레임워크의 핵심 구성 요소 3가지는?",
        "options": [
          "Thought - Action - Observation",
          "Plan - Execute - Review",
          "Input - Process - Output",
          "Search - Retrieve - Generate",
          "Ask - Answer - Verify"
        ],
        "correctIndex": 0,
        "explanation": "ReAct 에이전트는 생각(Reasoning/Thought) -> 행동(Acting/Action) -> 관찰(Observation)의 과정을 반복하며 문제를 해결합니다.",
        "isExam": false
      },
      {
        "id": 16,
        "text": "에이전트가 작업을 수행하다가 실패했을 때, 실패 원인을 분석하고 이를 바탕으로 재시도하여 성공률을 높이는 기법은?",
        "options": [
          "ReAct",
          "Reflexion",
          "Few-shot",
          "RAG",
          "Prompt Template"
        ],
        "correctIndex": 1,
        "explanation": "Reflexion은 실패 피드백을 기반으로 자기 반성(Self-reflection)을 수행하고, 이 내용을 다음 시도에 반영하여 문제 해결 능력을 높이는 프레임워크입니다.",
        "isExam": false
      },
      {
        "id": 17,
        "text": "Multi-Agent 시스템을 도입했을 때 얻을 수 있는 이점으로 가장 적절한 것은?",
        "options": [
          "에이전트 간 통신 비용이 증가하여 속도가 느려진다.",
          "단일 에이전트가 모든 툴을 관리하므로 구조가 단순해진다.",
          "작업을 세분화하여 개별 전문 에이전트가 처리하므로 Context 관리가 용이하고 Token 낭비를 줄일 수 있다.",
          "LLM의 파라미터 수를 직접 늘릴 수 있다.",
          "할루시네이션이 100% 제거된다."
        ],
        "correctIndex": 2,
        "explanation": "Multi-Agent 시스템은 검색, 개발, 작성 등 역할을 분담하여 필요한 정보만 전달하므로, 단일 에이전트가 모든 맥락을 처리할 때 발생하는 토큰 낭비와 비효율을 줄일 수 있습니다.",
        "isExam": false
      },
      {
        "id": 18,
        "text": "복잡한 문제를 해결하기 위해 여러 개의 에이전트가 협력하는 구조 중, 중앙 관리자(Supervisor)가 작업을 할당하고 조율하는 방식은?",
        "options": [
          "Network 구조",
          "Hierarchical 구조 / Supervisor 구조",
          "Random 구조",
          "Linear 구조",
          "Solo 구조"
        ],
        "correctIndex": 1,
        "explanation": "Supervisor 혹은 Hierarchical 구조는 중앙 제어(Supervisor) 에이전트가 하위 에이전트들을 관리하고 작업을 병렬 실행하거나 조율하는 방식입니다.",
        "isExam": false
      },
      {
        "id": 19,
        "text": "Tool Calling 과정에서 LLM의 역할 변화에 대한 설명으로 옳은 것은?",
        "options": [
          "LLM은 오직 텍스트 생성만 수행하고 도구 사용 여부는 사용자가 결정한다.",
          "과거에는 LLM이 도구를 직접 실행했지만, 최근에는 도구 실행 결과를 받기만 한다.",
          "LLM은 상황을 판단하여 필요한 Tool을 선택하고 인자(Argument)를 생성하는 'Controller' 역할을 한다.",
          "Tool Calling은 LLM의 성능을 저하시키므로 사용하지 않는 것이 좋다.",
          "모든 LLM은 별도의 프롬프트 없이도 자동으로 Tool을 사용할 수 있다."
        ],
        "correctIndex": 2,
        "explanation": "LLM은 텍스트 생성뿐만 아니라 상황을 판단하고, 지시하고, 제어할 수 있는 능력을 통해 외부 Tool을 활용하는 컨트롤 타워 역할을 수행합니다.",
        "isExam": false
      },
      {
        "id": 20,
        "text": "LangGraph에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "LangChain에서 그래프 데이터베이스를 구축하는 도구이다.",
          "에이전트의 흐름을 그래프 구조로 정의하여, 순환(Cycle)이나 상태(State) 관리가 가능한 워크플로우를 만드는 라이브러리이다.",
          "텍스트를 이미지로 변환하는 그래프 모델이다.",
          "RAG 성능을 평가하는 도구이다.",
          "LLM의 비용을 계산해주는 계산기이다."
        ],
        "correctIndex": 1,
        "explanation": "LangGraph는 Multi-Agent나 복잡한 RAG 흐름을 제어하기 위해 상태(State)를 유지하며 순환 및 분기 처리가 가능한 그래프 구조의 워크플로우를 설계하는 도구입니다.",
        "isExam": false
      },
      {
        "id": 21,
        "text": "프롬프트 엔지니어링에서 'Few-Shot'이란 무엇인가?",
        "options": [
          "모델을 새로운 데이터로 처음부터 다시 학습(Training)시키는 것",
          "프롬프트에 문제 해결 예시(Sample)를 몇 가지 함께 제공하는 것",
          "한 번에 오직 하나의 질문만 던져서 답변을 받는 것",
          "모델의 성능을 위해 가장 짧고 간결한 프롬프트를 작성하는 것",
          "답변의 길이를 특정 글자 수 이하로 제한하는 기법"
        ],
        "correctIndex": 1,
        "explanation": "Few-Shot은 모델에게 '질문-답변' 쌍의 예시를 몇 개 보여줌으로써, 모델이 사용자가 원하는 답변의 형식이나 논리를 빠르게 파악하도록 돕는 기법입니다. 예시가 아예 없으면 Zero-Shot, 하나만 있으면 One-Shot이라고 부릅니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "복잡한 수학 문제나 논리 문제를 풀 때, 모델에게 중간 풀이 과정을 생성하도록 유도하여 정확도를 높이는 기법은?",
        "options": [
          "Zero-Shot Prompting",
          "Chain of Thought (CoT, 사고의 사슬)",
          "Random Sampling",
          "Fine-Tuning (미세 조정)",
          "Data Augmentation (데이터 증강)"
        ],
        "correctIndex": 1,
        "explanation": "CoT는 모델이 최종 정답을 내놓기 전에 \"왜 그런 결과가 나왔는지\"에 대한 단계별 추론 과정을 스스로 쓰게 만드는 기법입니다. 이를 통해 복잡한 논리 오류를 줄일 수 있습니다.",
        "isExam": true
      },
      {
        "id": 23,
        "text": "\"Let's think step by step (단계별로 생각해 보자)\"라는 문구를 추가하여 추론 능력을 향상시키는 기법은?",
        "options": [
          "Few-Shot CoT",
          "Zero-Shot CoT",
          "Meta Prompting",
          "RAG (검색 증강 생성)",
          "Iterative Refinement"
        ],
        "correctIndex": 1,
        "explanation": "별도의 예시(Shot)를 주지 않고도 \"단계별로 생각하라\"는 마법의 문구 하나만으로 모델이 논리적 추론을 수행하게 만드는 방식입니다. 예시가 없으므로 'Zero-Shot' CoT에 해당합니다.",
        "isExam": true
      },
      {
        "id": 24,
        "text": "프롬프트의 4대 구성 요소가 아닌 것은?",
        "options": [
          "Persona (모델의 역할 부여)",
          "Task (수행해야 할 구체적 작업)",
          "Context (작업 수행에 필요한 배경 정보나 맥락)",
          "Learning Rate (학습률)",
          "Constraint (답변 시 지켜야 할 제약 사항)"
        ],
        "correctIndex": 3,
        "explanation": "페르소나, 작업, 맥락, 출력 형식(Format) 등이 프롬프트의 주요 구성 요소입니다. 반면 학습률(Learning Rate)은 모델을 '학습'시킬 때 사용하는 하이퍼파라미터이며, 프롬프트 작성 시에는 사용되지 않습니다.",
        "isExam": true
      },
      {
        "id": 25,
        "text": "LLM이 사실이 아닌 정보를 마치 사실인 것처럼 그럴싸하게 답변하는 현상은?",
        "options": [
          "Overfitting (과적합)",
          "Hallucination (환각)",
          "Vanishing Gradient (기울기 소실)",
          "Tokenization (토큰화)",
          "Data Leakage (데이터 유출)"
        ],
        "correctIndex": 1,
        "explanation": "환각 현상은 모델이 학습 데이터에 없는 내용을 지어내거나, 확률적으로 그럴듯한 단어를 이어 붙이다가 사실 관계를 틀리는 현상을 말합니다.",
        "isExam": true
      },
      {
        "id": 26,
        "text": "복잡한 작업을 한 번에 처리하지 않고, 여러 단계의 프롬프트로 나누어 순차적으로 처리하는 기법은?",
        "options": [
          "Prompt Chaining (프롬프트 체이닝)",
          "Batch Processing (배치 처리)",
          "Fine-Tuning (미세 조정)",
          "Vectorization (벡터화)",
          "Negative Prompting"
        ],
        "correctIndex": 0,
        "explanation": "하나의 큰 프롬프트에 모든 요구사항을 넣으면 모델이 혼란을 겪을 수 있습니다. 이를 단계별(예: 요약 -> 번역 -> 검토)로 쪼개어 앞 단계의 결과물을 다음 단계의 입력으로 사용하는 방식을 체이닝이라고 합니다.",
        "isExam": true
      },
      {
        "id": 27,
        "text": "Step-Back Prompting의 핵심 개념은?",
        "options": [
          "질문을 최대한 짧고 간결하게 줄여서 전달한다.",
          "구체적인 답을 바로 요구하기 전에, 관련된 상위 개념이나 일반적인 원리를 먼저 질문한다.",
          "모델이 틀린 답을 했을 때 한 단계 이전 질문으로 돌아간다.",
          "답변을 영어로 번역한 후 다시 한국어로 번역하여 정확도를 높인다.",
          "모델의 답변을 무조건 한 번 거절하여 재검토하게 한다."
        ],
        "correctIndex": 1,
        "explanation": "'한 걸음 물러나기(Step-Back)' 기법은 구체적인 문제에 매몰되지 않도록 모델에게 관련 원칙이나 상위 개념을 먼저 상기시킨 후 문제를 풀게 하여 실수를 줄이는 고도화된 기법입니다.",
        "isExam": true
      },
      {
        "id": 28,
        "text": "다음 중 프롬프트 작성 팁으로 적절하지 않은 것은?",
        "options": [
          "지시 사항을 명확하고 구체적이며 단정적으로 작성한다.",
          "표, 리스트, JSON 등 원하는 출력 형식을 명시해 준다.",
          "모델이 창의력을 발휘하도록 모호하고 추상적인 표현을 최대한 많이 사용한다.",
          "필요한 경우 \"너는 전문 마케터야\"와 같은 역할(Persona)을 부여한다.",
          "답변에 포함되지 말아야 할 '부정적 제약 조건'을 명시한다."
        ],
        "correctIndex": 2,
        "explanation": "프롬프트가 모호할수록 모델은 사용자의 의도를 파악하지 못해 엉뚱한 답을 내놓을 확률이 높습니다. 의도가 명확할수록 결과물의 품질이 안정적입니다.",
        "isExam": true
      },
      {
        "id": 29,
        "text": "LangChain에서 프롬프트 템플릿(Prompt Template)을 사용하는 주요 이유는?",
        "options": [
          "프롬프트 구조를 정형화하여 재사용성을 높이고 변수 입력 처리를 자동화하기 위해",
          "모델 내부의 가중치를 직접 수정하여 학습 속도를 높이기 위해",
          "인터넷 연결이 없는 오프라인 환경에서 LLM을 구동하기 위해",
          "파이썬 문법을 사용하지 않고 영어로만 코딩하기 위해",
          "모델의 토큰 사용량을 강제로 0으로 만들기 위해"
        ],
        "correctIndex": 0,
        "explanation": "템플릿을 사용하면 고정된 지시문 안에 사용자 입력값(변수)만 갈아 끼우며 대량의 작업을 효율적으로 처리할 수 있어 개발 생산성이 향상됩니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "최근 LLM 모델들이 시스템 프롬프트의 'Persona(역할 부여)' 없이도 성능이 잘 나오는 이유는?",
        "options": [
          "모델 자체가 대규모 지시사항 학습(Instruction Tuning)을 통해 범용적인 수행 능력을 갖췄기 때문",
          "최신 모델에서는 역할 부여 기능이 시스템적으로 차단되었기 때문",
          "프롬프트의 길이가 일정 수준보다 길어지면 모델이 인식을 못 하기 때문",
          "역할 부여는 애초에 심리적 효과일 뿐 기술적 효과가 없었기 때문",
          "사용자가 역할을 부여하는 대신 AI가 사용자에게 역할을 부여하는 시대가 되었기 때문"
        ],
        "correctIndex": 0,
        "explanation": "최신 모델들은 수많은 프롬프트와 역할 예시를 통해 이미 충분히 학습(Meta-learning/Instruction-tuning)되었기 때문에, 아주 복잡한 역할 설정이 없어도 문맥만으로 사용자의 의도를 충분히 파악할 수 있을 만큼 영리해졌습니다.",
        "isExam": true
      },
      {
        "id": 31,
        "text": "시스템 프롬프트(System Prompt)의 주된 역할로 가장 적절한 것은?",
        "options": [
          "사용자가 질문을 던질 때마다 매번 본문에 포함해야 하는 핵심 명령어이다.",
          "모델의 전반적인 페르소나, 태도, 규칙을 설정하는 최상위 운영 지침이다.",
          "답변 생성 시간을 측정하여 모델의 추론 속도를 조절하는 타이머 역할을 한다.",
          "답변의 최대 글자 수를 하드웨어 수준에서 강제로 제한하는 기능만 수행한다.",
          "모델이 외부 인터넷 API에 접속하여 정보를 검색하게 만드는 유일한 통로이다."
        ],
        "correctIndex": 1,
        "explanation": "대화의 규칙이나 성격(예: \"너는 친절한 마케터야\")을 정의하여 모델의 행동 양식을 결정하는 바탕이 됩니다.",
        "categoryId": "prompt-engineering",
        "isExam": true
      },
      {
        "id": 32,
        "text": "프롬프트가 모델의 시스템 설정이나 학습 데이터 내 기밀 정보를 내뱉도록 유도하는 공격은?",
        "options": [
          "Prompt Injection (프롬프트 주입)",
          "Prompt Leakage (프롬프트 유출)",
          "Hallucination (환각 현상)",
          "Data Cleaning (데이터 정제)",
          "Prompt Chaining (프롬프트 체이닝)"
        ],
        "correctIndex": 1,
        "explanation": "Injection이 모델의 동작을 조종하는 것이 목적이라면, Leakage는 숨겨진 지침이나 데이터를 탈취하는 데 초점이 맞춰져 있습니다.",
        "categoryId": "prompt-engineering",
        "isExam": true
      },
      {
        "id": 33,
        "text": "복잡한 문제를 해결하기 위해 동일한 질문을 여러 번 던져 다수결로 답을 정하는 기법은?",
        "options": [
          "Tree of Thoughts (사고의 트리)",
          "Self-Consistency (자기 일관성)",
          "ReAct (실행 및 추론)",
          "Zero-shot (무예시 프롬프팅)",
          "Reframing (관점 재설정)"
        ],
        "correctIndex": 1,
        "explanation": "여러 번의 추론 경로를 거쳐 가장 일관되게 도출된 답을 선택함으로써 최종 답변의 신뢰도를 높입니다.",
        "categoryId": "prompt-engineering",
        "isExam": true
      },
      {
        "id": 34,
        "text": "긴 대화로 토큰이 부족할 때 이전 대화 내용을 핵심적으로 요약하여 프롬프트에 넣는 기법은?",
        "options": [
          "Sliding Window (슬라이딩 윈도우)",
          "Conversation Summary (대화 요약)",
          "Prompt Deletion (프롬프트 삭제)",
          "Context Extension (문맥 확장)",
          "Vector Storage (벡터 저장)"
        ],
        "correctIndex": 1,
        "explanation": "과거의 대화 기록을 압축하여 중요한 맥락만 보존함으로써 토큰 사용량을 효율적으로 관리합니다.",
        "categoryId": "prompt-engineering",
        "isExam": true
      },
      {
        "id": 35,
        "text": "모델에 설정된 윤리적/안전 제한(Safety Filter)을 우회하여 답변을 받아내는 행위는?",
        "options": [
          "Reframing (재구성)",
          "Jailbreaking (탈옥)",
          "Tuning (조정)",
          "Padding (패딩)",
          "Masking (마스킹)"
        ],
        "correctIndex": 1,
        "explanation": "악의적인 프롬프트 설계를 통해 모델에 걸린 가드레일을 뚫고 부적절한 답변을 유도하는 시도입니다.",
        "categoryId": "prompt-engineering",
        "isExam": true
      }
    ]
  },
  {
    "id": "rag-agent",
    "name": "RAG Agent",
    "questions": [
      {
        "id": 1,
        "text": "LLM(Large Language Model)이 가진 한계점 중, RAG를 통해 해결하고자 하는 주된 문제는 무엇인가요?",
        "options": [
          "모델의 추론 속도가 너무 느리다.",
          "한국어 처리 능력이 떨어진다.",
          "학습 데이터 시점 이후의 최신 정보나 내부 데이터에 대해 답변하지 못하거나 환각(Hallucination)을 일으킨다.",
          "텍스트를 이미지로 변환하는 기능이 없다.",
          "문법적으로 올바른 문장을 생성하지 못한다."
        ],
        "correctIndex": 2,
        "explanation": "LLM은 Knowledge cutoff(지식 단절 시점)가 존재하여 최신 정보나 도메인 특화 데이터(내부 데이터)에 대해서는 성능을 내기 어렵거나 환각 현상이 발생합니다. RAG는 이를 보완하기 위해 외부 정보를 검색하여 제공합니다.",
        "isExam": false
      },
      {
        "id": 2,
        "text": "RAG(검색 증강 생성)와 파인 튜닝(Fine-tuning)의 가장 큰 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          "파인 튜닝은 외부 DB를 활용하고, RAG는 모델 파라미터를 변경한다.",
          "RAG는 모델의 파라미터를 업데이트하지 않고 프롬프트에 문맥(Context)을 추가하여 답변을 생성한다.",
          "파인 튜닝은 데이터 변경 시 재학습이 필요 없지만, RAG는 재학습이 필수적이다.",
          "RAG는 지식을 모델 내부에 저장하고, 파인 튜닝은 지식을 외부에 저장한다.",
          "비용 면에서 파인 튜닝이 RAG보다 항상 저렴하고 빠르다."
        ],
        "correctIndex": 1,
        "explanation": "파인 튜닝은 모델 파라미터를 변경하여 지식을 학습시키는 반면, RAG는 In-Context Learning을 통해 프롬프트에 해당 정보가 있을 때만 적용되므로 모델 학습(파라미터 변경)에는 해당하지 않습니다.",
        "isExam": false
      },
      {
        "id": 3,
        "text": "RAG 파이프라인의 일반적인 5단계 프로세스 순서로 올바른 것은?",
        "options": [
          "Indexing -> Searching -> Processing -> Augmenting -> Generating",
          "Processing -> Indexing -> Searching -> Augmenting -> Generating",
          "Indexing -> Processing -> Searching -> Augmenting -> Generating",
          "Searching -> Indexing -> Processing -> Generating -> Augmenting",
          "Indexing -> Augmenting -> Processing -> Searching -> Generating"
        ],
        "correctIndex": 2,
        "explanation": "RAG의 단계별 개념은 DB를 구성하는 Indexing, 질의를 전처리하는 Processing, 적합한 데이터를 찾는 Searching, 프롬프트를 생성하는 Augmenting, 답변을 생성하는 Generating 순서로 진행됩니다.",
        "isExam": false
      },
      {
        "id": 4,
        "text": "RAG를 위한 데이터 준비 과정인 '청킹(Chunking)'을 수행하는 가장 주된 이유는?",
        "options": [
          "데이터베이스 용량을 늘리기 위해",
          "LLM의 Context 길이 제한(Input limitation)과 검색의 정확도를 높이기 위해",
          "원본 데이터를 암호화하기 위해",
          "텍스트를 이미지로 변환하기 위해",
          "모든 문서를 하나의 거대한 텍스트로 합치기 위해"
        ],
        "correctIndex": 1,
        "explanation": "LLM 모델마다 Context 길이 지원 범위가 다르고, 긴 Context를 처리하는 능력에 한계가 있으므로 전체 문서를 입력하는 대신 의미 있는 단위(청크)로 잘라서 입력해야 합니다.",
        "isExam": false
      },
      {
        "id": 5,
        "text": "청킹(Chunking) 과정에서 '오버랩(Overlap)'을 설정하는 이유는 무엇인가요?",
        "options": [
          "저장 공간을 절약하기 위해",
          "청크가 나뉘는 경계에서 문맥(Context)이나 의미가 단절되는 것을 방지하기 위해",
          "검색 속도를 늦추기 위해",
          "LLM이 같은 문장을 반복해서 말하게 하기 위해",
          "청크의 총 개수를 줄이기 위해"
        ],
        "correctIndex": 1,
        "explanation": "문장이 중간에서 잘리면 의미를 이해하기 어려우므로, 청크 간에 일정 부분(일반적으로 10~20%)을 겹치게 하여 연결 시 의미를 보존합니다.",
        "isExam": false
      },
      {
        "id": 6,
        "text": "긴 문맥(Long Context)을 가진 최신 LLM 모델들이 등장했음에도 불구하고, 여전히 RAG와 청킹이 유효한 이유는?",
        "options": [
          "최신 모델은 긴 문맥을 전혀 처리하지 못하기 때문이다.",
          "긴 문맥의 중간 부분에 위치한 정보를 잘 찾지 못하는 'Lost in the Middle' 현상과 비용 효율성 때문이다.",
          "RAG를 사용하면 모델의 파라미터가 자동으로 업데이트되기 때문이다.",
          "청킹을 하지 않으면 벡터 DB에 저장이 불가능하기 때문이다.",
          "짧은 문맥 모델이 긴 문맥 모델보다 항상 성능이 좋기 때문이다."
        ],
        "correctIndex": 1,
        "explanation": "최신 모델(GPT-4, Gemini 등)은 Context 길이가 확장되었지만, 전체 문서를 다 넣으면 중간 정보를 놓치는 현상(Lost in the Middle)이 발생하거나 처리 비용이 증가하므로 효과적인 정보 추출이 필요합니다.",
        "isExam": false
      },
      {
        "id": 7,
        "text": "사용자의 질문이 지나치게 짧거나 모호할 때(예: \"TV가 안 나와요\"), Processing 단계에서 수행해야 할 적절한 조치는?",
        "options": [
          "질문을 무시하고 아무 답변이나 생성한다.",
          "이전 대화 내역을 바탕으로 질문을 구체화하거나 의도를 파악한다.",
          "질문을 그대로 벡터 DB에 검색한다.",
          "질문의 길이를 강제로 100자 이상으로 늘린다.",
          "검색 단계를 건너뛰고 바로 답변을 생성한다."
        ],
        "correctIndex": 1,
        "explanation": "지나치게 짧은 쿼리는 의미 이해를 위한 정보가 불충분하므로, 이전 대화 내역을 고려하여 맥락화하거나 의도를 파악하는 전처리가 필요합니다.",
        "isExam": false
      },
      {
        "id": 8,
        "text": "'Semantic Search(시멘틱 검색)'에 대한 설명으로 옳은 것은?",
        "options": [
          "키워드가 정확히 일치해야만 검색된다.",
          "BM25 알고리즘이 대표적인 예이다.",
          "텍스트를 임베딩 벡터로 변환하여 벡터 간의 의미적 유사도를 비교한다.",
          "문장의 길이만을 기준으로 정렬한다.",
          "SQL 쿼리문을 사용하여 DB를 검색한다."
        ],
        "correctIndex": 2,
        "explanation": "Semantic Search는 Transformer 기반 방식으로 텍스트를 벡터화하고, 표면적 일치가 아닌 의미적 유사성을 기반으로 탐색합니다.",
        "isExam": false
      },
      {
        "id": 9,
        "text": "벡터 DB에서 두 벡터 간의 유사도를 측정하는 지표 중, 1에서 코사인 유사도(Cosine Similarity)를 뺀 값으로, 방향성의 차이를 나타내는 것은?",
        "options": [
          "Euclidean Distance",
          "Dot Product",
          "Cosine Distance",
          "Manhattan Distance",
          "Jaccard Similarity"
        ],
        "correctIndex": 2,
        "explanation": "Cosine Distance는 \"1 - Cosine Similarity\" 로 계산되며, 두 벡터가 이루는 각도를 기반으로 거리를 측정합니다.",
        "isExam": false
      },
      {
        "id": 10,
        "text": "검색 결과의 다양성을 확보하기 위해, 가장 유사한 문서를 찾은 뒤 그와 비슷하지만 조금 떨어진(덜 유사한) 문서를 함께 선택하는 기법은?",
        "options": [
          "HNSW",
          "MMR (Maximal Marginal Relevance)",
          "Exact Match",
          "Random Sampling",
          "Inverted Index"
        ],
        "correctIndex": 1,
        "explanation": "MMR은 다양성을 고려한 방법으로, 쿼리와 가장 가까운 Chunk를 찾은 뒤 넓게 검색하여 중복된 정보만 나오는 것을 방지합니다.",
        "isExam": false
      },
      {
        "id": 11,
        "text": "Bi-Encoder와 Cross-Encoder에 대한 설명으로 올바른 것은?",
        "options": [
          "Bi-Encoder는 계산량이 많아 속도가 매우 느리다.",
          "Cross-Encoder는 두 문장을 각각 벡터로 만든 후 비교한다.",
          "Bi-Encoder는 문장을 미리 벡터로 변환해 둘 수 있어 대규모 검색에 유리하다.",
          "Cross-Encoder는 성능이 낮아 거의 사용되지 않는다.",
          "최신 RAG에서는 오직 Bi-Encoder만 사용한다."
        ],
        "correctIndex": 2,
        "explanation": "Bi-Encoder(예: SentenceBERT)는 각각의 질문/문서를 벡터로 생성해두고 비교하므로 대규모 데이터 처리가 빠릅니다. 반면 Cross-Encoder는 두 문장을 합쳐서 입력하므로 정확도는 높으나 계산량이 많아 1차 검색보다는 2차 Reranking에 주로 쓰입니다.",
        "isExam": false
      },
      {
        "id": 12,
        "text": "대규모 벡터 DB에서 모든 벡터를 1:1로 비교하는 것은 시간이 오래 걸리므로, 근사치를 이용하여 빠르게 검색하는 알고리즘을 통칭하는 용어는?",
        "options": [
          "SQL",
          "ANN (Approximate Nearest Neighbors)",
          "DFS (Depth First Search)",
          "BFS (Breadth First Search)",
          "RNN (Recurrent Neural Network)"
        ],
        "correctIndex": 1,
        "explanation": "다수의 질문을 처리할 때 모든 벡터를 계산하면 병목이 발생하므로, 검색 공간을 분할하거나 압축하여 근사값을 찾는 ANN(HNSW, ANNOY 등) 기법을 사용합니다.",
        "isExam": false
      },
      {
        "id": 13,
        "text": "'Small2Big' 전략(Parent Document Retriever)의 핵심 아이디어는 무엇인가요?",
        "options": [
          "검색은 큰 단위(Big Chunk)로 하고, LLM에게는 작은 단위(Small Chunk)를 준다.",
          "검색은 작은 단위(Small Chunk)로 정밀하게 수행하고, LLM에게는 그 주변 정보를 포함한 큰 단위(Parent Chunk)를 제공한다.",
          "검색과 생성 모두 가장 작은 단위로 수행한다.",
          "문서를 청킹하지 않고 전체를 통째로 검색한다.",
          "검색된 정보의 순서를 무작위로 섞어서 제공한다."
        ],
        "correctIndex": 1,
        "explanation": "Small Chunk는 정확한 검색에 유리하지만 맥락이 부족할 수 있으므로, 검색은 Small Chunk로 하되 실제 LLM에게 전달하는 Context는 원본이나 더 큰 Parent Chunk를 사용하여 문맥을 보강합니다.",
        "isExam": false
      },
      {
        "id": 14,
        "text": "청킹할 때, 각 청크에 문서의 요약이나 메타데이터를 덧붙여 임베딩하는 기법은?",
        "options": [
          "Contextual Retrieval",
          "Random Chunking",
          "Keyword Extraction",
          "Stopword Removal",
          "Character Splitting"
        ],
        "correctIndex": 0,
        "explanation": "청크에 헤더나 요약 정보를 추가(Chunk 강화)하여 검색 정확도를 높이는 것이 Contextual Retrieval입니다.",
        "isExam": false
      },
      {
        "id": 15,
        "text": "사용자의 질문에 대해 LLM이 가상의 답변을 생성하고, 이를 기반으로 실제 DB에서 유사 문서를 검색하는 방식은?",
        "options": [
"MMR (Maximal Marginal Relevance)",
          "ReAct (Reasoning and Acting)",
          "HyDE (Hypothetical Document Embedding)",
          "Self-Consistency (Voting Strategy)",
          "CoT (Chain-of-Thought)"
        ],
        "correctIndex": 2,
        "explanation": "HyDE는 질문에 대해 LLM이 답변이나 관련 문서를 생성하게 한 뒤, 그 텍스트를 임베딩하여 실제 문서와의 유사도를 비교합니다.",
        "isExam": false
      },
      {
        "id": 16,
        "text": "하나의 질문을 다양한 관점의 여러 질문으로 변환하여(Multi-Querying) 검색 확률을 높이는 기법은?",
        "options": [
          "Query Reformulation",
          "Query Deletion",
          "Query Compression",
          "Exact Match Search",
          "Vector Normalization"
        ],
        "correctIndex": 0,
        "explanation": "Query Reformulation은 질문을 여러 구체적인 형태로 재구성해 다각도로 검색함으로써 성능을 높입니다.",
        "isExam": false
      },
      {
        "id": 17,
        "text": "'Hybrid Search'는 어떤 두 가지 검색 방식을 결합하는 것을 의미하나요?",
        "options": [
          "Google 검색 + Naver 검색",
          "Lexical Search + Semantic Search",
          "Image Search + Text Search",
          "SQL Search + NoSQL Search",
          "Manual Search + Auto Search"
        ],
        "correctIndex": 1,
        "explanation": "키워드 기반 Sparse Vector와 임베딩 기반 Dense Vector 검색 결과를 결합하여 상호 보완적인 결과를 얻습니다.",
        "isExam": false
      },
      {
        "id": 18,
        "text": "1차로 검색된 문서들을 대상으로, 질문과의 관련성을 다시 정밀하게 평가하여 순서를 재배치하는 과정을 무엇이라고 하나요?",
        "options": [
          "Pre-training",
          "Quantization",
          "Reranking",
          "Chunking",
          "Indexing"
        ],
        "correctIndex": 2,
        "explanation": "Reranker는 Retriever가 찾아온 후보군 중에서 질문과 실제 관련이 있는 것을 찾아 순위를 재조정하는 2차 작업입니다.",
        "isExam": false
      },
      {
        "id": 19,
        "text": "RAG 성능 고도화 중 'Reordering'이 필요한 이유와 관련 있는 현상은?",
        "options": [
          "Hallucination (환각)",
          "Lost in the Middle (중간 내용 간과)",
          "Overfitting (과적합)",
          "Vanishing Gradient (기울기 소실)",
          "Token Limit (토큰 제한)"
        ],
        "correctIndex": 1,
        "explanation": "LLM은 긴 Context가 주어졌을 때 앞부분과 뒷부분에 더 많은 관심을 갖고 중간 내용을 놓치는 경향이 있어, 중요 정보를 양끝에 배치하는 등의 Reordering이 유용합니다.",
        "isExam": false
      },
      {
        "id": 20,
        "text": "PDF 문서 내의 텍스트뿐만 아니라 이미지, 표 등을 인식하고 파싱하여 RAG에 활용하기 위해 사용하는 도구로, IBM에서 만든 오픈소스 소프트웨어는?",
        "options": [
          "Pandas",
          "Docling",
          "OpenCV",
          "Tesseract",
          "Adobe Acrobat"
        ],
        "correctIndex": 1,
        "explanation": "Docling은 PDF, PPT, DOC, HTML 등에서 텍스트뿐 아니라 이미지와 테이블까지 파싱해 적절히 처리할 수 있게 돕는 도구입니다.",
        "isExam": false
      },
      {
        "id": 21,
        "text": "RAG(Retrieval-Augmented Generation)를 사용하는 주된 목적 두 가지는?",
        "options": [
          "모델의 학습 속도 향상 및 이미지 생성 능력 강화",
          "할루시네이션(환각) 완화 및 최신/내부 데이터 활용",
          "번역 성능의 의도적 저하 및 토큰 사용량의 극대화",
          "파이썬 코드의 자동 실행 및 서버 내 데이터 강제 삭제",
          "사용자 인터페이스(UI) 디자인 자동화 및 네트워크 속도 개선"
        ],
        "correctIndex": 1,
        "explanation": "RAG는 모델이 학습하지 않은 최신 정보나 기업 내부 데이터를 '검색'해서 프롬프트에 넣어줌으로써, 모르는 것을 아는 척하는 '환각 현상'을 줄이고 답변의 정확도를 높이는 데 사용됩니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "텍스트를 벡터(숫자 배열)로 변환하여 의미적 유사성을 기반으로 검색하는 방식은?",
        "options": [
          "Lexical Search (키워드 기반 검색)",
          "Semantic Search (시맨틱 검색)",
          "Binary Search (이진 검색)",
          "SQL Query (구조화 질의)",
          "Random Access (임의 접근)"
        ],
        "correctIndex": 1,
        "explanation": "시맨틱 검색은 단어의 철자가 달라도 의미가 비슷하면(예: '강아지'와 '댕댕이') 벡터 공간상에서 가깝게 위치한다는 점을 이용해 검색 결과의 품질을 높입니다.",
        "isExam": true
      },
      {
        "id": 23,
        "text": "RAG 파이프라인에서 긴 문서를 모델이 처리하기 좋은 작은 단위로 나누는 과정을 무엇이라 하는가?",
        "options": [
          "Embedding (임베딩)",
          "Chunking (청킹)",
          "Training (학습)",
          "Decoding (디코딩)",
          "Fine-tuning (미세 조정)"
        ],
        "correctIndex": 1,
        "explanation": "LLM은 한 번에 처리할 수 있는 토큰 수에 제한이 있습니다. 따라서 방대한 문서를 의미 있는 단위(단락, 문장 등)로 쪼개는 '청킹' 작업이 필수적입니다.",
        "isExam": true
      },
      {
        "id": 24,
        "text": "다음 중 벡터 데이터베이스(Vector DB)가 아닌 것은?",
        "options": [
          "Pinecone",
          "Chroma",
          "Milvus",
          "MySQL",
          "Weaviate"
        ],
        "correctIndex": 3,
        "explanation": "Pinecone, Chroma, Milvus 등은 고차원 벡터의 유사도 계산에 최적화된 DB입니다. MySQL은 대표적인 관계형 DB(RDBMS)이며, 벡터 검색을 위해서는 별도의 확장 기능(pgvector 등)을 사용해야 합니다.",
        "isExam": true
      },
      {
        "id": 25,
        "text": "키워드가 정확히 일치하는 문서를 찾는 데 유리한 검색 방식은? (예: 특정 사번, 제품 코드 검색)",
        "options": [
          "Semantic Search",
          "Vector Search",
          "Lexical Search",
          "Neural Search",
          "Multi-modal Search"
        ],
        "correctIndex": 2,
        "explanation": "의미적 유사성이 중요한 경우 시맨틱 검색이 좋지만, 사번이나 고유 코드처럼 '토씨 하나 안 틀리고 똑같은' 데이터를 찾을 때는 전통적인 키워드 기반 검색(BM25 등)이 훨씬 정확합니다.",
        "isExam": true
      },
      {
        "id": 26,
        "text": "Bi-Encoder 방식의 장점은?",
        "options": [
          "두 문장의 관계를 모델이 실시간으로 비교하여 가장 정밀하다.",
          "문서를 미리 벡터화(임베딩)해 둘 수 있어 검색 속도가 매우 빠르다.",
          "별도의 학습 데이터 없이도 모든 언어에서 완벽하게 작동한다.",
          "텍스트 생성 성능이 GPT-4보다 우월하다.",
          "하드웨어 사양에 관계없이 항상 동일한 속도를 보장한다."
        ],
        "correctIndex": 1,
        "explanation": "Bi-Encoder는 문서들을 미리 벡터로 만들어 DB에 저장해 둘 수 있습니다. 사용자의 질문이 들어오면 질문만 벡터로 만들어 거리 계산만 하면 되므로, 대규모 데이터 검색에 매우 유리합니다. ",
        "isExam": true
      },
      {
        "id": 27,
        "text": "검색된 문서들 중 질문과 가장 관련성이 높은 문서를 다시 정밀하게 순위를 매기는 과정은?",
        "options": [
          "Pre-training (사전 학습)",
          "Fine-tuning (미세 조정)",
          "Reranking (재순위화)",
          "Indexing (인덱싱)",
          "Distillation (지식 증류)"
        ],
        "correctIndex": 2,
        "explanation": "가벼운 모델(Bi-Encoder)로 후보군을 빠르게 뽑은 뒤, 무겁지만 정확한 모델(Cross-Encoder)을 사용하여 최종 순위를 다시 매기는 과정을 Reranking이라고 하며, RAG 성능 향상의 핵심 단계입니다.",
        "isExam": true
      },
      {
        "id": 28,
        "text": "청킹(Chunking) 시 인접한 청크 간에 내용을 일부 겹치게 하여 문맥 단절을 방지하는 기법은?",
        "options": [
          "Chunk Overlap",
          "Padding",
          "Masking",
          "Dropout",
          "Attention Mask"
        ],
        "correctIndex": 0,
        "explanation": "문서를 자를 때 경계 부분에서 문맥이 끊기는 것을 막기 위해, 이전 청크의 끝부분을 다음 청크의 시작 부분에 포함시키는 기법을 '오버랩'이라고 합니다.",
        "isExam": true
      },
      {
        "id": 29,
        "text": "LLM이 학습하지 않은 최신 정보를 답변하게 하려면 어떤 기술이 가장 적합한가?",
        "options": [
          "Zero-shot Prompting",
          "RAG (검색 증강 생성)",
          "모델 경량화 (Quantization)",
          "데이터 삭제 (Pruning)",
          "하이퍼파라미터 튜닝"
        ],
        "correctIndex": 1,
        "explanation": "모델 자체를 매번 다시 학습시키는 것은 비용이 너무 많이 듭니다. RAG는 외부 검색 엔진이나 DB에서 최신 정보를 긁어와 모델에게 전달하므로 가장 효율적입니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "다음 중 RAG 시스템 구축 시 'Indexing' 단계에 해당하는 작업은?",
        "options": [
          "사용자의 질문 의도를 파악하고 분석한다.",
          "외부 데이터를 로드하고, 청킹 및 임베딩하여 벡터 DB에 저장한다.",
          "LLM이 검색된 문서를 바탕으로 최종 답변을 생성한다.",
          "프롬프트의 페르소나를 설정한다.",
          "모델의 가중치를 업데이트한다."
        ],
        "correctIndex": 1,
        "explanation": "인덱싱은 답변을 하기 전, 검색 대상이 되는 데이터들을 '찾기 쉬운 상태'로 만들어 DB에 차곡차곡 쌓아두는 준비 과정을 말합니다.",
        "isExam": true
      },
      {
        "id": 31,
        "text": "벡터 DB 검색 시 날짜나 카테고리를 활용해 검색 범위를 미리 필터링하는 기술은?",
        "options": [
          "Embedding (임베딩)",
          "Metadata Filtering (메타데이터 필터링)",
          "Normalization (정규화)",
          "Chunking (청킹)",
          "Reranking (재순위화)"
        ],
        "correctIndex": 1,
        "explanation": "의미적 유사도뿐만 아니라 '최신순', '특정 카테고리' 등 메타데이터 조건을 걸어 검색 결과의 정확도를 높입니다.",
        "categoryId": "rag-agent",
        "isExam": true
      },
      {
        "id": 32,
        "text": "작은 청크로 정확하게 검색하고, 모델에게는 더 넓은 맥락을 제공하기 위해 상위 문서를 전달하는 방식은?",
        "options": [
          "Hybrid Search (하이브리드 검색)",
          "Parent Document Retriever (부모 문서 검색)",
          "Multi-Query Retriever (다중 질의 검색)",
          "Exact Match Search (정확 일치 검색)",
          "Random Sampling (무작위 추출)"
        ],
        "correctIndex": 1,
        "explanation": "검색은 작은 단위(Small Chunk)로 세밀하게 수행하되, 답변 생성 시에는 문맥이 풍부한 큰 단위(Parent Chunk)를 제공하는 전략입니다.",
        "categoryId": "rag-agent",
        "isExam": true
      },
      {
        "id": 33,
        "text": "에이전트가 생각(Thought), 행동(Action), 관찰(Observation)을 반복하며 문제를 푸는 패턴은?",
        "options": [
          "ReAct (추론 및 실행)",
          "Chain of Thought (사고의 사슬)",
          "Few-shot (소수 예시 학습)",
          "Map-Reduce (맵 리듀스)",
          "Refine (답변 개선)"
        ],
        "correctIndex": 0,
        "explanation": "도구(Tool)를 사용하여 외부 지식을 가져오고 그 결과를 다시 추론에 반영하는 자율 에이전트의 기본 구조입니다.",
        "categoryId": "rag-agent",
        "isExam": true
      },
      {
        "id": 34,
        "text": "RAG 시스템에서 'Latency(지연 시간)'를 유발하는 요소 중 사용자가 직접 통제할 수 없는 것은?",
        "options": [
          "데이터 인덱싱 시 설정한 청크의 크기",
          "검색 단계에서 가져올 결과 문서의 개수",
          "사용 중인 LLM API 모델의 자체 생성 속도",
          "사용자가 입력한 프롬프트 및 질문의 길이",
          "사용자가 답변을 받기 위해 기다리는 시간"
        ],
        "correctIndex": 2,
        "explanation": "모델의 연산 속도나 서버 부하로 인한 지연은 하드웨어나 모델 제공업체의 영역입니다.",
        "categoryId": "rag-agent",
        "isExam": true
      },
      {
        "id": 35,
        "text": "RAG를 도입해도 근본적으로 해결하기 어려운 모델의 고유 한계는?",
        "options": [
          "학습 데이터 시점 이후의 최신 지식 부재",
          "기업 내부용 비공개 보안 문서에 대한 접근 불가",
          "모델 자체의 논리적 추론 및 사고 능력 부족",
          "사실과 다른 답변을 내놓는 Hallucination(환각)",
          "답변의 말투나 종결 어미 등 페르소나 조정"
        ],
        "correctIndex": 2,
        "explanation": "RAG는 '참조 지식'을 넣어줄 뿐, 모델이 가진 논리력이나 지능 자체를 개선하지는 못합니다.",
        "categoryId": "rag-agent",
        "isExam": true
      }
    ]
  },
  {
    "id": "fine-tuning",
    "name": "Fine Tuning",
    "questions": [
      {
        "id": 1,
        "text": "LLM의 학습 과정 중, 이미 만들어진 모델(Pretrained Model)에 목적에 맞는 데이터를 추가로 학습시켜 성능을 향상시키는 과정은?",
        "options": [
          "Pretraining (사전 학습)",
          "Fine Tuning (파인 튜닝)",
          "Tokenization (토큰화)",
          "Prompt Engineering (프롬프트 엔지니어링)",
          "RAG (검색 증강 생성)"
        ],
        "correctIndex": 1,
        "explanation": "Fine Tuning은 이미 방대한 데이터로 학습된 베이스 모델(Base Model)에 새로운 데이터를 추가 학습하여 특정 도메인 지식이나 형식을 익히게 하는 과정입니다.",
        "isExam": true
      },
      {
        "id": 2,
        "text": "Fine Tuning을 수행하는 4가지 주요 목적에 해당하지 않는 것은?",
        "options": [
          "지식 (Knowledge) 주입",
          "능력 (Ability) 향상",
          "형식 (Format) 조정",
          "안전 (Safety) 강화",
          "모델 크기 (Model Size) 확장"
        ],
        "correctIndex": 4,
        "explanation": "Fine Tuning은 지식, 능력(논리적 추론 등), 출력 형식(말투, 길이), 안전성(유해한 답변 거부)을 위해 수행됩니다. 모델의 크기(파라미터 수)를 물리적으로 늘리는 것은 Fine Tuning의 목적이 아닙니다.",
        "isExam": true
      },
      {
        "id": 3,
        "text": "Base Model(Pretrained Model)의 특징으로 가장 적절한 것은?",
        "options": [
          "사용자의 질문에 친절하게 대답하도록 훈련되어 있다.",
          "주로 다음 토큰(Next Token)을 예측하는 단순 Completion 학습을 수행했다.",
          "특정 기업의 내부 규정이나 최신 뉴스를 이미 알고 있다.",
          "'챗봇'으로서의 역할을 수행하기 위해 강화 학습이 완료된 상태다.",
          "지시 사항(Instruction)을 따르는 능력이 매우 뛰어나다."
        ],
        "correctIndex": 1,
        "explanation": "Base Model은 위키피디아, 뉴스 등 대량의 텍스트로 '다음 단어 예측'만을 학습한 상태이므로, 질의응답이나 지시 사항 수행 능력은 부족합니다.",
        "isExam": true
      },
      {
        "id": 4,
        "text": "Fine Tuning을 진행할 때, 새로운 데이터를 학습하자 모델이 기존에 가지고 있던 지식이나 능력을 잃어버리는 현상은?",
        "options": [
          "Overfitting (과적합)",
          "Hallucination (환각)",
          "Catastrophic Forgetting (파국적 망각)",
          "Gradient Vanishing (기울기 소실)",
          "Context Window Limit (컨텍스트 윈도우 제한)"
        ],
        "correctIndex": 2,
        "explanation": "Catastrophic Forgetting은 추가 학습을 진행할 때 모델의 파라미터가 변하면서 기존의 언어 능력이나 지식이 손상되는 현상을 말합니다.",
        "isExam": true
      },
      {
        "id": 5,
        "text": "Continuous Pretraining(CPT)에 대한 설명으로 옳은 것은?",
        "options": [
          "질문-답변(QA) 쌍으로 이루어진 데이터만 사용한다.",
          "모델의 파라미터를 고정하고 프롬프트만 학습한다.",
          "특정 도메인의 말뭉치(Corpus)를 사용하여 모델의 기반 지식(토양)을 바꾼다.",
          "적은 양의 데이터로도 효과가 매우 빠르다.",
          "주로 Instruct Model을 대상으로 수행한다."
        ],
        "correctIndex": 2,
        "explanation": "CPT는 Pretrained Model에 새로운 도메인 지식(Corpus)을 추가로 주입하는 방식으로, 모델의 전반적인 언어 패턴과 지식을 변화시킵니다. Instruct Model보다는 Base Model에 주로 수행합니다.",
        "isExam": true
      },
      {
        "id": 6,
        "text": "RAG(Retrieval-Augmented Generation) 시스템의 성능을 높이기 위해, RAG 형식(관련 문서 + 질문 + 답변)의 데이터로 모델을 학습시키는 기법은?",
        "options": [
          "LoRA",
          "RAFT (Retrieval-Augmented Fine-Tuning)",
          "DPO",
          "RLHF",
          "PPO"
        ],
        "correctIndex": 1,
        "explanation": "RAFT는 LLM이 주어진 문서(Context)를 참고하여 답변하고, 불필요한 정보(Distractor)를 무시하도록 훈련시키는 기법으로, '오픈 북 시험 공부'에 비유됩니다.",
        "isExam": true
      },
      {
        "id": 7,
        "text": "Meta의 LIMA(Less is More for Alignment) 논문이 주장하는 Instruction Tuning의 핵심 역할은?",
        "options": [
          "모델에게 새로운 지식을 대량으로 주입하는 과정이다.",
          "모델의 파라미터 수를 획기적으로 줄이는 과정이다.",
          "Pretraining 과정에서 배운 지식을 인출하는 패턴(Format)을 학습하는 과정이다.",
          "강화 학습을 대체하는 완벽한 수단이다.",
          "이미지와 텍스트를 동시에 처리하게 만드는 과정이다."
        ],
        "correctIndex": 2,
        "explanation": "LIMA 논문은 Instruction Tuning이 새로운 지식을 배우는 것이 아니라, 이미 배운 지식을 사용자가 원하는 형식으로 꺼내 쓰는 방법(Alignment)을 익히는 과정임을 강조합니다.",
        "isExam": true
      },
      {
        "id": 8,
        "text": "Instruction Tuning 데이터셋의 구성 요소로 적절하지 않은 것은?",
        "options": [
          "Instruction (지시사항)",
          "Input (입력/질문)",
          "Output (출력/답변)",
          "Reward Function (보상 함수)",
          "System Prompt (선택적)"
        ],
        "correctIndex": 3,
        "explanation": "Instruction Tuning 데이터는 일반적으로 [지시사항, 질문, 답변]의 쌍으로 구성됩니다. 보상 함수(Reward Function)는 강화 학습(RL) 단계에서 사용되는 요소입니다.",
        "isExam": true
      },
      {
        "id": 9,
        "text": "RLHF(Reinforcement Learning with Human Feedback)의 핵심 구성 요소 중 하나로, LLM의 답변 품질을 점수(Scalar)로 평가하는 모델은?",
        "options": [
          "Policy Model",
          "Reward Model (보상 모델)",
          "Reference Model",
          "Tokenizer Model",
          "Embedding Model"
        ],
        "correctIndex": 1,
        "explanation": "Reward Model은 인간의 선호도 데이터를 학습하여, LLM이 생성한 답변이 얼마나 좋은지 점수로 평가하는 역할을 합니다.",
        "isExam": true
      },
      {
        "id": 10,
        "text": "강화 학습 과정에서 모델이 보상(Reward)을 최대화하려다 원래 언어 모델의 분포에서 너무 벗어나지 않도록 규제하는 값은?",
        "options": [
          "Learning Rate",
          "Batch Size",
          "KL Divergence (Kullback-Leibler Divergence)",
          "Dropout Rate",
          "Attention Score"
        ],
        "correctIndex": 2,
        "explanation": "PPO 알고리즘 등에서 KL Divergence 패널티를 사용하여 튜닝된 모델이 원본 모델(Reference Model)과 너무 다르게 변하여 언어 능력이 훼손되는 것을 방지합니다.",
        "isExam": true
      },
      {
        "id": 11,
        "text": "별도의 보상 모델(Reward Model) 없이, 선호 데이터(Chosen/Rejected)를 사용하여 직접 언어 모델을 최적화하는 방식은?",
        "options": [
          "PPO",
          "RLHF",
          "DPO (Direct Preference Optimization)",
          "A2C",
          "DQN"
        ],
        "correctIndex": 2,
        "explanation": "DPO는 보상 모델을 따로 학습하지 않고, LLM 자체가 선호되는 답변을 생성하도록 직접 최적화하는 방식으로, 구현이 간단하고 학습이 안정적입니다.",
        "isExam": true
      },
      {
        "id": 12,
        "text": "Rejection Sampling + SFT 방식에 대한 설명으로 옳은 것은?",
        "options": [
          "모델이 생성한 여러 답변 중 보상 모델 점수가 가장 낮은 것을 선택한다.",
          "강화 학습 없이 오직 인간이 작성한 데이터만 사용한다.",
          "모델이 생성한 답변 중 우수한(Best) 답변만 골라 다시 지도 학습(SFT)에 사용한다.",
          "모델의 파라미터를 전혀 수정하지 않는다.",
          "Base Model에서만 수행 가능하다."
        ],
        "correctIndex": 2,
        "explanation": "Rejection Sampling은 현재 모델로 다수의 답변을 생성한 뒤, 보상 모델(또는 규칙)로 가장 좋은 답변을 선별하여 이를 정답 데이터로 삼아 다시 SFT를 수행하는 방식입니다.",
        "isExam": true
      },
      {
        "id": 13,
        "text": "PEFT(Parameter Efficient Fine Tuning)의 대표적인 기법인 LoRA(Low-Rank Adaptation)의 원리는?",
        "options": [
          "모델의 모든 레이어를 제거하고 새로 학습한다.",
          "기존 가중치(W)는 고정하고, 이를 근사하는 저랭크 행렬(A, B)만 학습한다.",
          "모델의 파라미터를 4bit로 양자화하여 학습한다.",
          "입력 프롬프트의 길이를 줄여서 연산량을 감소시킨다.",
          "역전파(Backpropagation) 과정을 생략한다."
        ],
        "correctIndex": 1,
        "explanation": "LoRA는 Pretrained Weights는 동결(Freeze)하고, 변화량을 나타내는 작은 행렬 A와 B를 추가하여 이들만 학습시킴으로써 파라미터 수와 메모리 사용량을 획기적으로 줄입니다.",
        "isExam": true
      },
      {
        "id": 14,
        "text": "LoRA 적용 시 'Rank(r)' 값에 대한 설명으로 옳은 것은?",
        "options": [
          "r 값이 클수록 학습해야 할 파라미터 수가 줄어든다.",
          "r은 모델의 전체 레이어 개수와 동일해야 한다.",
          "r은 학습 가능한 정보의 차원을 의미하며, 일반적으로 원본 차원(d)보다 훨씬 작게 설정한다.",
          "r 값이 작을수록 모델의 성능이 무조건 좋아진다.",
          "r은 배치 사이즈(Batch Size)를 의미한다."
        ],
        "correctIndex": 2,
        "explanation": "LoRA에서 r은 Low-Rank의 차원을 의미하며, 원본 차원 d보다 훨씬 작은 값(예: 4, 8, 16 등)을 사용하여 파라미터를 효율화합니다.",
        "isExam": true
      },
      {
        "id": 15,
        "text": "Full Fine-Tuning 대비 LoRA의 장점이 아닌 것은?",
        "options": [
          "GPU 메모리 사용량이 적다.",
          "하나의 베이스 모델에 여러 개의 LoRA 어댑터를 갈아끼우며 사용할 수 있다.",
          "학습 속도가 빠르다.",
          "모델의 기존 지식을 잊어버리는 Catastrophic Forgetting이 덜 발생한다.",
          "모델의 추론 속도(Inference Latency)가 획기적으로 빨라진다."
        ],
        "correctIndex": 4,
        "explanation": "LoRA는 학습 시 효율적이지만, 추론 시에는 학습된 행렬(BA)을 원래 가중치(W)에 더해서(W' =W+BA) 사용하므로 구조적으로 모델 크기가 같아져 추론 속도 자체는 Full Fine-Tuning 모델과 동일합니다. (빨라지지 않음)",
        "isExam": true
      },
      {
        "id": 16,
        "text": "GPU 메모리가 부족할 때, 베이스 모델을 4bit 등으로 양자화(Quantization)한 상태에서 LoRA를 적용하는 기법은?",
        "options": [
          "DoRA",
          "QLoRA",
          "AdaLoRA",
          "LongLoRA",
          "Soft Prompting"
        ],
        "correctIndex": 1,
        "explanation": "QLoRA(Quantized LoRA)는 베이스 모델을 양자화하여 메모리를 줄인 상태에서 LoRA 어댑터를 붙여 학습하는 방식입니다.",
        "isExam": true
      },
      {
        "id": 17,
        "text": "DeepSeek-R1과 같은 최신 추론(Reasoning) 모델의 핵심 특징은?",
        "options": [
          "답변 생성 속도가 매우 빠르다.",
          "답변을 생성하기 전에 긴 사고 과정(Chain of Thought/Thinking)을 거친다.",
          "외부 도구(Tool) 사용에만 특화되어 있다.",
          "파라미터 수가 1B 이하로 매우 작다.",
          "이미지 생성 능력이 텍스트 능력보다 뛰어나다."
        ],
        "correctIndex": 1,
        "explanation": "DeepSeek-R1이나 OpenAI o1 같은 Reasoning 모델은 답변을 내놓기 전에 내부적으로 긴 추론 과정(Thinking Process/Long CoT)을 수행하여 복잡한 문제를 해결합니다.",
        "isExam": true
      },
      {
        "id": 18,
        "text": "DeepSeek-R1-Zero가 사용한 강화 학습 기법으로, 별도의 Value Model(Critic) 없이 그룹 내 답변들의 상대적 우열을 비교하여 학습하는 방식은?",
        "options": [
"PPO (Proximal Policy Optimization)",
          "A3C (Asynchronous Advantage Actor-Critic)",
          "GRPO (Group Relative Policy Optimization)",
          "TRPO (Trust Region Policy Optimization)",
          "DDPG (Deep Deterministic Policy Gradient)"
        ],
        "correctIndex": 2,
        "explanation": "GRPO는 하나의 질문에 대해 여러 개의 답변을 생성하고, 그 그룹 내의 평균 보상을 기준으로 각 답변의 우열을 가려 학습하는 방식으로, 연산 자원을 절약합니다.",
        "isExam": true
      },
      {
        "id": 19,
        "text": "DeepSeek-R1-Zero 학습 과정에서 관찰된 'Aha Moment'란 무엇인가?",
        "options": [
          "모델이 정답을 즉시 맞추는 현상",
          "모델이 스스로 자신의 풀이 과정을 재검토하고 오류를 수정하는 현상",
          "모델의 학습 속도가 갑자기 빨라지는 구간",
          "사용자의 의도를 완벽하게 파악하는 순간",
          "더 이상 성능이 향상되지 않는 정체 구간"
        ],
        "correctIndex": 1,
        "explanation": "학습이 진행되면서 모델이 텍스트 생성 도중 \"잠깐, 다시 생각해보자\"와 같이 스스로 오류를 인지하고 수정(Self-Correction)하는 패턴이 발현된 것을 의미합니다.",
        "isExam": true
      },
      {
        "id": 20,
        "text": "Reasoning LLM을 만들기 위한 데이터 레시피 중, 'Distillation' 방식의 의미는?",
        "options": [
          "사람이 직접 모든 데이터를 작성하는 것",
          "작은 모델이 큰 모델(예: DeepSeek-R1)이 생성한 사고 과정(Thinking)과 답변을 학습하는 것",
          "인터넷의 모든 데이터를 무작위로 학습하는 것",
          "수학 문제만 골라서 학습하는 것",
          "강화 학습만으로 모델을 처음부터 학습시키는 것"
        ],
        "correctIndex": 1,
        "explanation": "Distillation(지식 증류)은 성능이 뛰어난 큰 모델(Teacher)이 생성한 양질의 추론 데이터(사고 과정 포함)를 작은 모델(Student)에게 학습시켜 성능을 끌어올리는 방법입니다.",
        "isExam": true
      },
      {
        "id": 21,
        "text": "Pre-trained 모델 전체를 학습하지 않고, 일부 파라미터만 추가하거나 선택적으로 학습하여 효율적으로 튜닝하는 기법의 통칭은 무엇입니까?",
        "options": [
          "SFT (Supervised Fine-Tuning)",
          "RLHF (Reinforcement Learning from Human Feedback)",
          "PEFT (Parameter Efficient Fine-Tuning)",
          "CPT (Continuous Pre-Training)",
          "RAG (Retrieval-Augmented Generation)"
        ],
        "correctIndex": 2,
        "explanation": "PEFT는 거대 모델의 수십억 개 파라미터를 모두 수정하는 대신, 아주 적은 수의 파라미터만 추가하거나 업데이트함으로써 연산 자원과 메모리를 획기적으로 절약하며 모델을 최적화하는 기술들을 통칭합니다.",
        "isExam": true
      },
      {
        "id": 22,
        "text": "PEFT의 대표적인 알고리즘으로, 가중치 업데이트 시 행렬을 두 개의 저랭크(Low-Rank) 행렬로 분해하여 학습 파라미터 수를 줄이는 방식은?",
        "options": [
          "PPO (Proximal Policy Optimization)",
          "LoRA (Low-Rank Adaptation)",
          "DPO (Direct Preference Optimization)",
          "BERT",
          "Adapter"
        ],
        "correctIndex": 1,
        "explanation": "LoRA는 기존 모델의 가중치는 고정(Freeze)한 채, 가중치의 변화량을 나타내는 행렬을 저랭크로 분해하여 학습하는 방식입니다. 이를 통해 학습이 필요한 파라미터 수를 1,000배 이상 줄이기도 합니다.",
        "isExam": true
      },
      {
        "id": 23,
        "text": "미세 조정(Fine-Tuning)을 수행할 때, 새로운 데이터를 학습하면서 모델이 이미 가지고 있던 기존의 일반적인 지식이나 능력을 잃어버리는 현상은?",
        "options": [
          "Hallucination (환각)",
          "Overfitting (과적합)",
          "Catastrophic Forgetting (파괴적 망각)",
          "Vanishing Gradient (기울기 소실)",
          "Data Leakage (데이터 누출)"
        ],
        "correctIndex": 2,
        "explanation": "특정 도메인이나 작업에 맞춰 모델을 강하게 학습시킬 때, 사전 학습 과정에서 습득했던 범용적인 지식이 손상되어 기존에 잘하던 작업을 못 하게 되는 현상을 말합니다.",
        "isExam": true
      },
      {
        "id": 24,
        "text": "다음 중 미세 조정(Fine-Tuning)을 도입하기에 가장 적절한 상황은 무엇입니까?",
        "options": [
          "실시간 주식 정보나 오늘의 날씨 정보를 답변해야 할 때",
          "모델에게 특정 병원의 진료 기록 작성 스타일이나 전문적인 말투를 내재화시키고 싶을 때",
          "단순히 두 수의 덧셈이나 곱셈 같은 산술 연산을 수행할 때",
          "전 세계의 일반적인 상식(예: 프랑스의 수도)을 물어볼 때",
          "외부 웹사이트의 최신 뉴스 기사를 요약해야 할 때"
        ],
        "correctIndex": 1,
        "explanation": "미세 조정은 모델의 말투, 출력 형식, 특수 도메인 지식의 내재화 등 모델의 '행동 패턴'을 바꾸는 데 매우 효과적입니다. 실시간 정보나 최신 데이터 반영에는 RAG가 더 유리합니다.",
        "isExam": true
      },
      {
        "id": 25,
        "text": "별도의 보상 모델(Reward Model) 없이, 선호 데이터(Good/Bad) 쌍만으로 모델을 인간의 선호에 맞게 정렬하는 효율적인 방식은?",
        "options": [
          "PPO (Proximal Policy Optimization)",
          "SFT (Supervised Fine-Tuning)",
          "DPO (Direct Preference Optimization)",
          "CPT (Continuous Pre-Training)",
          "In-Context Learning"
        ],
        "correctIndex": 2,
        "explanation": "DPO는 복잡한 RLHF(강화 학습) 과정에서 보상 모델 학습과 PPO 알고리즘 단계를 생략하고, 직접적으로 데이터의 선호도를 학습하여 모델을 정렬하는 더 단순하고 효율적인 방식입니다.",
        "isExam": true
      },
      {
        "id": 26,
        "text": "RAG(검색 증강 생성)와 미세 조정(Fine-Tuning)의 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          "RAG는 모델의 내부 파라미터를 영구적으로 수정한다.",
          "미세 조정은 답변을 생성할 때마다 외부 데이터베이스를 검색한다.",
          "RAG는 최신 정보 반영에 유리하고, 미세 조정은 모델의 행동 패턴과 지식 내재화에 유리하다.",
          "두 기술은 완전히 동일한 원리로 작동하는 기술이다.",
          "미세 조정은 RAG보다 데이터 업데이트 비용이 훨씬 저렴하다."
        ],
        "correctIndex": 2,
        "explanation": "RAG는 외부 정보를 실시간으로 참조하여 답변하므로 정보 업데이트가 쉽고 할루시네이션을 줄이는 데 좋으며, 미세 조정은 모델 자체를 특정 목적에 맞춰 '체질 개선'을 하는 데 강점이 있습니다.",
        "isExam": true
      },
      {
        "id": 27,
        "text": "지도 미세 조정(SFT, Supervised Fine-Tuning)의 주된 학습 데이터 형태는 무엇입니까?",
        "options": [
          "라벨이 없는 대규모 텍스트 뭉치 (Corpus)",
          "질문(Instruction)과 그에 대한 정답(Response) 쌍으로 구성된 데이터",
          "대량의 이미지와 텍스트 설명 데이터",
          "단순히 '좋음' 혹은 '싫음'으로 표시된 보상 점수",
          "모델이 스스로 생성한 오답 데이터"
        ],
        "correctIndex": 1,
        "explanation": "SFT는 특정 지시사항(Instruction)에 대해 모델이 어떻게 대답해야 하는지 모범 답안(Gold Standard)을 보여주며 학습시키는 단계입니다.",
        "isExam": true
      },
      {
        "id": 28,
        "text": "베이스 모델(Base Model)과 인스트럭트 모델(Instruct Model)의 주요 차이점은?",
        "options": [
          "베이스 모델은 다음 단어 예측 위주로 학습되었고, 인스트럭트 모델은 지시사항을 따르도록 튜닝되었다.",
          "베이스 모델은 대화가 불가능하며 코딩 작업만 수행할 수 있다.",
          "인스트럭트 모델은 추가적인 학습 없이 프롬프트만으로 만들어진 모델이다.",
          "베이스 모델이 인스트럭트 모델보다 항상 더 안전한 답변을 생성한다.",
          "두 모델 사이에는 구조적, 기능적 차이가 전혀 없다."
        ],
        "correctIndex": 0,
        "explanation": "베이스 모델은 단순히 문장을 이어 나가는 능력에 집중되어 있지만, 여기에 SFT 등을 적용하여 사용자의 명령에 적절히 대답하도록 만든 것이 인스트럭트 모델입니다.",
        "isExam": true
      },
      {
        "id": 29,
        "text": "RLHF(인간 피드백 기반 강화 학습)의 핵심 구성 요소가 아닌 것은?",
        "options": [
          "사전 학습된 언어 모델 (Pre-trained Model)",
          "보상 모델 (Reward Model)",
          "PPO (Proximal Policy Optimization) 알고리즘",
          "벡터 데이터베이스 (Vector Database)",
          "인간의 선호도가 반영된 비교 데이터"
        ],
        "correctIndex": 3,
        "explanation": "벡터 데이터베이스는 주로 RAG(검색 증강 생성) 환경에서 지식 검색을 위해 사용되는 도구입니다. RLHF는 모델의 답변 품질을 인간의 기준에 맞추는 '정렬' 과정에 집중합니다.",
        "isExam": true
      },
      {
        "id": 30,
        "text": "특정 도메인의 대량 코퍼스를 추가로 학습시켜 모델이 해당 분야의 기초 지식을 내재화하도록 강화하는 과정은?",
        "options": [
          "프롬프트 엔지니어링 (Prompt Engineering)",
          "지속적 사전 학습 (CPT, Continuous Pre-Training)",
          "인컨텍스트 러닝 (In-Context Learning)",
          "제로샷 추론 (Zero-shot Inference)",
          "퓨샷 러닝 (Few-shot Learning)"
        ],
        "correctIndex": 1,
        "explanation": "CPT는 이미 학습된 모델에 의료, 법률 등 특정 분야의 방대한 텍스트 데이터를 추가로 학습시켜, 해당 도메인의 기본 언어 구조와 지식을 깊이 있게 익히게 하는 과정입니다.",
        "isExam": true
      },
      {
        "id": 31,
        "text": "전체 훈련 데이터를 모델에 한 번 통과시키는 학습 단위를 무엇이라 하는가?",
        "options": [
          "Batch (배치)",
          "Epoch (에폭)",
          "Step (스텝)",
          "Iteration (이터레이션)",
          "Learning Rate (학습률)"
        ],
        "correctIndex": 1,
        "explanation": "1 에폭은 준비된 전체 데이터셋을 한 번 모두 훑어 학습한 상태를 의미합니다.",
        "categoryId": "fine-tuning",
        "isExam": true
      },
      {
        "id": 32,
        "text": "과적합(Overfitting)을 방지하기 위해 학습 도중 모델의 성능을 평가하는 별도의 데이터셋은?",
        "options": [
          "Train Set (훈련 세트)",
          "Validation Set (검증 세트)",
          "Test Set (테스트 세트)",
          "Dummy Set (가상 세트)",
          "Raw Data (원천 데이터)"
        ],
        "correctIndex": 1,
        "explanation": "학습 중에 실시간으로 모델의 일반화 성능을 체크하여 학습 중단 시점을 결정하는 데 사용됩니다.",
        "categoryId": "fine-tuning",
        "isExam": true
      },
      {
        "id": 33,
        "text": "모델 학습 시 오차(Loss)가 줄어들도록 가중치를 조정하는 가장 대표적인 최적화 알고리즘은?",
        "options": [
          "Gradient Descent (경사 하강법)",
          "Heap Sorting (힙 정렬)",
          "Linear Regression (선형 회귀)",
          "K-Means Clustering (K-평균 군집화)",
          "Decision Tree (의사결정 나무)"
        ],
        "correctIndex": 0,
        "explanation": "손실 함수의 기울기를 따라 오차가 최소화되는 지점으로 파라미터를 업데이트해 나가는 딥러닝의 핵심 기법입니다.",
        "categoryId": "fine-tuning",
        "isExam": true
      },
      {
        "id": 34,
        "text": "GPU 메모리가 부족할 때 베이스 모델을 양자화하여 아주 적은 파라미터만 학습시키는 기법은?",
        "options": [
          "Full Fine-Tuning (전체 미세 조정)",
          "QLoRA (양자화 로라)",
          "Distillation (지식 증류)",
          "Pruning (모델 가지치기)",
          "Normalization (데이터 정규화)"
        ],
        "correctIndex": 1,
        "explanation": "모델을 4비트 등으로 압축한 상태에서 LoRA 어댑터만 붙여 학습하여 메모리 효율을 극대화한 방식입니다.",
        "categoryId": "fine-tuning",
        "isExam": true
      },
      {
        "id": 35,
        "text": "파인 튜닝 후 정량적 지표 외에 실제 사람이 답변을 직접 보고 품질을 평가하는 방식은?",
        "options": [
          "Unit Test (단위 테스트)",
          "Human Evaluation (정성 평가)",
          "Code Review (코드 검토)",
          "Static Analysis (정적 분석)",
          "Alpha Testing (알파 테스트)"
        ],
        "correctIndex": 1,
        "explanation": "생성형 AI 답변의 모호함을 정량적 지표(BLEU 등)만으로는 판단하기 어려워 전문가의 직접 평가가 필수적입니다.",
        "categoryId": "fine-tuning",
        "isExam": true
      }
    ]
  }
]