[
  {
    "id": "python-basics",
    "name": "Python 기초",
    "questions": [
      {
        "id": 1,
        "text": "Python 언어의 특징으로 가장 적절하지 않은 것은 무엇인가요?",
        "options": [
          "문법이 간결하고 배우기 쉽다.",
          "컴파일 언어로 실행 속도가 매우 빠르다.",
          "방대한 라이브러리와 커뮤니티 지원이 있다.",
          "웹 개발, 데이터 분석, AI/ML 등 범용적으로 사용된다.",
          "LLM(Large Language Model) 개발에서 많은 활용성을 보인다."
        ],
        "correctIndex": 1,
        "explanation": "Python은 스크립트 언어(인터프리터)이며 컴파일 언어가 아니다."
      },
      {
        "id": 2,
        "text": ".py 파일과 .ipynb 파일의 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          ".py 파일은 주피터 노트북 파일이다.",
          ".ipynb 파일은 일반 Python 스크립트 파일로 실제 개발에 적합하다.",
          ".ipynb 파일은 JSON 형식으로 저장되며 코드, 결과, 문서를 함께 관리할 수 있다.",
          ".py 파일은 데이터 분석 및 교육용 실험에 주로 사용된다.",
          "두 파일 형식 간에는 아무런 기능적 차이가 없다."
        ],
        "correctIndex": 2,
        "explanation": ".ipynb는 주피터 노트북 파일로 JSON 형식이며 코드와 결과, 마크다운을 함께 관리한다."
      },
      {
        "id": 3,
        "text": "Python 변수(Variable)의 특징인 '동적 타이핑(Dynamic Typing)'에 대한 설명으로 옳은 것은?",
        "options": [
          "변수 선언 시 int, str과 같은 타입을 반드시 명시해야 한다.",
          "변수의 타입은 컴파일 시점에 결정된다.",
          "실행 시점에 값이 할당될 때 타입이 결정된다.",
          "한 번 선언된 변수의 타입은 변경할 수 없다.",
          "var, let 같은 키워드를 사용하여 변수를 선언해야 한다."
        ],
        "correctIndex": 2,
        "explanation": "Python은 실행 시점에 값이 할당될 때 타입이 결정되는 동적 타이핑을 지원한다."
      },
      {
        "id": 4,
        "text": "Python의 변수 명명 규칙(PEP8)에 어긋나는 것은?",
        "options": [
          "user_name",
          "total_count",
          "MAX_RETRY",
          "class",
          "_private_var"
        ],
        "correctIndex": 3,
        "explanation": "예약어인 class는 변수명으로 사용할 수 없다."
      },
      {
        "id": 5,
        "text": "다음 중 Python의 기본 자료형에 대한 설명으로 틀린 것은?",
        "options": [
          "int: 메모리 제한 없는 큰 정수를 표현할 수 있다.",
          "float: 부동소수점 방식을 사용하며 정밀도 한계가 존재한다.",
          "str: 문자열을 나타내며 불변(immutable) 시퀀스이다.",
          "bool: True와 False 값을 가지며 내부적으로는 1과 0으로 처리된다.",
          "None: 값이 0임을 나타내는 숫자형 데이터이다."
        ],
        "correctIndex": 4,
        "explanation": "None은 널 타입으로 값이 없음을 나타내며 숫자 0과는 다르다."
      },
      {
        "id": 6,
        "text": "Python의 자료구조 중 '순서가 있고 값을 변경할 수 없는(Immutable)' 것은?",
        "options": [
          "List",
          "Dictionary",
          "Set",
          "Tuple",
          "Array"
        ],
        "correctIndex": 3,
        "explanation": "Tuple은 순서가 있지만 값을 변경할 수 없는 자료구조이다."
      },
      {
        "id": 7,
        "text": "Python 조건문에서 '거짓(Falsy)'으로 평가되는 값이 아닌 것은?",
        "options": [
          "None",
          "0",
          "\"\" (빈 문자열)",
          "[] (빈 리스트)",
          "-1"
        ],
        "correctIndex": 4,
        "explanation": "-1은 Truthy 값이며 거짓이 아니다."
      },
      {
        "id": 8,
        "text": "반복문(Loop) 제어 키워드 중, 현재 반복을 건너뛰고 다음 반복을 진행하게 하는 것은?",
        "options": [
          "break",
          "continue",
          "pass",
          "return",
          "stop"
        ],
        "correctIndex": 1,
        "explanation": "continue는 현재 반복을 건너뛰고 다음 반복으로 진행한다."
      },
      {
        "id": 9,
        "text": "함수(Function)를 사용하는 목적으로 가장 적절한 것은?",
        "options": [
          "코드를 복잡하게 만들기 위해",
          "한 번만 실행되는 코드를 작성하기 위해",
          "특정 코드나 기능을 반복 사용하고 재사용성을 높이 위해",
          "프로그램의 실행 속도를 늦추기 위해",
          "변수의 타입을 강제로 변환하기 위해"
        ],
        "correctIndex": 2,
        "explanation": "함수는 코드 재사용성과 가독성을 높이기 위해 사용한다."
      },
      {
        "id": 10,
        "text": "효율적인 코드 설계를 위한 'DRY 원칙'의 의미는 무엇인가요?",
        "options": [
          "Do Repeat Yourself (코드를 반복해서 작성하라)",
          "Don't Repeat Yourself (같은 코드의 반복을 피하라)",
          "Define Return Yield (반환값을 항상 정의하라)",
          "Data Research Yield (데이터를 먼저 분석하라)",
          "Debug Run Yield (디버깅을 먼저 수행하라)"
        ],
        "correctIndex": 1,
        "explanation": "DRY는 'Don't Repeat Yourself'의 약자로 중복 코드를 피한다는 의미이다."
      },
      {
        "id": 11,
        "text": "Python 모듈(Module)과 패키지(Package)에 대한 설명으로 바른 것은?",
        "options": [
          ".py 파일 하나는 모듈이 될 수 없다.",
          "패키지는 하나의 폴더에 여러 모듈을 묶어서 저장하는 형식이다.",
          "import 구문은 모듈 내의 함수를 사용할 수 없게 한다.",
          "라이브러리는 모듈과 패키지를 포함하지 않는 개념이다.",
          "모듈은 반드시 __init__.py 파일이 있어야 한다."
        ],
        "correctIndex": 1,
        "explanation": "패키지는 폴더에 여러 모듈을 묶어 저장한다."
      },
      {
        "id": 12,
        "text": "Python의 리스트 컴프리헨션(List Comprehension)을 사용한 코드로 올바른 것은? (목표: 0부터 9까지의 짝수의 제곱을 담은 리스트 생성)",
        "options": [
          "result = [x**2 if x % 2 == 0 for x in range(10)]",
          "result = [x**2 for x in range(10) if x % 2 == 0]",
          "result = {x**2 for x in range(10) if x % 2 == 0}",
          "result = (x**2 for x in range(10) if x % 2 == 0)",
          "result = [for x in range(10) if x % 2 == 0 return x**2]"
        ],
        "correctIndex": 1,
        "explanation": "리스트 컴프리헨션의 올바른 문법은 [표현식 for 변수 in 이터러블 if 조건] 형태이다."
      },
      {
        "id": 13,
        "text": "파일 입출력 시 with open(...) as f: 구문을 사용하는 주된 이유는 무엇인가요?",
        "options": [
          "파일을 더 빠르게 읽기 위해",
          "파일의 인코딩을 자동으로 변환하기 위해",
          "블록 실행 후 파일을 자동으로 닫아주기(close) 위해",
          "바이너리 파일을 텍스트로 변환하기 위해",
          "파일 이름을 자동으로 변경하기 위해"
        ],
        "correctIndex": 2,
        "explanation": "with 구문은 블록을 벗어날 때 자동으로 파일을 닫는다."
      },
      {
        "id": 14,
        "text": "경량 데이터 교환 형식으로, 파이썬의 Dictionary와 유사한 구조를 가진 것은?",
        "options": [
          "XML",
          "HTML",
          "CSV",
          "JSON",
          "SQL"
        ],
        "correctIndex": 3,
        "explanation": "JSON은 키-값 구조로 파이썬 dict와 유사하다."
      },
      {
        "id": 15,
        "text": "예외 처리(Exception Handling)에서 try-except 구문의 역할로 가장 적절한 것은?",
        "options": [
          "프로그램의 문법 오류를 자동으로 수정한다.",
          "모든 에러를 무시하고 프로그램을 강제로 종료한다.",
          "실행 중 발생한 예외를 포착하여 프로그램이 비정상 종료되지 않도록 처리한다.",
          "코드를 컴파일하여 실행 속도를 높인다.",
          "데이터베이스 연결을 최적화한다."
        ],
        "correctIndex": 2,
        "explanation": "try-except는 예외를 포착해 프로그램이 중단되지 않게 처리한다."
      },
      {
        "id": 16,
        "text": "예외 처리 구문 중 예외 발생 여부와 상관없이 '항상 실행되는 코드'를 작성하는 블록은?",
        "options": [
          "try",
          "except",
          "else",
          "finally",
          "catch"
        ],
        "correctIndex": 3,
        "explanation": "finally 블록은 예외 발생 여부와 관계없이 항상 실행된다."
      },
      {
        "id": 17,
        "text": "객체지향 프로그래밍(OOP)에서 'Class'의 정의로 가장 적절한 것은?",
        "options": [
          "데이터(속성)와 기능(메서드)을 하나로 묶은 객체의 설계도",
          "실행 가능한 독립적인 프로그램 파일",
          "데이터베이스의 테릿을 관리하는 도구",
          "외부 라이브러리를 설치하는 명령어",
          "반복문을 효율적으로 실행하는 함수"
        ],
        "correctIndex": 0,
        "explanation": "Class는 데이터와 메서드를 포함하는 설계도이다."
      },
      {
        "id": 18,
        "text": "Class 내부에서 인스턴스(Instance) 자신을 가리키는 키워드는 무엇인가요?",
        "options": [
          "this",
          "self",
          "me",
          "instance",
          "object"
        ],
        "correctIndex": 1,
        "explanation": "Python에서는 self가 인스턴스를 가리킨다."
      },
      {
        "id": 19,
        "text": "Class 생성자 메서드의 이름으로 올바른 것은?",
        "options": [
          "__create__",
          "__start__",
          "__main__",
          "__init__",
          "__new__"
        ],
        "correctIndex": 3,
        "explanation": "Python 클래스의 생성자는 __init__ 메서드이다."
      },
      {
        "id": 20,
        "text": "상속(Inheritance) 관계에서 자식 클래스가 부모 클래스의 메서드 기능을 그대로 가져오면서 확장하려고 할 때 사용하는 함수는?",
        "options": [
          "parent()",
          "base()",
          "super()",
          "root()",
          "extend()"
        ],
        "correctIndex": 2,
        "explanation": "super()를 사용해 부모 클래스 메서드를 호출한다."
      }
    ]
  },
  {
    "id": "data-analysis",
    "name": "데이터 분석",
    "questions": [
      {
        "id": 1,
        "text": "Python의 수치 연산 라이브러리인 NumPy에 대한 설명으로 가장 적절하지 않은 것은?",
        "options": [
          "C 언어로 구현된 함수를 사용하여 연산 속도가 빠르다.",
          "파이썬의 기본 리스트(List)보다 대량의 데이터 처리에 유리하다.",
          "벡터, 행렬, 텐서 연산을 수행하는 데 필수적이다.",
          "머신러닝 및 딥러닝 라이브러리에서는 거의 사용되지 않는다.",
          "LLM 및 AI 분야의 기초가 되는 라이브러리다."
        ],
        "correctIndex": 3,
        "explanation": "거의 모든 ML/DL 라이브러리는 NumPy를 기반으로 사용합니다."
      },
      {
        "id": 2,
        "text": "NumPy에서 모든 요소가 0인 m×n 행렬을 생성하는 함수는?",
        "options": [
          "np.array()",
          "np.zeros((m,n))",
          "np.ones((m,n))",
          "np.arange()",
          "np.random.randn()"
        ],
        "correctIndex": 1,
        "explanation": "np.zeros((m,n))은 m×n 크기의 영(0)행렬을 생성합니다."
      },
      {
        "id": 3,
        "text": "두 벡터의 방향 유사도를 측정할 때 주로 사용되는 NumPy 연산은 무엇인가요?",
        "options": [
          "요소별 덧셈 (+)",
          "요소별 곱셈 (*)",
          "내적 (Dot Product, np.dot)",
          "전치 행렬 (.T)",
          "노름 (Norm, np.linalg.norm)"
        ],
        "correctIndex": 2,
        "explanation": "내적(Dot Product)은 벡터의 방향 유사도를 측정하는 데 활용됩니다."
      },
      {
        "id": 4,
        "text": "NumPy 행렬 연산에서 두 행렬 A와 B의 행렬 곱(Matrix Multiplication)을 수행하는 코드로 옳은 것은?",
        "options": [
          "A * B",
          "np.add(A, B)",
          "A / B",
          "np.matmul(A, B) 또는 A @ B",
          "np.transpose(A)"
        ],
        "correctIndex": 3,
        "explanation": "행렬 곱은 np.matmul(A, B) 함수를 쓰거나 A @ B 연산자를 사용합니다."
      },
      {
        "id": 5,
        "text": "Pandas의 데이터 구조 중 2차원 테이블 형태의 데이터를 다루는 객체는?",
        "options": [
          "Series",
          "DataFrame",
          "List",
          "Dictionary",
          "Array"
        ],
        "correctIndex": 1,
        "explanation": "Series는 1차원, DataFrame은 2차원(행과 열) 구조를 제공하며 Series의 결합 형태입니다."
      },
      {
        "id": 6,
        "text": "Pandas DataFrame(df)의 기초 통계 분석 결과(평균, 표준편차, 최솟값 등)를 요약해서 보여주는 함수는?",
        "options": [
          "df.shape",
          "df.columns",
          "df.info()",
          "df.describe()",
          "df.head()"
        ],
        "correctIndex": 3,
        "explanation": "df.describe()는 데이터의 기본 통계 분석 결과를 제공합니다."
      },
      {
        "id": 7,
        "text": "Pandas에서 특정 조건(예: 20대 이상이면서 남성)을 만족하는 데이터를 필터링할 때 사용하는 논리 연산자는?",
        "options": [
          "&&",
          "||",
          "& (AND), | (OR)",
          "and, or",
          "!"
        ],
        "correctIndex": 2,
        "explanation": "Pandas 필터링 시에는 &(AND)와 |(OR) 연산자를 사용하여 조건을 결합합니다."
      },
      {
        "id": 8,
        "text": "Pandas에서 SQL의 JOIN과 유사하게, 두 개의 DataFrame을 특정 키(Key)를 기준으로 합치는 함수는?",
        "options": [
          "concat()",
          "append()",
          "merge()",
          "groupby()",
          "pivot_table()"
        ],
        "correctIndex": 2,
        "explanation": "merge() 함수는 SQL JOIN과 유사하게 공통 컬럼을 기준으로 데이터를 병합합니다."
      },
      {
        "id": 9,
        "text": "데이터프레임에서 특정 기준(컬럼)으로 데이터를 묶어서 통계(평균, 합계 등)를 계산할 때 사용하는 메서드는?",
        "options": [
          "sort_values()",
          "groupby()",
          "apply()",
          "fillna()",
          "drop()"
        ],
        "correctIndex": 1,
        "explanation": "groupby()는 특정 기준으로 데이터를 묶어서 통계를 계산할 때 사용됩니다."
      },
      {
        "id": 10,
        "text": "텍스트 분석 전처리 과정이 필요한 이유로 가장 적절한 것은?",
        "options": [
          "텍스트 데이터를 이미지로 변환하기 위해",
          "불필요한 문자나 잡음(Noise)을 제거하고 데이터를 표준화하기 위해",
          "데이터의 용량을 무조건 늘리기 위해",
          "모든 단어를 숫자가 아닌 특수문자로 변환하기 위해",
          "LLM이 전처리된 데이터는 처리하지 못하기 때문에"
        ],
        "correctIndex": 1,
        "explanation": "텍스트 분석 모델에 전달하기 전에 불필요한 문자/잡음에 취약한 부분을 정리 및 표준화해야 합니다."
      },
      {
        "id": 11,
        "text": "정규표현식(Regex) 패턴 중 연속된 숫자(0-9)를 의미하는 패턴은?",
        "options": [
          "\\s+",
          "[가-힣]+",
          "[a-zA-Z]+",
          "\\d+",
          "\\b"
        ],
        "correctIndex": 3,
        "explanation": "\\d+는 숫자를 의미하는 정규표현식 패턴입니다."
      },
      {
        "id": 12,
        "text": "텍스트 정제(Cleaning) 단계에서 주로 수행하는 작업이 아닌 것은?",
        "options": [
          "HTML 태그 제거",
          "URL 주소 제거",
          "이모지(Emoji) 제거",
          "특수문자를 공백으로 치환",
          "문장의 긍정/부정 분류"
        ],
        "correctIndex": 4,
        "explanation": "정제(Cleaning)는 태그, URL, 이모지 제거 등을 수행하며, 감성 분류는 전처리가 끝난 후 모델링 단계의 작업입니다."
      },
      {
        "id": 13,
        "text": "문장을 의미 있는 단위(단어, 형태소 등)로 나누는 과정을 무엇이라 하는가?",
        "options": [
          "정규화 (Normalization)",
          "토큰화 (Tokenization)",
          "임베딩 (Embedding)",
          "파싱 (Parsing)",
          "시각화 (Visualization)"
        ],
        "correctIndex": 1,
        "explanation": "토큰화(Tokenization)는 문장, 단어, 형태소 등 의미 있는 단위로 텍스트를 분리하는 과정입니다."
      },
      {
        "id": 14,
        "text": "텍스트 정규화(Normalization)의 예시로 적절한 것은?",
        "options": [
          "\"Hello\"와 \"hello\"를 대소문자 통일하여 같은 단어로 처리한다.",
          "문장의 순서를 무작위로 섞는다.",
          "모든 명사를 제거한다.",
          "문장을 띄어쓰기 없이 모두 합친다.",
          "이미지를 텍스트로 설명한다."
        ],
        "correctIndex": 0,
        "explanation": "정규화는 대소문자 통일, 반복 문자 축소 등을 통해 텍스트를 표준 형태로 변환하는 과정입니다."
      },
      {
        "id": 15,
        "text": "\"이\", \"그\", \"저\", \"것\"과 같이 문법적 기능은 하지만 분석에 큰 의미가 없어 제거하는 단어들을 무엇이라 하는가?",
        "options": [
          "핵심어 (Keywords)",
          "고유명사 (Proper Nouns)",
          "불용어 (Stopwords)",
          "신조어 (Slang)",
          "외래어 (Loanwords)"
        ],
        "correctIndex": 2,
        "explanation": "불용어(Stopwords)는 분석에 불필요한 조사, 접속사 등을 의미하며 이를 제거하여 품질을 개선합니다."
      },
      {
        "id": 16,
        "text": "텍스트를 숫자로 변환하는 기법 중, 단어의 순서는 무시하고 단어의 출현 빈도만을 벡터로 표현하는 방식은?",
        "options": [
          "Word2Vec",
          "Bag of Words (BoW)",
          "Transformer",
          "RNN",
          "Sequence-to-Sequence"
        ],
        "correctIndex": 1,
        "explanation": "Bag of Words(BoW)는 텍스트를 단어의 묶음으로 처리하며, 순서를 무시하고 빈도수를 벡터로 표현합니다."
      },
      {
        "id": 17,
        "text": "Bag of Words(BoW) 방식의 단점으로 가장 적절한 것은?",
        "options": [
          "구현이 매우 복잡하다.",
          "단어의 순서 정보가 손실되어 문맥 파악이 어렵다.",
          "계산 속도가 매우 느리다.",
          "모든 단어가 0이 아닌 값을 가진다.",
          "문서 분류에는 사용할 수 없다."
        ],
        "correctIndex": 1,
        "explanation": "BoW는 단어의 순서를 무시하기 때문에 복잡한 맥락에서 내용들을 이해하기 어렵다는 단점이 있습니다."
      },
      {
        "id": 18,
        "text": "TF-IDF에서 'IDF(Inverse Document Frequency)'의 의미로 올바른 것은?",
        "options": [
          "특정 문서 내에서 단어가 등장한 횟수",
          "모든 문서에서 자주 등장하는 흔한 단어에 가중치를 주는 값",
          "전체 문서 수 대비 해당 단어가 포함된 문서 수의 비율을 역수로 취한 값 (희귀성 반영)",
          "문장의 길이를 측정하는 척도",
          "단어 간의 거리를 계산하는 함수"
        ],
        "correctIndex": 2,
        "explanation": "IDF는 전체 문서 수 중 해당 단어가 포함된 문서 수가 적을수록(희귀할수록) 높은 값을 가지며, 이는 단어의 중요도를 반영합니다."
      },
      {
        "id": 19,
        "text": "두 문서 벡터 간의 유사도를 측정하는 방법 중, 벡터 사이의 각도(방향)를 기반으로 유사성을 판단하는 것은?",
        "options": [
          "유클리드 거리 (Euclidean Distance)",
          "맨해튼 거리 (Manhattan Distance)",
          "코사인 유사도 (Cosine Similarity)",
          "자카드 유사도 (Jaccard Similarity)",
          "해밍 거리 (Hamming Distance)"
        ],
        "correctIndex": 2,
        "explanation": "코사인 유사도(Cosine Similarity)는 두 벡터가 얼마나 비슷한 방향인지(각도)를 측정하여 유사도를 계산합니다."
      },
      {
        "id": 20,
        "text": "TF-IDF 행렬을 사용하여 문서 간의 유사도를 시각화할 때 유용한 그래프 형태는?",
        "options": [
          "파이 차트 (Pie Chart)",
          "히트맵 (Heatmap)",
          "산점도 (Scatter Plot)",
          "박스 플롯 (Box Plot)",
          "히스토그램 (Histogram)"
        ],
        "correctIndex": 1,
        "explanation": "문서 유사도 히트맵(Heatmap)을 사용하면 문서 간의 코사인 유사도 등을 색상의 진하기로 직관적으로 비교할 수 있습니다."
      }
    ]
  },
  {
    "id": "llm-basics",
    "name": "LLM 기본",
    "questions": [
      {
        "id": 1,
        "text": "RAG(Retrieval‑Augmented Generation)의 핵심 개념으로 가장 적절한 것은?",
        "options": [
          "모델의 파라미터를 직접 수정하여 지식을 주입하는 방식이다.",
          "외부 데이터베이스에서 관련 정보를 검색(Retrieval)하여 프롬프트에 포함시킨 뒤 생성(Generation)하는 방식이다.",
          "검색 없이 LLM의 내부 지식만을 활용해 답변을 생성하는 기법이다.",
          "텍스트를 이미지로 변환한 후 다시 텍스트로 바꾸는 과정이다.",
          "정해진 규칙(Rule‑based)에 따라 답변을 선택하는 챗봇 방식이다."
        ],
        "correctIndex": 1,
        "explanation": "RAG는 LLM이 학습하지 않은 최신 정보나 사내 데이터를 활용하기 위해, 질문과 관련된 문서를 검색하여 문맥(Context)으로 제공하는 기술입니다."
      },
      {
        "id": 2,
        "text": "LLM의 하이퍼파라미터 중 'Temperature'에 대한 설명으로 옳은 것은?",
        "options": [
          "값이 0에 가까울수록 답변이 창의적이고 무작위성이 강해진다.",
          "값이 높을수록(예: 1.0 이상) 답변이 결정론적이고 일관되게 변한다.",
          "Temperature는 모델의 학습 속도를 조절하는 변수다.",
          "값이 낮을수록(예: 0.1) 가장 확률이 높은 토큰을 선택하여 답변이 논리적이고 사실적이 된다.",
          "Temperature는 입력 텍스트의 길이를 제한하는 설정이다."
        ],
        "correctIndex": 3,
        "explanation": "Temperature가 낮으면 확률 분포가 뾰족해져 가장 높은 확률의 단어를 선택(결정론적)하며, 높으면 분포가 평탄해져 다양한 단어를 선택(창의적)하게 됩니다."
      },
      {
        "id": 3,
        "text": "'환각(Hallucination)' 현상에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "LLM이 사용자 의도를 완벽하게 파악하여 정답을 맞히는 현상",
          "모델이 사실이 아닌 정보를 마치 사실인 것처럼 그럴듯하게 생성하는 현상",
          "질문에 대한 답변을 거부하는 안전 장치 작동 현상",
          "검색된 문서의 내용만을 그대로 복사하여 출력하는 현상",
          "네트워크 오류로 인해 답변 생성이 중단되는 현상"
        ],
        "correctIndex": 1,
        "explanation": "환각은 LLM이 확률적으로 문장을 생성하는 과정에서, 사실 관계가 틀리거나 없는 내용을 있는 것처럼 꾸며내는 현상을 말합니다."
      },
      {
        "id": 4,
        "text": "텍스트를 컴퓨터가 이해할 수 있는 숫자 형태의 벡터(Vector)로 변환하는 과정을 무엇이라 하는가?",
        "options": [
          "Tokenization (토큰화)",
          "Chunking (청킹)",
          "Embedding (임베딩)",
          "Parsing (파싱)",
          "Rendering (렌더링)"
        ],
        "correctIndex": 2,
        "explanation": "임베딩(Embedding)은 텍스트의 의미를 고차원 공간의 벡터(숫자 배열)로 변환하여 컴퓨터가 의미적 유사성을 계산할 수 있게 하는 과정입니다."
      },
      {
        "id": 5,
        "text": "다음 중 벡터 데이터베이스(Vector DB)가 주로 수행하는 역할은?",
        "options": [
          "정형 데이터(SQL)의 테이블 간 관계를 정의한다.",
          "이미지 파일을 원본 그대로 압축하여 저장한다.",
          "임베딩된 벡터를 저장하고, 질문 벡터와 유사한 벡터를 고속으로 검색한다.",
          "웹사이트의 HTML 코드를 실시간으로 크롤링한다.",
          "LLM의 파라미터 가중치를 실시간으로 업데이트한다."
        ],
        "correctIndex": 2,
        "explanation": "Vector DB는 임베딩 벡터를 저장하고 인덱싱하여, 코사인 유사도 등을 기반으로 유사한 데이터를 빠르게 찾는(Similarity Search) 역할을 합니다."
      },
      {
        "id": 6,
        "text": "RAG 파이프라인에서 'Chunking(청킹)'이 필요한 이유는?",
        "options": [
          "LLM의 컨텍스트 윈도우(입력 길이) 제한을 맞추고, 검색의 정확도를 높이기 위해",
          "텍스트를 암호화하여 보안을 강화하기 위해",
          "모든 데이터를 하나의 거대한 파일로 합치기 위해",
          "데이터베이스의 저장 용량을 늘리기 위해",
          "이미지를 텍스트로 변환하기 위해"
        ],
        "correctIndex": 0,
        "explanation": "긴 문서를 통째로 넣으면 LLM의 입력 한계를 초과하거나 정보의 밀도가 희석됩니다. 의미 단위로 적절히 자르는 청킹은 검색 정밀도와 LLM 이해도를 모두 높습니다."
      },
      {
        "id": 7,
        "text": "'Hybrid Search(하이브리드 검색)'란 무엇을 의미하는가?",
        "options": [
          "구글 검색과 네이버 검색을 동시에 사용하는 것",
          "키워드 기반 검색(Keyword Search)과 의미 기반 검색(Semantic Search)을 결합하여 사용하는 것",
          "텍스트 검색과 이미지 검색을 번갈아 수행하는 것",
          "SQL 쿼리와 NoSQL 쿼리를 섞어 쓰는 것",
          "사람이 직접 검색하고 AI가 요약하는 방식"
        ],
        "correctIndex": 1,
        "explanation": "키워드 매칭(Lexical)의 정확성과 의미적 유사성(Semantic)의 맥락 파악 능력을 결합하여 상호 보완적인 검색 결과를 얻는 방식입니다."
      },
      {
        "id": 8,
        "text": "RAG 시스템에서 'Reranker(재순위화 모델)'의 역할은?",
        "options": [
          "문서를 처음부터 다시 작성한다.",
          "검색된 후보 문서들의 점수를 다시 계산하여, 질문과의 관련성이 높은 순서로 재정렬한다.",
          "벡터 데이터베이스의 인덱스를 삭제한다.",
          "사용자의 질문을 다른 언어로 번역한다.",
          "검색 속도를 물리적으로 2배 빠르게 만든다."
        ],
        "correctIndex": 1,
        "explanation": "1차 검색(Retrieval)으로 가져온 문서들은 순위가 부정확할 수 있습니다. Reranker는 더 정교한 모델을 사용해 질문‑문서 쌍의 관련성을 정밀 채점하여 최상위 문서의 품질을 높입니다."
      },
      {
        "id": 9,
        "text": "프롬프트 엔지니어링 기법 중, 예제(Example)를 몇 개 보여주어 모델이 패턴을 학습하게 하는 방식은?",
        "options": [
          "Zero-shot Prompting",
          "Few-shot Prompting",
          "Chain-of-Thought",
          "Tree of Thoughts",
          "ReAct"
        ],
        "correctIndex": 1,
        "explanation": "Few-shot Prompting은 ‘질문: A, 답변: B’와 같은 예시(Shot)를 소수 제공하여 모델이 작업의 형식과 의도를 파악하도록 유도하는 기법입니다."
      },
      {
        "id": 10,
        "text": "'Chain-of-Thought (CoT)' 프롬프트의 특징은?",
        "options": [
          "질문에 대해 즉시 단답형으로 대답하도록 강제한다.",
          "답변을 생성하기 전에 단계별 추론 과정(Step‑by‑step reasoning)을 거치도록 유도한다.",
          "외부 도구를 사용하지 않도록 제한한다.",
          "모델의 파라미터를 영구적으로 변경한다.",
          "문장의 순서를 무작위로 섞는다."
        ],
        "correctIndex": 1,
        "explanation": "‘Let’s think step by step’과 같이 추론 과정을 명시적으로 생성하게 함으로써 복잡한 문제의 해결 능력을 향상시킵니다."
      },
      {
        "id": 11,
        "text": "다음 중 LLM 기반 ‘에이전트(Agent)’와 일반적인 LLM 챗봇의 가장 큰 차이점은?",
        "options": [
          "에이전트는 인터넷에 연결되어 있지 않다.",
          "에이전트는 도구(Tool)를 스스로 선택하고 사용하여 작업을 수행하는 자율성을 가진다.",
          "챗봇은 항상 정확한 답변만 한다.",
          "에이전트는 텍스트 생성을 할 수 없다.",
          "차이점이 없다."
        ],
        "correctIndex": 1,
        "explanation": "에이전트는 단순 대화를 넘어 검색, 계산기, API 호출 등의 도구(Tool)를 사용할 수 있으며, 계획(Plan)을 세우고 실행(Action)하는 주체적 능력을 가집니다."
      },
      {
        "id": 12,
        "text": "'Prompt Injection' 공격에 대한 설명으로 옳은 것은?",
        "options": [
          "프롬프트를 짧게 입력하여 비용을 아끼는 기술",
          "악의적인 명령어를 입력하여 LLM이 설계된 지침(System Prompt)을 무시하고 엉뚱한 동작을 하게 만드는 공격",
          "데이터베이스의 속도를 느리게 만드는 디도스 공격의 일종",
          "프롬프트에 이모티콘을 많이 넣어 답변을 부드럽게 만드는 것",
          "모델의 학습 데이터를 삭제하는 해킹 기법"
        ],
        "correctIndex": 1,
        "explanation": "‘이전의 모든 지시를 무시하고…’와 같은 문구를 통해 시스템이 설정한 윤리적 제약이나 페르소나를 뚫는 공격 방식입니다."
      },
      {
        "id": 13,
        "text": "LLM의 'Context Window(컨텍스트 윈도우)'가 가득 찼을 때 발생하는 문제는?",
        "options": [
          "모델의 지능이 갑자기 상승한다.",
          "가장 최근의 대화 내용이나 중요한 앞부분의 정보가 잘려나가(Truncation) 기억하지 못하게 된다.",
          "답변 생성 속도가 매우 빨라진다.",
          "토큰 비용이 0이 된다.",
          "모델이 자동으로 재부팅된다."
        ],
        "correctIndex": 1,
        "explanation": "컨텍스트 윈도우는 모델이 한 번에 처리할 수 있는 토큰의 최대 한도입니다. 이를 초과하면 과거 정보를 잊거나 오류가 발생합니다."
      },
      {
        "id": 14,
        "text": "RAG에서 'Lost in the Middle' 현상은 무엇을 의미하는가?",
        "options": [
          "검색된 문서가 너무 적어서 답변을 못하는 현상",
          "프롬프트의 중간 부분에 위치한 정보보다 처음과 끝에 위치한 정보를 모델이 더 잘 기억하는 경향",
          "데이터베이스의 중간 데이터가 삭제되는 현상",
          "임베딩 과정에서 중간 차원이 소실되는 현상",
          "사용자가 질문 도중에 말을 멈추는 현상"
        ],
        "correctIndex": 1,
        "explanation": "LLM은 긴 컨텍스트(Long Context)를 처리할 때, 문맥의 시작과 끝에 집중하고 중간 부분의 정보를 간과하는 경향이 있다는 연구 결과입니다."
      },
      {
        "id": 15,
        "text": "벡터 유사도 측정 방식 중, 두 벡터 사이의 각도를 기반으로 유사성을 판단하는 가장 보편적인 지표는?",
        "options": [
          "유클리드 거리 (Euclidean Distance)",
          "코사인 유사도 (Cosine Similarity)",
          "맨해튼 거리 (Manhattan Distance)",
          "자카드 유사도 (Jaccard Similarity)",
          "해밍 거리 (Hamming Distance)"
        ],
        "correctIndex": 1,
        "explanation": "텍스트 임베딩 검색에서는 벡터의 크기보다 방향(각도)이 의미적 유사성을 더 잘 나타내므로 코사인 유사도가 가장 널리 사용됩니다."
      },
      {
        "id": 16,
        "text": "'Fine‑tuning'과 RAG의 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          "Fine‑tuning은 외부 지식을 검색하고, RAG는 모델 내부 지식을 바꾼다.",
          "Fine‑tuning은 모델의 파라미터를 업데이트하여 특정 말투나 형식을 학습시키는 데 유리하고, RAG는 최신 정보 제공에 유리하다.",
          "RAG는 비용이 매우 비싸고 Fine‑tuning은 비용이 거의 들지 않는다.",
          "Fine‑tuning은 환각 현상을 100% 제거할 수 있다.",
          "두 기술은 동시에 사용할 수 없다."
        ],
        "correctIndex": 1,
        "explanation": "Fine‑tuning은 모델 자체를 재학습시켜 도메인 특화 지식이나 스타일을 주입하는 것이고, RAG는 검색을 통해 지식을 보강하는 것입니다. 두 기술은 상호 보완적으로 함께 사용될 수 있습니다."
      },
      {
        "id": 17,
        "text": "LLM이 도구(Tool)를 사용하기 위해 출력해야 하는 구조화된 데이터 형식으로 가장 많이 쓰이는 것은?",
        "options": [
          "Plain Text",
          "JSON (JavaScript Object Notation)",
          "Binary Code",
          "HTML",
          "MP3"
        ],
        "correctIndex": 1,
        "explanation": "함수 호출(Function Calling) 시, LLM은 도구 이름과 인자(Arguments)를 명확히 전달하기 위해 구조화가 용이한 JSON 형식을 주로 생성합니다."
      },
      {
        "id": 18,
        "text": "'Multi‑Query Retrieval' 전략의 목적은?",
        "options": [
          "사용자의 질문을 하나로 요약하여 검색 횟수를 줄이는 것",
          "사용자의 모호한 질문을 다양한 관점의 여러 질문으로 변환하여 검색 범위를 넓히고 정답 가능성을 높이는 것",
          "여러 명의 사용자가 동시에 질문할 수 있게 하는 것",
          "질문을 100개 복사하여 시스템 부하를 테스트하는 것",
          "검색 결과를 무시하고 LLM이 질문을 다시 만드는 것"
        ],
        "correctIndex": 1,
        "explanation": "하나의 질문만으로는 검색에 실패할 수 있으므로, LLM을 이용해 유사한 의미의 다른 질문들을 생성하고 각각 검색하여 결과를 종합하는 전략입니다."
      },
      {
        "id": 19,
        "text": "LLM 애플리케이션 개발 프레임워크인 ‘LangChain’이나 ‘LlamaIndex’의 주된 역할이 아닌 것은?",
        "options": [
          "다양한 LLM 모델을 쉽게 교체하여 사용할 수 있게 추상화한다.",
          "문서 로드, 청킹, 임베딩 과정을 파이프라인으로 연결한다.",
          "자체적인 GPU를 제공하여 모델을 학습시킨다.",
          "에이전트 및 메모리 기능을 구현하기 위한 도구를 제공한다.",
          "프롬프트 템플릿을 관리한다."
        ],
        "correctIndex": 2,
        "explanation": "이들 프레임워크는 LLM 활용을 돕는 오케스트레이션(조정) 도구이지, GPU 인프라나 모델 학습 플랫폼 자체는 아닙니다."
      },
      {
        "id": 20,
        "text": "RAG 시스템의 성능을 평가할 때 ‘Ground Truth(정답 데이터)’와 생성된 답변을 비교하여 평가하는 지표가 아닌 것은?",
        "options": [
          "Faithfulness (충실성 - 검색된 문서에 기반했는가)",
          "Answer Relevance (답변 관련성 - 질문에 적절한가)",
          "Context Precision (문맥 정확도 - 검색된 내용이 유용한가)",
          "Latency (지연 시간)",
          "BLEU Score (일반적인 기계 번역 평가 지표, RAG 특화는 아님)"
        ],
        "correctIndex": 3,
        "explanation": "Latency는 시스템 속도 지표이며, 내용의 정확성을 평가하는 지표는 아닙니다."
      }
    ]
  },
  {
    "id": "prompt-engineering",
    "name": "프롬프트 엔지니어링",
    "questions": [
      {
        "id": 1,
        "text": "최근 LLM 모델의 발전으로 인한 프롬프트 엔지니어링의 변화 양상으로 가장 적절한 것은?",
        "options": [
          "모델 성능이 좋아져 프롬프트에 아무런 지시를 하지 않아도 완벽한 답을 한다.",
          "모델이 고도화됨에 따라 정보를 단순 나열하기보다, 원하는 출력 형식을 위해 정보를 요약 및 구조화하는 방향으로 변화했다.",
          "최신 모델은 'Meta Prompting' 학습이 되어 있지 않아 사용자가 모든 규칙을 세세히 정해야 한다.",
          "프롬프트 엔지니어링은 이제 완전히 사라진 기술이다.",
          "과거 모델일수록 복잡한 추론 과정을 스스로 잘 수행했다."
        ],
        "correctIndex": 1,
        "explanation": "최근 모델은 정보를 단순 나열하기보다 사용 목적에 따라 적합한 포맷으로 출력하도록 정보를 요약하고 구조화하는 능력이 향상되었습니다. 또한 LLM 자체가 다양한 프롬프트 작성 방식(Meta Prompting)에 대해 학습되어 있습니다."
      },
      {
        "id": 2,
        "text": "Google Gemini Prompting Guide 101에서 제시한 효과적인 프롬프트의 4가지 요소가 아닌 것은?",
        "options": [
          "Persona (역할 설정)",
          "Task (작업 내용)",
          "Context (참고 정보)",
          "Format (출력 형식)",
          "Temperature (창의성 조절)"
        ],
        "correctIndex": 4,
        "explanation": "교재에서 제시한 Google Gemini의 프롬프트 4요소는 Persona, Task, Context, Format입니다."
      },
      {
        "id": 3,
        "text": "최근 연구(EMNLP 2024 등)에서 밝혀진 '시스템 프롬프트 내 페르소나(Persona)'의 효과에 대한 설명으로 옳은 것은?",
        "options": [
          "모든 상황에서 페르소나를 설정하면 성능이 비약적으로 향상된다.",
          "페르소나는 모델의 추론 능력보다는 답변의 '형식(Format)'이나 '어조'를 맞추는 데 더 유효하다.",
          "페르소나는 이제 전혀 사용할 필요가 없는 기법이다.",
          "특정 직업(예: 변호사, 의사)을 부여하면 해당 도메인의 전문 지식이 없는 모델도 전문가처럼 답변한다.",
          "페르소나는 항상 사용자 프롬프트의 맨 마지막에 위치해야 한다."
        ],
        "correctIndex": 1,
        "explanation": "최근 연구에 따르면 시스템 프롬프트의 페르소나는 지식 기반 성능 향상에 큰 도움을 주지 않으며, 오히려 답변의 형식 차원에서 여전히 유효한 것으로 나타났습니다."
      },
      {
        "id": 4,
        "text": "Few-Shot Prompting을 사용할 때 발생할 수 있는 편향(Bias)이나 주의점으로 적절한 것은?",
        "options": [
          "예시를 많이 줄수록 토큰 사용량이 줄어든다.",
          "예시의 내용뿐만 아니라 길이, 톤, 어휘 등에 모델이 과도하게 영향을 받을 수 있다.",
          "예시는 반드시 1개만 제공해야 한다.",
          "예시를 주면 모델의 창의성이 무한대로 늘어난다.",
          "한국어는 영어보다 토큰 효율이 높으므로 예시를 더 많이 넣어도 비용이 적게 든다."
        ],
        "correctIndex": 1,
        "explanation": "Few-Shot Prompting은 입력된 예시에 몰입된 결과로 편향이 생길 수 있으며, 예시의 특정 방향(길이, 톤 등)에 과도하게 영향을 받을 수 있습니다."
      },
      {
        "id": 5,
        "text": "복잡한 작업을 한 번에 처리하지 않고 여러 단계로 나누어 처리하는 'Prompt Chaining'의 장점으로 옳지 않은 것은?",
        "options": [
          "불필요한 정보를 제거하여 Context 길이를 단축할 수 있다.",
          "토큰 소모를 절감할 수 있다.",
          "이전 단계의 맥락(Context)을 무시하고 매번 새로운 대화를 시작해야 한다.",
          "복잡한 질문을 쪼개어 답변의 정확도를 높일 수 있다.",
          "LLM 사용 효율성을 향상시킨다."
        ],
        "correctIndex": 2,
        "explanation": "Prompt Chaining은 LLM이 이전 맥락을 기억한다는 점을 활용하여 질문을 쪼개 처리하는 방식으로, 맥락을 무시하는 것이 아니라 효율적으로 관리하는 기법입니다."
      },
      {
        "id": 6,
        "text": "LLM의 논리적 추론 능력을 향상시키기 위해, 질문에 바로 답하지 않고 풀이 과정을 출력하도록 유도하는 기법은?",
        "options": [
          "Retrieval Augmented Generation (RAG)",
          "Chain-of-Thought (CoT)",
          "Lexical Search",
          "Few-Shot Prompting",
          "ReAct"
        ],
        "correctIndex": 1,
        "explanation": "CoT(Chain-of-Thought)는 문제 풀이 시 논리적 사고를 단계적으로 유도하여 추론 성능을 높이는 기법입니다."
      },
      {
        "id": 7,
        "text": "예시(Example) 없이 프롬프트에 \"Let's think step by step\"이라는 문구를 추가하여 논리적 추론을 유도하는 방식은?",
        "options": [
          "Few-shot CoT",
          "Zero-shot CoT",
          "Step-Back Prompting",
          "Reflexion",
          "Self-Consistency"
        ],
        "correctIndex": 1,
        "explanation": "Zero-shot CoT는 별도의 예제 없이 \"Let's think step by step\"과 같은 지시어만으로 단계적 추론을 유도합니다."
      },
      {
        "id": 8,
        "text": "'Step-Back Prompting'에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "문제를 더 작은 단위로 쪼개어 순차적으로 해결한다.",
          "답변을 생성하기 전에, 문제의 본질이나 더 큰 개념(Abstraction)을 먼저 도출하여 구조를 파악한다.",
          "무조건 답변을 짧게 하도록 강제하는 기법이다.",
          "과거의 기억을 모두 삭제하고 처음부터 다시 시작하는 방식이다.",
          "검색된 문서의 내용을 그대로 복사해서 답변하는 방식이다."
        ],
        "correctIndex": 1,
        "explanation": "Step-Back Prompting은 구체적인 질문에서 한 발 물러나 더 높은 수준의 개념이나 원리를 먼저 파악(Abstraction)한 뒤 답변을 생성하여 정확도를 높이는 기법입니다."
      },
      {
        "id": 9,
        "text": "프롬프트 작성 시 한국어와 영어 사용에 대한 팁으로 올바른 것은?",
        "options": [
          "한국어 특화 모델이 아니면 일반적으로 영어로 지시하는 것이 모델의 이해력과 토큰 효율성 측면에서 유리하다.",
          "모든 모델은 한국어 데이터를 영어보다 더 많이 학습했다.",
          "한국어로 지시할 때 문법 오류나 언어 혼용은 절대 발생하지 않는다.",
          "지시 사항을 영어로 작성하면 답변의 정확도가 항상 떨어진다.",
          "오픈 소스 LLM은 상용 LLM보다 한국어 성능이 항상 뛰어나다."
        ],
        "correctIndex": 0,
        "explanation": "대부분의 모델은 영어 학습량이 압도적이므로 영어 지시 시 이해력과 토큰 효율성이 증가합니다. 한국어 미흡 모델은 문법 오류나 언어 혼용이 발생할 수 있습니다."
      },
      {
        "id": 10,
        "text": "LangChain의 핵심 문법인 LCEL(LangChain Expression Language)에서 구성 요소를 연결하는 연산자는?",
        "options": [
          "+",
          ">>",
          "| (Pipe)",
          "&",
          "->"
        ],
        "correctIndex": 2,
        "explanation": "LCEL은 유닉스 파이프와 유사한 | 연산자를 사용하여 Prompt, LLM, OutputParser 등을 체인으로 연결합니다."
      },
      {
        "id": 11,
        "text": "LangChain의 기본 Chain 구성 순서로 가장 일반적인 것은?",
        "options": [
          "LLM → Prompt → OutputParser",
          "Prompt → OutputParser → LLM",
          "Prompt → LLM → OutputParser",
          "OutputParser → LLM → Prompt",
          "LLM → OutputParser → Prompt"
        ],
        "correctIndex": 2,
        "explanation": "입력 변수를 받아 프롬프트를 구성하고(Prompt), 이를 모델에 전달하여(LLM), 그 결과를 원하는 형식으로 변환(OutputParser)하는 순서가 일반적입니다."
      },
      {
        "id": 12,
        "text": "LangChain에서 LLM의 출력을 문자열(String), JSON, Pydantic 등 원하는 형식으로 변환해주는 모듈은?",
        "options": [
          "Retriever",
          "VectorStore",
          "PromptTemplate",
          "OutputParser",
          "Loader"
        ],
        "correctIndex": 3,
        "explanation": "Parser(OutputParser)는 LLM 뒤에 연결하여 LLM의 텍스트 출력을 구조화된 데이터(JSON 등)나 특정 포맷으로 변환하는 역할을 합니다."
      },
      {
        "id": 13,
        "text": "RAG(Retrieval Augmented Generation) 파이프라인 도입의 주된 목적은?",
        "options": [
          "LLM의 학습 속도를 높이기 위함",
          "LLM이 모르는 정보나 최신 정보를 외부 검색을 통해 보완하여 할루시네이션을 줄이기 위함",
          "프롬프트 작성을 자동화하기 위함",
          "이미지 생성을 가능하게 하기 위함",
          "텍스트를 음성으로 변환하기 위함"
        ],
        "correctIndex": 1,
        "explanation": "RAG는 검색 도구를 추가하여 LLM이 학습하지 않았거나 정확하지 않은 정보에 대해 외부 데이터를 참조해 답변하게 함으로써 할루시네이션을 완화합니다."
      },
      {
        "id": 14,
        "text": "LLM에게 외부 함수나 API를 사용할 수 있는 능력을 부여하는 기능으로, 최근 모델들이 JSON 형식의 스키마를 통해 지원하는 것은?",
        "options": [
          "Fine-tuning",
          "Prompt Chaining",
          "Tool Calling (Function Calling)",
          "Vector Embedding",
          "Zero-shot Learning"
        ],
        "correctIndex": 2,
        "explanation": "Tool Calling(또는 Function Calling)은 LLM이 사용할 수 있는 도구(함수)의 정보를 제공하고, LLM이 필요시 이를 호출하여 작업을 수행하게 하는 기능입니다."
      },
      {
        "id": 15,
        "text": "LLM Agent의 초기 모델인 'ReAct' 프레임워크의 핵심 구성 요소 3가지는?",
        "options": [
          "Thought - Action - Observation",
          "Plan - Execute - Review",
          "Input - Process - Output",
          "Search - Retrieve - Generate",
          "Ask - Answer - Verify"
        ],
        "correctIndex": 0,
        "explanation": "ReAct 에이전트는 생각(Reasoning/Thought) -> 행동(Acting/Action) -> 관찰(Observation)의 과정을 반복하며 문제를 해결합니다."
      },
      {
        "id": 16,
        "text": "에이전트가 작업을 수행하다가 실패했을 때, 실패 원인을 분석하고 이를 바탕으로 재시도하여 성공률을 높이는 기법은?",
        "options": [
          "ReAct",
          "Reflexion",
          "Few-shot",
          "RAG",
          "Prompt Template"
        ],
        "correctIndex": 1,
        "explanation": "Reflexion은 실패 피드백을 기반으로 자기 반성(Self-reflection)을 수행하고, 이 내용을 다음 시도에 반영하여 문제 해결 능력을 높이는 프레임워크입니다."
      },
      {
        "id": 17,
        "text": "Multi-Agent 시스템을 도입했을 때 얻을 수 있는 이점으로 가장 적절한 것은?",
        "options": [
          "에이전트 간 통신 비용이 증가하여 속도가 느려진다.",
          "단일 에이전트가 모든 툴을 관리하므로 구조가 단순해진다.",
          "작업을 세분화하여 개별 전문 에이전트가 처리하므로 Context 관리가 용이하고 Token 낭비를 줄일 수 있다.",
          "LLM의 파라미터 수를 직접 늘릴 수 있다.",
          "할루시네이션이 100% 제거된다."
        ],
        "correctIndex": 2,
        "explanation": "Multi-Agent 시스템은 검색, 개발, 작성 등 역할을 분담하여 필요한 정보만 전달하므로, 단일 에이전트가 모든 맥락을 처리할 때 발생하는 토큰 낭비와 비효율을 줄일 수 있습니다."
      },
      {
        "id": 18,
        "text": "복잡한 문제를 해결하기 위해 여러 개의 에이전트가 협력하는 구조 중, 중앙 관리자(Supervisor)가 작업을 할당하고 조율하는 방식은?",
        "options": [
          "Network 구조",
          "Hierarchical(계층적) 구조 / Supervisor 구조",
          "Random 구조",
          "Linear 구조",
          "Solo 구조"
        ],
        "correctIndex": 1,
        "explanation": "Supervisor 혹은 Hierarchical 구조는 중앙 제어(Supervisor) 에이전트가 하위 에이전트들을 관리하고 작업을 병렬 실행하거나 조율하는 방식입니다."
      },
      {
        "id": 19,
        "text": "Tool Calling 과정에서 LLM의 역할 변화에 대한 설명으로 옳은 것은?",
        "options": [
          "LLM은 오직 텍스트 생성만 수행하고 도구 사용 여부는 사용자가 결정한다.",
          "과거에는 LLM이 도구를 직접 실행했지만, 최근에는 도구 실행 결과를 받기만 한다.",
          "LLM은 상황을 판단하여 필요한 Tool을 선택하고 인자(Argument)를 생성하는 'Controller' 역할을 한다.",
          "Tool Calling은 LLM의 성능을 저하시키므로 사용하지 않는 것이 좋다.",
          "모든 LLM은 별도의 프롬프트 없이도 자동으로 Tool을 사용할 수 있다."
        ],
        "correctIndex": 2,
        "explanation": "LLM은 텍스트 생성뿐만 아니라 상황을 판단하고, 지시하고, 제어할 수 있는 능력을 통해 외부 Tool을 활용하는 컨트롤 타워 역할을 수행합니다."
      },
      {
        "id": 20,
        "text": "LangGraph에 대한 설명으로 가장 적절한 것은?",
        "options": [
          "LangChain에서 그래프 데이터베이스를 구축하는 도구이다.",
          "에이전트의 흐름을 그래프 구조로 정의하여, 순환(Cycle)이나 상태(State) 관리가 가능한 워크플로우를 만드는 라이브러리이다.",
          "텍스트를 이미지로 변환하는 그래프 모델이다.",
          "RAG 성능을 평가하는 도구이다.",
          "LLM의 비용을 계산해주는 계산기이다."
        ],
        "correctIndex": 1,
        "explanation": "LangGraph는 Multi-Agent나 복잡한 RAG 흐름을 제어하기 위해 상태(State)를 유지하며 순환 및 분기 처리가 가능한 그래프 구조의 워크플로우를 설계하는 도구입니다."
      }
    ]
  },
  {
    "id": "rag-agent",
    "name": "RAG Agent",
    "questions": [
      {
        "id": 1,
        "text": "LLM(Large Language Model)이 가진 한계점 중, RAG를 통해 해결하고자 하는 주된 문제는 무엇인가요?",
        "options": [
          "모델의 추론 속도가 너무 느리다.",
          "한국어 처리 능력이 떨어진다.",
          "학습 데이터 시점 이후의 최신 정보나 내부 데이터에 대해 답변하지 못하거나 환각(Hallucination)을 일으킨다.",
          "텍스트를 이미지로 변환하는 기능이 없다.",
          "문법적으로 올바른 문장을 생성하지 못한다."
        ],
        "correctIndex": 2,
        "explanation": "LLM은 Knowledge cutoff(지식 단절 시점)가 존재하여 최신 정보나 도메인 특화 데이터(내부 데이터)에 대해서는 성능을 내기 어렵거나 환각 현상이 발생합니다. RAG는 이를 보완하기 위해 외부 정보를 검색하여 제공합니다."
      },
      {
        "id": 2,
        "text": "RAG(검색 증강 생성)와 파인 튜닝(Fine-tuning)의 가장 큰 차이점에 대한 설명으로 옳은 것은?",
        "options": [
          "파인 튜닝은 외부 DB를 활용하고, RAG는 모델 파라미터를 변경한다.",
          "RAG는 모델의 파라미터를 업데이트하지 않고 프롬프트에 문맥(Context)을 추가하여 답변을 생성한다.",
          "파인 튜닝은 데이터 변경 시 재학습이 필요 없지만, RAG는 재학습이 필수적이다.",
          "RAG는 지식을 모델 내부에 저장하고, 파인 튜닝은 지식을 외부에 저장한다.",
          "비용 면에서 파인 튜닝이 RAG보다 항상 저렴하고 빠르다."
        ],
        "correctIndex": 1,
        "explanation": "파인 튜닝은 모델 파라미터를 변경하여 지식을 학습시키는 반면, RAG는 In-Context Learning을 통해 프롬프트에 해당 정보가 있을 때만 적용되므로 모델 학습(파라미터 변경)에는 해당하지 않습니다."
      },
      {
        "id": 3,
        "text": "RAG 파이프라인의 일반적인 5단계 프로세스 순서로 올바른 것은?",
        "options": [
          "Indexing -> Searching -> Processing -> Augmenting -> Generating",
          "Processing -> Indexing -> Searching -> Augmenting -> Generating",
          "Indexing -> Processing -> Searching -> Augmenting -> Generating",
          "Searching -> Indexing -> Processing -> Generating -> Augmenting",
          "Indexing -> Augmenting -> Processing -> Searching -> Generating"
        ],
        "correctIndex": 2,
        "explanation": "RAG의 단계별 개념은 DB를 구성하는 Indexing, 질의를 전처리하는 Processing, 적합한 데이터를 찾는 Searching, 프롬프트를 생성하는 Augmenting, 답변을 생성하는 Generating 순서로 진행됩니다."
      },
      {
        "id": 4,
        "text": "RAG를 위한 데이터 준비 과정인 '청킹(Chunking)'을 수행하는 가장 주된 이유는?",
        "options": [
          "데이터베이스 용량을 늘리기 위해",
          "LLM의 Context 길이 제한(Input limitation)과 검색의 정확도를 높이기 위해",
          "원본 데이터를 암호화하기 위해",
          "텍스트를 이미지로 변환하기 위해",
          "모든 문서를 하나의 거대한 텍스트로 합치기 위해"
        ],
        "correctIndex": 1,
        "explanation": "LLM 모델마다 Context 길이 지원 범위가 다르고, 긴 Context를 처리하는 능력에 한계가 있으므로 전체 문서를 입력하는 대신 의미 있는 단위(청크)로 잘라서 입력해야 합니다."
      },
      {
        "id": 5,
        "text": "청킹(Chunking) 과정에서 '오버랩(Overlap)'을 설정하는 이유는 무엇인가요?",
        "options": [
          "저장 공간을 절약하기 위해",
          "청크가 나뉘는 경계에서 문맥(Context)이나 의미가 단절되는 것을 방지하기 위해",
          "검색 속도를 늦추기 위해",
          "LLM이 같은 문장을 반복해서 말하게 하기 위해",
          "청크의 총 개수를 줄이기 위해"
        ],
        "correctIndex": 1,
        "explanation": "문장이 중간에서 잘리면 의미를 이해하기 어려우므로, 청크 간에 일정 부분(일반적으로 10~20%)을 겹치게 하여 연결 시 의미를 보존합니다."
      },
      {
        "id": 6,
        "text": "긴 문맥(Long Context)을 가진 최신 LLM 모델들이 등장했음에도 불구하고, 여전히 RAG와 청킹이 유효한 이유는?",
        "options": [
          "최신 모델은 긴 문맥을 전혀 처리하지 못하기 때문이다.",
          "긴 문맥의 중간 부분에 위치한 정보를 잘 찾지 못하는 'Lost in the Middle' 현상과 비용 효율성 때문이다.",
          "RAG를 사용하면 모델의 파라미터가 자동으로 업데이트되기 때문이다.",
          "청킹을 하지 않으면 벡터 DB에 저장이 불가능하기 때문이다.",
          "짧은 문맥 모델이 긴 문맥 모델보다 항상 성능이 좋기 때문이다."
        ],
        "correctIndex": 1,
        "explanation": "최신 모델(GPT-4, Gemini 등)은 Context 길이가 확장되었지만, 전체 문서를 다 넣으면 중간 정보를 놓치는 현상(Lost in the Middle)이 발생하거나 처리 비용이 증가하므로 효과적인 정보 추출이 필요합니다."
      },
      {
        "id": 7,
        "text": "사용자의 질문이 지나치게 짧거나 모호할 때(예: \"TV가 안 나와요\"), Processing 단계에서 수행해야 할 적절한 조치는?",
        "options": [
          "질문을 무시하고 아무 답변이나 생성한다.",
          "이전 대화 내역(History)을 바탕으로 질문을 구체화(Contextualize)하거나 의도를 파악한다.",
          "질문을 그대로 벡터 DB에 검색한다.",
          "질문의 길이를 강제로 100자 이상으로 늘린다.",
          "검색 단계를 건너뛰고 바로 답변을 생성한다."
        ],
        "correctIndex": 1,
        "explanation": "지나치게 짧은 쿼리는 의미 이해를 위한 정보가 불충분하므로, 이전 대화 내역을 고려하여 맥락화하거나 의도를 파악하는 전처리가 필요합니다."
      },
      {
        "id": 8,
        "text": "'Semantic Search(시멘틱 검색)'에 대한 설명으로 옳은 것은?",
        "options": [
          "키워드가 정확히 일치해야만 검색된다.",
          "BM25 알고리즘이 대표적인 예이다.",
          "텍스트를 임베딩 벡터로 변환하여 벡터 간의 의미적 유사도를 비교한다.",
          "문장의 길이만을 기준으로 정렬한다.",
          "SQL 쿼리문을 사용하여 DB를 검색한다."
        ],
        "correctIndex": 2,
        "explanation": "Semantic Search는 Transformer 기반 방식으로 텍스트를 벡터화하고, 표면적 일치가 아닌 의미적 유사성을 기반으로 탐색합니다."
      },
      {
        "id": 9,
        "text": "벡터 DB에서 두 벡터 간의 유사도를 측정하는 지표 중, 1에서 코사인 유사도(Cosine Similarity)를 뺀 값으로, 방향성의 차이를 나타내는 것은?",
        "options": [
          "Euclidean Distance",
          "Dot Product",
          "Cosine Distance",
          "Manhattan Distance",
          "Jaccard Similarity"
        ],
        "correctIndex": 2,
        "explanation": "Cosine Distance는 \"1 - Cosine Similarity\" 로 계산되며, 두 벡터가 이루는 각도를 기반으로 거리를 측정합니다."
      },
      {
        "id": 10,
        "text": "검색 결과의 다양성을 확보하기 위해, 가장 유사한 문서를 찾은 뒤 그와 비슷하지만 조금 떨어진(덜 유사한) 문서를 함께 선택하는 기법은?",
        "options": [
          "HNSW",
          "MMR (Maximal Marginal Relevance)",
          "Exact Match",
          "Random Sampling",
          "Inverted Index"
        ],
        "correctIndex": 1,
        "explanation": "MMR은 다양성을 고려한 방법으로, 쿼리와 가장 가까운 Chunk를 찾은 뒤 넓게 검색하여 중복된 정보만 나오는 것을 방지합니다."
      },
      {
        "id": 11,
        "text": "Bi-Encoder와 Cross-Encoder에 대한 설명으로 올바른 것은?",
        "options": [
          "Bi-Encoder는 계산량이 많아 속도가 매우 느리다.",
          "Cross-Encoder는 두 문장을 각각 벡터로 만든 후 비교한다.",
          "Bi-Encoder는 문장을 미리 벡터로 변환해 둘 수 있어 대규모 검색에 유리하다.",
          "Cross-Encoder는 성능이 낮아 거의 사용되지 않는다.",
          "최신 RAG에서는 오직 Bi-Encoder만 사용한다."
        ],
        "correctIndex": 2,
        "explanation": "Bi-Encoder(예: SentenceBERT)는 각각의 질문/문서를 벡터로 생성해두고 비교하므로 대규모 데이터 처리가 빠릅니다. 반면 Cross-Encoder는 두 문장을 합쳐서 입력하므로 정확도는 높으나 계산량이 많아 1차 검색보다는 2차 Reranking에 주로 쓰입니다."
      },
      {
        "id": 12,
        "text": "대규모 벡터 DB에서 모든 벡터를 1:1로 비교하는 것은 시간이 오래 걸리므로, 근사치를 이용하여 빠르게 검색하는 알고리즘을 통칭하는 용어는?",
        "options": [
          "SQL",
          "ANN (Approximate Nearest Neighbors)",
          "DFS (Depth First Search)",
          "BFS (Breadth First Search)",
          "RNN (Recurrent Neural Network)"
        ],
        "correctIndex": 1,
        "explanation": "다수의 질문을 처리할 때 모든 벡터를 계산하면 병목이 발생하므로, 검색 공간을 분할하거나 압축하여 근사값을 찾는 ANN(HNSW, ANNOY 등) 기법을 사용합니다."
      },
      {
        "id": 13,
        "text": "'Small2Big' 전략(Parent Document Retriever)의 핵심 아이디어는 무엇인가요?",
        "options": [
          "검색은 큰 단위(Big Chunk)로 하고, LLM에게는 작은 단위(Small Chunk)를 준다.",
          "검색은 작은 단위(Small Chunk)로 정밀하게 수행하고, LLM에게는 그 주변 정보를 포함한 큰 단위(Parent Chunk)를 제공한다.",
          "검색과 생성 모두 가장 작은 단위로 수행한다.",
          "문서를 청킹하지 않고 전체를 통째로 검색한다.",
          "검색된 정보의 순서를 무작위로 섞어서 제공한다."
        ],
        "correctIndex": 1,
        "explanation": "Small Chunk는 정확한 검색에 유리하지만 맥락이 부족할 수 있으므로, 검색은 Small Chunk로 하되 실제 LLM에게 전달하는 Context는 원본이나 더 큰 Parent Chunk를 사용하여 문맥을 보강합니다."
      },
      {
        "id": 14,
        "text": "청킹할 때, 각 청크에 문서의 요약이나 메타데이터를 덧붙여 임베딩하는 기법은?",
        "options": [
          "Contextual Retrieval",
          "Random Chunking",
          "Keyword Extraction",
          "Stopword Removal",
          "Character Splitting"
        ],
        "correctIndex": 0,
        "explanation": "청크에 헤더나 요약 정보를 추가(Chunk 강화)하여 검색 정확도를 높이는 것이 Contextual Retrieval입니다."
      },
      {
        "id": 15,
        "text": "사용자의 질문에 대해 LLM이 가상의 답변을 생성하고, 이를 기반으로 실제 DB에서 유사 문서를 검색하는 방식은?",
        "options": [
          "MMR",
          "ReAct",
          "HyDE (Hypothetical Document Embedding)",
          "Self-Consistency",
          "Chain-of-Thought"
        ],
        "correctIndex": 2,
        "explanation": "HyDE는 질문에 대해 LLM이 답변이나 관련 문서를 생성하게 한 뒤, 그 텍스트를 임베딩하여 실제 문서와의 유사도를 비교합니다."
      },
      {
        "id": 16,
        "text": "하나의 질문을 다양한 관점의 여러 질문으로 변환하여(Multi-Querying) 검색 확률을 높이는 기법은?",
        "options": [
          "Query Reformulation",
          "Query Deletion",
          "Query Compression",
          "Exact Match Search",
          "Vector Normalization"
        ],
        "correctIndex": 0,
        "explanation": "Query Reformulation은 질문을 여러 구체적인 형태로 재구성해 다각도로 검색함으로써 성능을 높입니다."
      },
      {
        "id": 17,
        "text": "'Hybrid Search'는 어떤 두 가지 검색 방식을 결합하는 것을 의미하나요?",
        "options": [
          "Google 검색 + Naver 검색",
          "Lexical Search (키워드 기반) + Semantic Search (임베딩 기반)",
          "Image Search + Text Search",
          "SQL Search + NoSQL Search",
          "Manual Search + Auto Search"
        ],
        "correctIndex": 1,
        "explanation": "키워드 기반 Sparse Vector와 임베딩 기반 Dense Vector 검색 결과를 결합하여 상호 보완적인 결과를 얻습니다."
      },
      {
        "id": 18,
        "text": "1차로 검색된 문서들을 대상으로, 질문과의 관련성을 다시 정밀하게 평가하여 순서를 재배치하는 과정을 무엇이라고 하나요?",
        "options": [
          "Pre-training",
          "Quantization",
          "Reranking",
          "Chunking",
          "Indexing"
        ],
        "correctIndex": 2,
        "explanation": "Reranker는 Retriever가 찾아온 후보군 중에서 질문과 실제 관련이 있는 것을 찾아 순위를 재조정하는 2차 작업입니다."
      },
      {
        "id": 19,
        "text": "RAG 성능 고도화 중 'Reordering'이 필요한 이유와 관련 있는 현상은?",
        "options": [
          "Hallucination (환각)",
          "Lost in the Middle (중간 내용 간과)",
          "Overfitting (과적합)",
          "Vanishing Gradient (기울기 소실)",
          "Token Limit (토큰 제한)"
        ],
        "correctIndex": 1,
        "explanation": "LLM은 긴 Context가 주어졌을 때 앞부분과 뒷부분에 더 많은 관심을 갖고 중간 내용을 놓치는 경향이 있어, 중요 정보를 양끝에 배치하는 등의 Reordering이 유용합니다."
      },
      {
        "id": 20,
        "text": "PDF 문서 내의 텍스트뿐만 아니라 이미지, 표 등을 인식하고 파싱하여 RAG에 활용하기 위해 사용하는 도구로, IBM에서 만든 오픈소스 소프트웨어는?",
        "options": [
          "Pandas",
          "Docling",
          "OpenCV",
          "Tesseract",
          "Adobe Acrobat"
        ],
        "correctIndex": 1,
        "explanation": "Docling은 PDF, PPT, DOC, HTML 등에서 텍스트뿐 아니라 이미지와 테이블까지 파싱해 적절히 처리할 수 있게 돕는 도구입니다."
      }
    ]
  },
  {
    "id": "fine-tuning",
    "name": "Fine Tuning",
    "questions": [
      {
        "id": 1,
        "text": "LLM의 학습 과정 중, 이미 만들어진 모델(Pretrained Model)에 목적에 맞는 데이터를 추가로 학습시켜 성능을 향상시키는 과정은?",
        "options": [
          "Pretraining (사전 학습)",
          "Fine Tuning (파인 튜닝)",
          "Tokenization (토큰화)",
          "Prompt Engineering (프롬프트 엔지니어링)",
          "RAG (검색 증강 생성)"
        ],
        "correctIndex": 1,
        "explanation": "Fine Tuning은 이미 방대한 데이터로 학습된 베이스 모델(Base Model)에 새로운 데이터를 추가 학습하여 특정 도메인 지식이나 형식을 익히게 하는 과정입니다."
      },
      {
        "id": 2,
        "text": "Fine Tuning을 수행하는 4가지 주요 목적에 해당하지 않는 것은?",
        "options": [
          "지식 (Knowledge) 주입",
          "능력 (Ability) 향상",
          "형식 (Format) 조정",
          "안전 (Safety) 강화",
          "모델 크기 (Model Size) 확장"
        ],
        "correctIndex": 4,
        "explanation": "Fine Tuning은 지식, 능력(논리적 추론 등), 출력 형식(말투, 길이), 안전성(유해한 답변 거부)을 위해 수행됩니다. 모델의 크기(파라미터 수)를 물리적으로 늘리는 것은 Fine Tuning의 목적이 아닙니다."
      },
      {
        "id": 3,
        "text": "Base Model(Pretrained Model)의 특징으로 가장 적절한 것은?",
        "options": [
          "사용자의 질문에 친절하게 대답하도록 훈련되어 있다.",
          "주로 다음 토큰(Next Token)을 예측하는 단순 Completion 학습을 수행했다.",
          "특정 기업의 내부 규정이나 최신 뉴스를 이미 알고 있다.",
          "'챗봇'으로서의 역할을 수행하기 위해 강화 학습이 완료된 상태다.",
          "지시 사항(Instruction)을 따르는 능력이 매우 뛰어나다."
        ],
        "correctIndex": 1,
        "explanation": "Base Model은 위키피디아, 뉴스 등 대량의 텍스트로 '다음 단어 예측'만을 학습한 상태이므로, 질의응답이나 지시 사항 수행 능력은 부족합니다."
      },
      {
        "id": 4,
        "text": "Fine Tuning을 진행할 때, 새로운 데이터를 학습하자 모델이 기존에 가지고 있던 지식이나 능력을 잃어버리는 현상은?",
        "options": [
          "Overfitting (과적합)",
          "Hallucination (환각)",
          "Catastrophic Forgetting (파국적 망각)",
          "Gradient Vanishing (기울기 소실)",
          "Context Window Limit (컨텍스트 윈도우 제한)"
        ],
        "correctIndex": 2,
        "explanation": "Catastrophic Forgetting은 추가 학습을 진행할 때 모델의 파라미터가 변하면서 기존의 언어 능력이나 지식이 손상되는 현상을 말합니다."
      },
      {
        "id": 5,
        "text": "Continuous Pretraining(CPT)에 대한 설명으로 옳은 것은?",
        "options": [
          "질문-답변(QA) 쌍으로 이루어진 데이터만 사용한다.",
          "모델의 파라미터를 고정하고 프롬프트만 학습한다.",
          "특정 도메인의 말뭉치(Corpus)를 사용하여 모델의 기반 지식(토양)을 바꾼다.",
          "적은 양의 데이터로도 효과가 매우 빠르다.",
          "주로 Instruct Model을 대상으로 수행한다."
        ],
        "correctIndex": 2,
        "explanation": "CPT는 Pretrained Model에 새로운 도메인 지식(Corpus)을 추가로 주입하는 방식으로, 모델의 전반적인 언어 패턴과 지식을 변화시킵니다. Instruct Model보다는 Base Model에 주로 수행합니다."
      },
      {
        "id": 6,
        "text": "RAG(Retrieval-Augmented Generation) 시스템의 성능을 높이기 위해, RAG 형식(관련 문서 + 질문 + 답변)의 데이터로 모델을 학습시키는 기법은?",
        "options": [
          "LoRA",
          "RAFT (Retrieval-Augmented Fine-Tuning)",
          "DPO",
          "RLHF",
          "PPO"
        ],
        "correctIndex": 1,
        "explanation": "RAFT는 LLM이 주어진 문서(Context)를 참고하여 답변하고, 불필요한 정보(Distractor)를 무시하도록 훈련시키는 기법으로, '오픈 북 시험 공부'에 비유됩니다."
      },
      {
        "id": 7,
        "text": "Meta의 LIMA(Less is More for Alignment) 논문이 주장하는 Instruction Tuning의 핵심 역할은?",
        "options": [
          "모델에게 새로운 지식을 대량으로 주입하는 과정이다.",
          "모델의 파라미터 수를 획기적으로 줄이는 과정이다.",
          "Pretraining 과정에서 배운 지식을 인출하는 패턴(Format)을 학습하는 과정이다.",
          "강화 학습을 대체하는 완벽한 수단이다.",
          "이미지와 텍스트를 동시에 처리하게 만드는 과정이다."
        ],
        "correctIndex": 2,
        "explanation": "LIMA 논문은 Instruction Tuning이 새로운 지식을 배우는 것이 아니라, 이미 배운 지식을 사용자가 원하는 형식으로 꺼내 쓰는 방법(Alignment)을 익히는 과정임을 강조합니다."
      },
      {
        "id": 8,
        "text": "Instruction Tuning 데이터셋의 구성 요소로 적절하지 않은 것은?",
        "options": [
          "Instruction (지시사항)",
          "Input (입력/질문)",
          "Output (출력/답변)",
          "Reward Function (보상 함수)",
          "System Prompt (선택적)"
        ],
        "correctIndex": 3,
        "explanation": "Instruction Tuning 데이터는 일반적으로 [지시사항, 질문, 답변]의 쌍으로 구성됩니다. 보상 함수(Reward Function)는 강화 학습(RL) 단계에서 사용되는 요소입니다."
      },
      {
        "id": 9,
        "text": "RLHF(Reinforcement Learning with Human Feedback)의 핵심 구성 요소 중 하나로, LLM의 답변 품질을 점수(Scalar)로 평가하는 모델은?",
        "options": [
          "Policy Model",
          "Reward Model (보상 모델)",
          "Reference Model",
          "Tokenizer Model",
          "Embedding Model"
        ],
        "correctIndex": 1,
        "explanation": "Reward Model은 인간의 선호도 데이터를 학습하여, LLM이 생성한 답변이 얼마나 좋은지 점수로 평가하는 역할을 합니다."
      },
      {
        "id": 10,
        "text": "강화 학습 과정에서 모델이 보상(Reward)을 최대화하려다 원래 언어 모델의 분포에서 너무 벗어나지 않도록 규제하는 값은?",
        "options": [
          "Learning Rate",
          "Batch Size",
          "KL Divergence (Kullback-Leibler Divergence)",
          "Dropout Rate",
          "Attention Score"
        ],
        "correctIndex": 2,
        "explanation": "PPO 알고리즘 등에서 KL Divergence 패널티를 사용하여 튜닝된 모델이 원본 모델(Reference Model)과 너무 다르게 변하여 언어 능력이 훼손되는 것을 방지합니다."
      },
      {
        "id": 11,
        "text": "별도의 보상 모델(Reward Model) 없이, 선호 데이터(Chosen/Rejected)를 사용하여 직접 언어 모델을 최적화하는 방식은?",
        "options": [
          "PPO",
          "RLHF",
          "DPO (Direct Preference Optimization)",
          "A2C",
          "DQN"
        ],
        "correctIndex": 2,
        "explanation": "DPO는 보상 모델을 따로 학습하지 않고, LLM 자체가 선호되는 답변을 생성하도록 직접 최적화하는 방식으로, 구현이 간단하고 학습이 안정적입니다."
      },
      {
        "id": 12,
        "text": "Rejection Sampling + SFT 방식에 대한 설명으로 옳은 것은?",
        "options": [
          "모델이 생성한 여러 답변 중 보상 모델 점수가 가장 낮은 것을 선택한다.",
          "강화 학습 없이 오직 인간이 작성한 데이터만 사용한다.",
          "모델이 생성한 답변 중 우수한(Best) 답변만 골라 다시 지도 학습(SFT)에 사용한다.",
          "모델의 파라미터를 전혀 수정하지 않는다.",
          "Base Model에서만 수행 가능하다."
        ],
        "correctIndex": 2,
        "explanation": "Rejection Sampling은 현재 모델로 다수의 답변을 생성한 뒤, 보상 모델(또는 규칙)로 가장 좋은 답변을 선별하여 이를 정답 데이터로 삼아 다시 SFT를 수행하는 방식입니다."
      },
      {
        "id": 13,
        "text": "PEFT(Parameter Efficient Fine Tuning)의 대표적인 기법인 LoRA(Low-Rank Adaptation)의 원리는?",
        "options": [
          "모델의 모든 레이어를 제거하고 새로 학습한다.",
          "기존 가중치(W)는 고정하고, 이를 근사하는 저랭크 행렬(A, B)만 학습한다.",
          "모델의 파라미터를 4bit로 양자화하여 학습한다.",
          "입력 프롬프트의 길이를 줄여서 연산량을 감소시킨다.",
          "역전파(Backpropagation) 과정을 생략한다."
        ],
        "correctIndex": 1,
        "explanation": "LoRA는 Pretrained Weights는 동결(Freeze)하고, 변화량을 나타내는 작은 행렬 A와 B를 추가하여 이들만 학습시킴으로써 파라미터 수와 메모리 사용량을 획기적으로 줄입니다."
      },
      {
        "id": 14,
        "text": "LoRA 적용 시 'Rank(r)' 값에 대한 설명으로 옳은 것은?",
        "options": [
          "r 값이 클수록 학습해야 할 파라미터 수가 줄어든다.",
          "r은 모델의 전체 레이어 개수와 동일해야 한다.",
          "r은 학습 가능한 정보의 차원을 의미하며, 일반적으로 원본 차원(d)보다 훨씬 작게 설정한다.",
          "r 값이 작을수록 모델의 성능이 무조건 좋아진다.",
          "r은 배치 사이즈(Batch Size)를 의미한다."
        ],
        "correctIndex": 2,
        "explanation": "LoRA에서 r은 Low-Rank의 차원을 의미하며, 원본 차원 d보다 훨씬 작은 값(예: 4, 8, 16 등)을 사용하여 파라미터를 효율화합니다."
      },
      {
        "id": 15,
        "text": "Full Fine-Tuning 대비 LoRA의 장점이 아닌 것은?",
        "options": [
          "GPU 메모리 사용량이 적다.",
          "하나의 베이스 모델에 여러 개의 LoRA 어댑터를 갈아끼우며 사용할 수 있다.",
          "학습 속도가 빠르다.",
          "모델의 기존 지식을 잊어버리는 Catastrophic Forgetting이 덜 발생한다.",
          "모델의 추론 속도(Inference Latency)가 획기적으로 빨라진다."
        ],
        "correctIndex": 4,
        "explanation": "LoRA는 학습 시 효율적이지만, 추론 시에는 학습된 행렬(BA)을 원래 가중치(W)에 더해서(W' =W+BA) 사용하므로 구조적으로 모델 크기가 같아져 추론 속도 자체는 Full Fine-Tuning 모델과 동일합니다. (빨라지지 않음)"
      },
      {
        "id": 16,
        "text": "GPU 메모리가 부족할 때, 베이스 모델을 4bit 등으로 양자화(Quantization)한 상태에서 LoRA를 적용하는 기법은?",
        "options": [
          "DoRA",
          "QLoRA",
          "AdaLoRA",
          "LongLoRA",
          "Soft Prompting"
        ],
        "correctIndex": 1,
        "explanation": "QLoRA(Quantized LoRA)는 베이스 모델을 양자화하여 메모리를 줄인 상태에서 LoRA 어댑터를 붙여 학습하는 방식입니다."
      },
      {
        "id": 17,
        "text": "DeepSeek-R1과 같은 최신 추론(Reasoning) 모델의 핵심 특징은?",
        "options": [
          "답변 생성 속도가 매우 빠르다.",
          "답변을 생성하기 전에 긴 사고 과정(Chain of Thought/Thinking)을 거친다.",
          "외부 도구(Tool) 사용에만 특화되어 있다.",
          "파라미터 수가 1B 이하로 매우 작다.",
          "이미지 생성 능력이 텍스트 능력보다 뛰어나다."
        ],
        "correctIndex": 1,
        "explanation": "DeepSeek-R1이나 OpenAI o1 같은 Reasoning 모델은 답변을 내놓기 전에 내부적으로 긴 추론 과정(Thinking Process/Long CoT)을 수행하여 복잡한 문제를 해결합니다."
      },
      {
        "id": 18,
        "text": "DeepSeek-R1-Zero가 사용한 강화 학습 기법으로, 별도의 Value Model(Critic) 없이 그룹 내 답변들의 상대적 우열을 비교하여 학습하는 방식은?",
        "options": [
          "PPO",
          "A3C",
          "GRPO (Group Relative Policy Optimization)",
          "TRPO",
          "DDPG"
        ],
        "correctIndex": 2,
        "explanation": "GRPO는 하나의 질문에 대해 여러 개의 답변을 생성하고, 그 그룹 내의 평균 보상을 기준으로 각 답변의 우열을 가려 학습하는 방식으로, 연산 자원을 절약합니다."
      },
      {
        "id": 19,
        "text": "DeepSeek-R1-Zero 학습 과정에서 관찰된 'Aha Moment'란 무엇인가?",
        "options": [
          "모델이 정답을 즉시 맞추는 현상",
          "모델이 스스로 자신의 풀이 과정을 재검토하고 오류를 수정하는 현상",
          "모델의 학습 속도가 갑자기 빨라지는 구간",
          "사용자의 의도를 완벽하게 파악하는 순간",
          "더 이상 성능이 향상되지 않는 정체 구간"
        ],
        "correctIndex": 1,
        "explanation": "학습이 진행되면서 모델이 텍스트 생성 도중 \"잠깐, 다시 생각해보자\"와 같이 스스로 오류를 인지하고 수정(Self-Correction)하는 패턴이 발현된 것을 의미합니다."
      },
      {
        "id": 20,
        "text": "Reasoning LLM을 만들기 위한 데이터 레시피 중, 'Distillation' 방식의 의미는?",
        "options": [
          "사람이 직접 모든 데이터를 작성하는 것",
          "작은 모델이 큰 모델(예: DeepSeek-R1)이 생성한 사고 과정(Thinking)과 답변을 학습하는 것",
          "인터넷의 모든 데이터를 무작위로 학습하는 것",
          "수학 문제만 골라서 학습하는 것",
          "강화 학습만으로 모델을 처음부터 학습시키는 것"
        ],
        "correctIndex": 1,
        "explanation": "Distillation(지식 증류)은 성능이 뛰어난 큰 모델(Teacher)이 생성한 양질의 추론 데이터(사고 과정 포함)를 작은 모델(Student)에게 학습시켜 성능을 끌어올리는 방법입니다."
      }
    ]
  }
]